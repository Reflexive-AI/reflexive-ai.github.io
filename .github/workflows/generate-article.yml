name: Generate Daily Article

on:
  schedule:
    # Runs every 6 hours: 00:00, 06:00, 12:00, 18:00 UTC
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      article_count:
        description: 'Number of articles to generate'
        required: false
        default: '1'
        type: string
      model:
        description: 'AI model to use'
        required: false
        default: 'gpt-4o'
        type: choice
        options:
          - gpt-4o
          - gpt-4o-mini

permissions:
  contents: write
  pull-requests: write

jobs:
  generate:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Generate article with GitHub Models
        uses: actions/github-script@v7
        id: generate
        env:
          ARTICLE_COUNT: ${{ github.event.inputs.article_count || '1' }}
          MODEL: ${{ github.event.inputs.model || 'gpt-4o' }}
          MODELS_API_TOKEN: ${{ secrets.MODELS_API_TOKEN }}
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Read the article list to find next unpublished article
            const articleListPath = 'ARTICLE_LIST_100.md';
            const articleList = fs.readFileSync(articleListPath, 'utf8');
            
            // Find existing articles
            const researchDir = 'src/content/research';
            const existingFiles = fs.existsSync(researchDir) ? fs.readdirSync(researchDir) : [];
            const existingNumbers = new Set(
              existingFiles
                .filter(f => f.endsWith('.md'))
                .map(f => parseInt(f.split('-')[0]))
                .filter(n => !isNaN(n))
            );
            
            // Build compact article index for cross-referencing (title + slug only)
            const articleIndex = existingFiles
              .filter(f => f.endsWith('.md'))
              .slice(-30) // Cap at 30 most recent to keep prompt compact
              .map(f => {
                const content = fs.readFileSync(path.join(researchDir, f), 'utf8');
                const titleMatch = content.match(/title:\s*"([^"]+)"/);
                const slug = f.replace('.md', '');
                return titleMatch ? `- ${titleMatch[1]} ‚Üí /research/${slug}` : null;
              })
              .filter(Boolean)
              .join('\n');
            
            // Parse article list for unpublished articles
            const unpublishedPattern = /^(\d+)\.\s*\[\s*\]\s*(.+?)(?:\s*\[([A-Z\]\[]+)\])?\s*$/gm;
            const unpublished = [];
            let match;
            let currentList = fs.readFileSync(articleListPath, 'utf8');
            let listUpdated = false;
            while ((match = unpublishedPattern.exec(articleList)) !== null) {
              const num = parseInt(match[1]);
              if (existingNumbers.has(num)) {
                // File already exists but tracking list says [ ] ‚Äî fix the mismatch
                const markPattern = new RegExp(`^(${num})\\.\\s*\\[\\s*\\]`, 'm');
                currentList = currentList.replace(markPattern, `$1. [x]`);
                listUpdated = true;
                console.log(`‚úì Article ${num} already exists on disk, marked as [x]`);
              } else {
                unpublished.push({
                  number: num,
                  title: match[2].trim(),
                  tags: match[3] || ''
                });
              }
            }
            if (listUpdated) {
              fs.writeFileSync(articleListPath, currentList);
            }
            
            // Check if we need to generate new article ideas
            if (unpublished.length < 10) {
              console.log(`Only ${unpublished.length} articles remaining. Will create PR with new ideas.`);
              core.setOutput('needs_ideas', 'true');
            }
            
            if (unpublished.length === 0) {
              console.log('No unpublished articles found');
              core.setOutput('needs_ideas', 'true');
              return;
            }
            
            const count = parseInt(process.env.ARTICLE_COUNT) || 1;
            const toGenerate = unpublished.slice(0, count);
            
            console.log(`Generating ${toGenerate.length} article(s):`);
            toGenerate.forEach(a => console.log(`  ${a.number}. ${a.title}`));
            
            // Get a sample article for style reference
            let sampleContent = '';
            if (existingFiles.length > 0) {
              const sampleFile = existingFiles.find(f => f.endsWith('.md'));
              if (sampleFile) {
                sampleContent = fs.readFileSync(path.join(researchDir, sampleFile), 'utf8').slice(0, 2000);
              }
            }
            
            // Generate each article using GitHub Models API
            const generatedFiles = [];
            
            for (const article of toGenerate) {
              const prompt = `You are a research writer for the Reflexive AI Initiative, a think tank focused on AI governance, safety, and the role of AI in its own regulation.

            Write a complete research article with this title: "${article.title}"
            Article number: ${article.number}
            Tags hint: ${article.tags} (R=Research, P=Policy, A=AI-focused)

            Requirements:
            1. Start with YAML frontmatter between --- delimiters (title, excerpt, date: ${new Date().toISOString().split('T')[0]}, toc: true, categories, tags)
            2. Write 1500-2500 words of substantive, evidence-based content
            3. Include 4-6 major sections with ## headers
            4. Use an academic but accessible tone
            5. Cross-reference related concepts where relevant
            6. End with a conclusion section
            7. Add an italicized note about scope/limitations at the end

            CRITICAL FORMATTING RULES:
            - Output the article as raw markdown, NOT wrapped in code fences
            - Do NOT wrap output in \`\`\`yaml, \`\`\`markdown, or \`\`\` blocks
            - The very first line of your response must be --- (the YAML frontmatter opening delimiter)
            - The frontmatter must end with --- on its own line
            - After the closing --- write the article body directly as markdown

            CROSS-LINKING: Include 2-3 inline references to related articles using this format: [Article Title](/research/slug)
            At the end, add a "## Related Articles" section listing 2-3 relevant pieces.
            
            Here are existing articles you can reference:
            ${articleIndex}

            STYLE RULES (from WRITING_STYLE.md):
            - No emojis ever
            - No em-dashes (use colons or semicolons)
            - Avoid: "utilize", "leverage", "facilitate", "in order to", "delve", "crucial"
            - Be direct, specific, prefer short sentences
            - Sound like a researcher, not a press release

            ${sampleContent ? `Here's an example of our style:\n\n${sampleContent}` : ''}

            Write the complete article now:`;
              
              // Use GitHub Models API via fetch
              const response = await fetch('https://models.inference.ai.azure.com/chat/completions', {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json',
                  'Authorization': `Bearer ${process.env.MODELS_API_TOKEN}`
                },
                body: JSON.stringify({
                  model: process.env.MODEL,
                  messages: [{ role: 'user', content: prompt }],
                  max_tokens: 4096,
                  temperature: 0.7
                })
              });
              
              if (!response.ok) {
                console.error(`API error: ${response.status} ${response.statusText}`);
                const errorText = await response.text();
                console.error(errorText);
                continue;
              }
              
              const data = await response.json();
              let content = data.choices[0].message.content;

              // Robust frontmatter extraction ‚Äî handles all LLM wrapping patterns:
              //   ```yaml\n---\nfm\n---\n```\nbody
              //   ```yaml\nfm\n---\n```\nbody  (missing opening ---)
              //   ```\n---\nfm\n---\nbody\n```  (whole doc in one fence)
              //   ---\nfm\n---\nbody            (correct, no fences)

              // Step 1: Find the title field ‚Äî this anchors us to the real frontmatter
              const titleIdx = content.indexOf('title:');
              if (titleIdx === -1) {
                console.error(`Article ${article.number}: no title field found in LLM output, skipping`);
                continue;
              }

              // Step 2: Find the closing --- after the title (end of frontmatter)
              const fmCloseIdx = content.indexOf('\n---', titleIdx);
              if (fmCloseIdx === -1) {
                console.error(`Article ${article.number}: no closing --- found for frontmatter, skipping`);
                continue;
              }

              // Step 3: Extract frontmatter (from title to closing ---) and body (everything after)
              const fmContent = content.substring(titleIdx, fmCloseIdx).trim();
              let body = content.substring(fmCloseIdx + 4); // skip past \n---

              // Step 4: Clean stray code fences from the body
              // Remove fence right after frontmatter (```\n at start of body)
              body = body.replace(/^\s*```\s*\n?/, '');
              // Remove trailing fence at end of document
              body = body.replace(/\n?```\s*$/, '');
              body = body.trim();

              // Step 5: Reassemble with clean --- delimiters
              content = '---\n' + fmContent + '\n---\n\n' + body;

              // Step 6: Validate required frontmatter fields before writing
              const hasTitle = /^title:\s*".+"/m.test(fmContent);
              const hasExcerpt = /^excerpt:\s*".+"/m.test(fmContent);
              if (!hasTitle || !hasExcerpt) {
                console.error(`Article ${article.number}: missing required frontmatter fields (title: ${hasTitle}, excerpt: ${hasExcerpt}), skipping`);
                continue;
              }

              // Generate filename
              const slug = article.title.toLowerCase()
                .replace(/[^a-z0-9\s-]/g, '')
                .replace(/\s+/g, '-')
                .slice(0, 50)
                .replace(/-+$/, '');
              
              const filename = `${String(article.number).padStart(3, '0')}-${slug}.md`;
              const filepath = path.join(researchDir, filename);
              
              // Ensure directory exists
              if (!fs.existsSync(researchDir)) {
                fs.mkdirSync(researchDir, { recursive: true });
              }
              
              fs.writeFileSync(filepath, content);
              console.log(`‚úì Generated: ${filename}`);
              generatedFiles.push(filename);
              
              // Only mark article as complete AFTER file is successfully written
              let updatedList = fs.readFileSync(articleListPath, 'utf8');
              const markDonePattern = new RegExp(`^(${article.number})\\.\\s*\\[\\s*\\]`, 'm');
              updatedList = updatedList.replace(markDonePattern, `$1. [x]`);
              fs.writeFileSync(articleListPath, updatedList);
              console.log(`‚úì Marked article ${article.number} as complete`);
            }
            
            return generatedFiles.join(',');
            
      - name: Check for any changes
        id: check_changes
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "has_changes=true" >> "$GITHUB_OUTPUT"
          fi

      - name: Install dependencies
        if: steps.check_changes.outputs.has_changes == 'true'
        run: npm ci

      - name: Regenerate neural graph and search index
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          node scripts/generate-graph.js
          node scripts/generate-search-index.js
          node scripts/generate-llms-txt.js

      - name: Commit and push
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add -A
          git diff --staged --quiet || git commit -m "Add generated article(s) - $(date +'%Y-%m-%d')"
          git push

      # Generate new article ideas when list runs low
      - name: Generate article ideas
        if: steps.generate.outputs.needs_ideas == 'true'
        uses: actions/github-script@v7
        id: ideas
        env:
          MODEL: ${{ github.event.inputs.model || 'gpt-4o' }}
          MODELS_API_TOKEN: ${{ secrets.MODELS_API_TOKEN }}
        with:
          script: |
            const fs = require('fs');
            
            const articleList = fs.readFileSync('ARTICLE_LIST_100.md', 'utf8');
            
            const prompt = `You are helping expand the article list for the Reflexive AI Initiative.

            Current article list:
            ${articleList}

            Generate 15 NEW article ideas that:
            1. Fill gaps in current coverage
            2. Extend existing themes naturally
            3. Balance [R] Research, [P] Policy, and [A] AI-focused tags
            4. Are timely and evergreen (avoid dated references)
            5. Follow the numbering from where the list ends

            Format each as:
            [NUMBER]. [ ] Article Title [TAGS]

            Return ONLY the numbered list, nothing else.`;

            const response = await fetch('https://models.inference.ai.azure.com/chat/completions', {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${process.env.MODELS_API_TOKEN}`
              },
              body: JSON.stringify({
                model: process.env.MODEL,
                messages: [{ role: 'user', content: prompt }],
                max_tokens: 1000,
                temperature: 0.8
              })
            });

            if (!response.ok) {
              console.error('Failed to generate ideas');
              return;
            }

            const data = await response.json();
            const ideas = data.choices[0].message.content;
            
            // Save ideas to a file for the PR
            fs.writeFileSync('PROPOSED_ARTICLES.md', `# Proposed New Articles\n\nGenerated on ${new Date().toISOString().split('T')[0]}\n\n${ideas}\n`);
            
            return ideas;

      - name: Create PR with new ideas
        if: steps.ideas.outputs.result != ''
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          BRANCH="article-ideas-$(date +'%Y%m%d-%H%M')"
          git checkout -b "$BRANCH"
          git add PROPOSED_ARTICLES.md
          git commit -m "chore: propose new article ideas"
          git push -u origin "$BRANCH"
          
          gh pr create \
            --title "üìù Proposed new article ideas" \
            --body "The article list is running low. Here are 15 proposed new topics for review.

          ## Instructions
          1. Review the ideas in \`PROPOSED_ARTICLES.md\`
          2. Edit/approve topics you like
          3. Add approved topics to \`ARTICLE_LIST_100.md\`
          4. Delete \`PROPOSED_ARTICLES.md\` before merging" \
            --base main
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
