<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Could AI systems be certified for safety like aircraft or medical devices? An analysis of what AI certification might look like, its benefits, and significant challenges."><meta name="generator" content="Astro v5.17.1"><!-- Fonts --><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Source+Serif+4:ital,wght@0,400;0,500;0,600;1,400&display=swap" rel="stylesheet"><!-- Favicon --><link rel="icon" type="image/png" href="/logo.png"><!-- Open Graph --><meta property="og:title" content="Certification Regimes for AI Systems | Reflexive AI Initiative"><meta property="og:description" content="Could AI systems be certified for safety like aircraft or medical devices? An analysis of what AI certification might look like, its benefits, and significant challenges."><meta property="og:type" content="website"><meta property="og:site_name" content="Reflexive AI Initiative"><title>Certification Regimes for AI Systems | Reflexive AI Initiative</title><link rel="stylesheet" href="/_astro/_slug_.BtA_RPCv.css"></head> <body>  <header class="header"> <div class="container header__inner"> <a href="/" class="header__brand"> <img src="/logo.png" alt="" class="header__logo"> <div> <span class="header__title">Reflexive AI</span> <span class="header__tagline">Governance · Reflexivity · Constraint</span> </div> </a> <nav class="header__nav"> <a href="/about" class="header__link">About</a> <a href="/research" class="header__link">Research</a> <a href="/contribute" class="header__link">Contribute</a> </nav> </div> </header>  <main>  <div class="article-layout"> <article class="article"> <header class="article__header"> <div class="article__meta"> <a href="/research" class="article__category">Governance Analysis</a> <span>·</span> <time datetime="2026-01-23T00:00:00.000Z"> January 23, 2026 </time> </div> <h1 class="article__title">Certification Regimes for AI Systems</h1> <p class="article__excerpt">Could AI systems be certified for safety like aircraft or medical devices? An analysis of what AI certification might look like, its benefits, and significant challenges.</p> </header>  <div class="toc-mobile"> <button class="toc-mobile__button" aria-expanded="false" onclick="this.setAttribute('aria-expanded', this.getAttribute('aria-expanded') === 'true' ? 'false' : 'true'); this.nextElementSibling.classList.toggle('open');"> <span>On This Page</span> <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M4 6L8 10L12 6" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </button> <nav class="toc-mobile__content"> <ul class="toc-mobile__list"> <li style="margin-left: 0px"> <a href="#the-certification-idea">The Certification Idea</a> </li><li style="margin-left: 0px"> <a href="#how-certification-works-in-other-domains">How Certification Works in Other Domains</a> </li><li style="margin-left: 12px"> <a href="#aviation">Aviation</a> </li><li style="margin-left: 12px"> <a href="#medical-devices">Medical Devices</a> </li><li style="margin-left: 12px"> <a href="#product-safety">Product Safety</a> </li><li style="margin-left: 12px"> <a href="#common-features">Common Features</a> </li><li style="margin-left: 0px"> <a href="#what-ai-certification-might-look-like">What AI Certification Might Look Like</a> </li><li style="margin-left: 12px"> <a href="#pre-deployment-assessment">Pre-Deployment Assessment</a> </li><li style="margin-left: 12px"> <a href="#deployment-approval">Deployment Approval</a> </li><li style="margin-left: 12px"> <a href="#ongoing-monitoring">Ongoing Monitoring</a> </li><li style="margin-left: 12px"> <a href="#tiered-approaches">Tiered Approaches</a> </li><li style="margin-left: 0px"> <a href="#potential-benefits">Potential Benefits</a> </li><li style="margin-left: 12px"> <a href="#quality-assurance">Quality Assurance</a> </li><li style="margin-left: 12px"> <a href="#liability-clarity">Liability Clarity</a> </li><li style="margin-left: 12px"> <a href="#public-trust">Public Trust</a> </li><li style="margin-left: 12px"> <a href="#level-playing-field">Level Playing Field</a> </li><li style="margin-left: 12px"> <a href="#market-development">Market Development</a> </li><li style="margin-left: 0px"> <a href="#significant-challenges">Significant Challenges</a> </li><li style="margin-left: 12px"> <a href="#what-would-be-certified">What Would Be Certified?</a> </li><li style="margin-left: 12px"> <a href="#against-what-standards">Against What Standards?</a> </li><li style="margin-left: 12px"> <a href="#how-would-testing-work">How Would Testing Work?</a> </li><li style="margin-left: 12px"> <a href="#post-deployment-drift">Post-Deployment Drift</a> </li><li style="margin-left: 12px"> <a href="#resource-requirements">Resource Requirements</a> </li><li style="margin-left: 12px"> <a href="#regulatory-capacity">Regulatory Capacity</a> </li><li style="margin-left: 12px"> <a href="#circumvention-risks">Circumvention Risks</a> </li><li style="margin-left: 0px"> <a href="#hybrid-approaches">Hybrid Approaches</a> </li><li style="margin-left: 12px"> <a href="#process-certification">Process Certification</a> </li><li style="margin-left: 12px"> <a href="#conformity-assessment">Conformity Assessment</a> </li><li style="margin-left: 12px"> <a href="#continuous-certification">Continuous Certification</a> </li><li style="margin-left: 12px"> <a href="#self-certification-with-accountability">Self-Certification with Accountability</a> </li><li style="margin-left: 0px"> <a href="#the-reflexive-dimension">The Reflexive Dimension</a> </li><li style="margin-left: 0px"> <a href="#recommendations">Recommendations</a> </li><li style="margin-left: 0px"> <a href="#conclusion">Conclusion</a> </li><li style="margin-left: 0px"> <a href="#further-reading">Further Reading</a> </li> </ul> </nav> </div> <div class="article__content">  <h2 id="the-certification-idea">The Certification Idea</h2>
<p>Many high-stakes technologies require certification before deployment. Aircraft must be certified as airworthy. Medical devices must receive regulatory approval. Electrical products must meet safety standards. These certification regimes ensure minimum safety before products reach users.</p>
<p>Could similar regimes work for AI? Advocates argue that certification could provide quality assurance, liability clarity, and public trust. Skeptics argue that AI’s distinctive characteristics make traditional certification approaches impractical.</p>
<p>This analysis examines what AI certification might look like, drawing lessons from existing regimes while acknowledging AI-specific challenges.</p>
<h2 id="how-certification-works-in-other-domains">How Certification Works in Other Domains</h2>
<p>Understanding existing certification regimes illuminates what AI certification might require.</p>
<h3 id="aviation">Aviation</h3>
<p>Aircraft certification is among the most rigorous:</p>
<ul>
<li><strong>Type certification:</strong> New aircraft designs undergo extensive evaluation against airworthiness standards</li>
<li><strong>Manufacturing certification:</strong> Production facilities must be certified for quality</li>
<li><strong>Individual certification:</strong> Each aircraft is inspected before operation</li>
<li><strong>Ongoing compliance:</strong> Continued airworthiness requires regular inspection and maintenance</li>
</ul>
<p>This regime is expensive and time-consuming—but has achieved remarkable safety records. We explored aviation’s lessons for AI in <a href="/research/021-aviation-lessons/">incident reporting systems</a>.</p>
<h3 id="medical-devices">Medical Devices</h3>
<p>Medical device certification varies by risk level:</p>
<ul>
<li><strong>Low-risk devices:</strong> Self-certification with registration</li>
<li><strong>Moderate-risk devices:</strong> Third-party conformity assessment</li>
<li><strong>High-risk devices:</strong> Regulatory approval with clinical data</li>
</ul>
<p>The process takes months to years and requires substantial evidence of safety and efficacy.</p>
<h3 id="product-safety">Product Safety</h3>
<p>Consumer products typically require:</p>
<ul>
<li>Conformity with published standards</li>
<li>Testing by accredited laboratories</li>
<li>Marking (CE, UL, etc.) indicating compliance</li>
</ul>
<p>This is less rigorous than aviation or medical devices but provides basic safety assurance.</p>
<h3 id="common-features">Common Features</h3>
<p>Across domains, certification typically includes:</p>
<ul>
<li><strong>Clear standards:</strong> Defined requirements that products must meet</li>
<li><strong>Testing:</strong> Evidence that requirements are met</li>
<li><strong>Third-party verification:</strong> Independent assessment, not just self-certification</li>
<li><strong>Documentation:</strong> Records enabling traceability</li>
<li><strong>Ongoing compliance:</strong> Requirements don’t end at initial certification</li>
<li><strong>Enforcement:</strong> Consequences for non-compliance or failure</li>
</ul>
<h2 id="what-ai-certification-might-look-like">What AI Certification Might Look Like</h2>
<p>Drawing on these models, AI certification could potentially include several elements.</p>
<h3 id="pre-deployment-assessment">Pre-Deployment Assessment</h3>
<p>Before deployment, AI systems could undergo assessment covering:</p>
<ul>
<li><strong>Capability evaluation:</strong> What can the system do? (connecting to our analysis of <a href="/research/024-capability-evaluations/">dangerous capability evaluations</a>)</li>
<li><strong>Risk assessment:</strong> What harms might occur?</li>
<li><strong>Testing:</strong> How does the system perform in controlled conditions?</li>
<li><strong>Documentation:</strong> Is there adequate documentation of training, architecture, and limitations?</li>
</ul>
<h3 id="deployment-approval">Deployment Approval</h3>
<p>Based on assessment, certification authorities could:</p>
<ul>
<li><strong>Approve:</strong> The system may be deployed as proposed</li>
<li><strong>Approve with conditions:</strong> Deployment permitted with restrictions</li>
<li><strong>Require modifications:</strong> Changes needed before deployment</li>
<li><strong>Reject:</strong> Deployment not permitted</li>
</ul>
<h3 id="ongoing-monitoring">Ongoing Monitoring</h3>
<p>Certification wouldn’t end at deployment. Requirements could include:</p>
<ul>
<li><strong>Performance monitoring:</strong> Tracking system behavior in real-world operation</li>
<li><strong>Incident reporting:</strong> Disclosing problems that emerge (as we examined in <a href="/research/021-aviation-lessons/">aviation lessons</a>)</li>
<li><strong>Recertification:</strong> Periodic reassessment, especially after significant changes</li>
<li><strong>Update approval:</strong> Changes to deployed systems require review</li>
</ul>
<h3 id="tiered-approaches">Tiered Approaches</h3>
<p>Not all AI applications warrant the same certification rigor. Tiered approaches could match scrutiny to risk:</p>
<ul>
<li><strong>Low-risk applications:</strong> Self-certification with registration</li>
<li><strong>Moderate-risk applications:</strong> Third-party assessment</li>
<li><strong>High-risk applications:</strong> Regulatory approval with extensive evidence</li>
</ul>
<p>The EU AI Act takes this approach, with different requirements for different risk levels.</p>
<h2 id="potential-benefits">Potential Benefits</h2>
<p>AI certification could provide significant benefits.</p>
<h3 id="quality-assurance">Quality Assurance</h3>
<p>Certification would establish minimum standards. Systems that pass would have demonstrated certain capabilities and safety properties. Users would have some confidence in certified systems.</p>
<h3 id="liability-clarity">Liability Clarity</h3>
<p>Certification could clarify liability. Systems that fail despite proper certification might place liability differently than systems that weren’t certified or that were deployed despite certification failures.</p>
<h3 id="public-trust">Public Trust</h3>
<p>Visible certification marks—like CE marking or FDA approval—could build public trust in AI systems. Users would know that certified systems had passed independent review.</p>
<h3 id="level-playing-field">Level Playing Field</h3>
<p>Certification requirements would apply equally to all covered systems. Responsible developers wouldn’t face competitive disadvantage from meeting higher standards.</p>
<h3 id="market-development">Market Development</h3>
<p>Clear certification requirements might actually accelerate AI adoption by providing assurance that currently-cautious users lack. Healthcare systems that won’t adopt uncertified AI might adopt certified systems.</p>
<h2 id="significant-challenges">Significant Challenges</h2>
<p>Despite potential benefits, AI certification faces significant challenges.</p>
<h3 id="what-would-be-certified">What Would Be Certified?</h3>
<p>Defining what gets certified is difficult. A foundation model? A fine-tuned version? A specific deployment? AI systems are often highly customizable—the same base model can be adapted for countless applications.</p>
<p>This differs fundamentally from physical products where certification applies to defined, manufactured goods.</p>
<h3 id="against-what-standards">Against What Standards?</h3>
<p>Certification requires clear standards. For AI, what standards would apply?</p>
<ul>
<li>Safety standards for AI are nascent</li>
<li>Capability thresholds are difficult to define</li>
<li>“Good enough” performance is context-dependent</li>
<li>Trade-offs between different properties (accuracy vs. explainability vs. privacy) require judgment</li>
</ul>
<p>We examined standards challenges in <a href="/research/039-standards-bodies/">the role of standards bodies</a>.</p>
<h3 id="how-would-testing-work">How Would Testing Work?</h3>
<p>Traditional certification testing involves defined tests against specifications. For AI:</p>
<ul>
<li>Systems may behave differently in deployment than in testing</li>
<li>Adversarial inputs can cause failures that standard testing misses</li>
<li>Rare but important situations are hard to test</li>
<li>Testing may not reveal the capabilities we identified in <a href="/research/009-capability-overhang/">capability overhang</a></li>
</ul>
<h3 id="post-deployment-drift">Post-Deployment Drift</h3>
<p>Certified products typically don’t change. AI systems may drift over time as they’re updated, fine-tuned, or exposed to changing data. What was certified at deployment may not match what’s operating later.</p>
<h3 id="resource-requirements">Resource Requirements</h3>
<p>Rigorous certification is expensive. Aviation certification costs millions; medical device approval takes years. Could AI certification achieve necessary rigor without imposing prohibitive costs, especially on smaller developers?</p>
<h3 id="regulatory-capacity">Regulatory Capacity</h3>
<p>Certification requires capable certifiers. Regulators would need technical expertise in AI that many currently lack. Third-party certifiers would need similar capacity. We explored related challenges in <a href="/research/018-regulation-is-hard/">why regulation is hard</a>.</p>
<h3 id="circumvention-risks">Circumvention Risks</h3>
<p>Certification could be circumvented:</p>
<ul>
<li>Deploying outside certified jurisdictions</li>
<li>Avoiding threshold for certification requirements</li>
<li>Modifying systems after certification</li>
<li>Misrepresenting system capabilities</li>
</ul>
<p>Enforcement would face significant challenges.</p>
<h2 id="hybrid-approaches">Hybrid Approaches</h2>
<p>Given these challenges, pure certification may be impractical. Hybrid approaches might be more viable.</p>
<h3 id="process-certification">Process Certification</h3>
<p>Rather than certifying specific systems, certify processes:</p>
<ul>
<li>Does the developer follow adequate risk management practices?</li>
<li>Are there appropriate testing procedures?</li>
<li>Is there ongoing monitoring?</li>
</ul>
<p>This resembles ISO management system certification more than product certification.</p>
<h3 id="conformity-assessment">Conformity Assessment</h3>
<p>Rather than binary approval, conformity assessment could provide graduated information:</p>
<ul>
<li>What tests did the system undergo?</li>
<li>What results were achieved?</li>
<li>What limitations were identified?</li>
</ul>
<p>Users could make informed decisions based on assessment rather than relying on binary certification.</p>
<h3 id="continuous-certification">Continuous Certification</h3>
<p>Rather than point-in-time certification, continuous monitoring could maintain ongoing compliance:</p>
<ul>
<li>Automated checking of deployed systems</li>
<li>Continuous performance monitoring</li>
<li>Triggered reassessment when anomalies appear</li>
</ul>
<p>This addresses post-deployment drift concerns.</p>
<h3 id="self-certification-with-accountability">Self-Certification with Accountability</h3>
<p>For lower-risk applications, require self-certification with:</p>
<ul>
<li>Published documentation</li>
<li>Mandatory disclosure of limitations</li>
<li>Strong liability for misrepresentation</li>
</ul>
<p>This provides some assurance without heavy regulatory infrastructure.</p>
<h2 id="the-reflexive-dimension">The Reflexive Dimension</h2>
<p>Our work on reflexive governance suggests additional possibilities.</p>
<p>AI systems could participate in their own certification:</p>
<ul>
<li><strong>Self-reporting:</strong> Systems report their capabilities and limitations (as we explored in <a href="/research/014-ai-regulator-protocol/">AI-to-regulator communication</a>)</li>
<li><strong>Constraint explanation:</strong> Systems explain what they’re designed to refuse (see <a href="/research/026-explaining-constraints/">explaining constraints</a>)</li>
<li><strong>Monitoring assistance:</strong> Systems help detect their own problems</li>
</ul>
<p>This wouldn’t replace external certification but could complement it. However, as we examined in <a href="/research/013-limits-of-self-constraint/">the limits of self-constraint</a>, self-reporting has inherent limitations.</p>
<h2 id="recommendations">Recommendations</h2>
<p>Based on this analysis, AI certification should:</p>
<p><strong>Start with high-risk applications.</strong> Focus initial certification requirements on applications where harms are most serious and certification benefits most justified.</p>
<p><strong>Emphasize process over products.</strong> Given AI’s adaptability, certify processes for responsible development and deployment rather than specific system versions.</p>
<p><strong>Build incrementally.</strong> Develop certification capacity over time rather than attempting comprehensive regimes immediately.</p>
<p><strong>Invest in regulatory capacity.</strong> Certification is only as good as the certifiers. Significant investment in regulatory expertise is required.</p>
<p><strong>Combine mechanisms.</strong> Certification alone won’t solve AI governance. Integrate with liability, monitoring, and other governance mechanisms.</p>
<p><strong>Maintain adaptability.</strong> Whatever certification approaches emerge, they must be able to evolve as AI capabilities and understanding change.</p>
<h2 id="conclusion">Conclusion</h2>
<p>AI certification offers potential benefits but faces significant challenges. Pure certification models from other domains don’t translate directly. Hybrid approaches—emphasizing process, continuous monitoring, and graduated assessment—may be more practical.</p>
<p>Certification should be part of AI governance but cannot be the whole of it. Building effective certification will require sustained investment, experimentation, and adaptation.</p>
<h2 id="further-reading">Further Reading</h2>
<ul>
<li><a href="/research/024-capability-evaluations/">Dangerous Capability Evaluations</a></li>
<li><a href="/research/021-aviation-lessons/">Incident Reporting Systems: Lessons from Aviation</a></li>
<li><a href="/research/039-standards-bodies/">The Role of Standards Bodies in AI Governance</a></li>
<li><a href="/research/010-self-reporting-vs-audit/">Self-Reporting vs. External Audit: Trade-offs</a></li>
</ul>  </div> <footer class="article__footer" style="margin-top: var(--space-12); padding-top: var(--space-6); border-top: 1px solid var(--color-border);"> <div class="article-card__meta"> <a href="/tags" class="article-card__tag">regulation</a><a href="/tags" class="article-card__tag">standards</a><a href="/tags" class="article-card__tag">safety</a><a href="/tags" class="article-card__tag">deployment</a> </div> </footer> </article>  <aside class="toc-sidebar" id="toc-sidebar"> <div class="toc-sidebar__inner"> <div class="toc-sidebar__header"> <span class="toc-sidebar__title">On This Page</span> <button class="toc-sidebar__toggle" aria-label="Toggle table of contents" onclick="document.getElementById('toc-sidebar').classList.toggle('collapsed');"> <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M4 6L8 10L12 6" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </button> </div> <ul class="toc-sidebar__list"> <li style="margin-left: 0px"> <a href="#the-certification-idea">The Certification Idea</a> </li><li style="margin-left: 0px"> <a href="#how-certification-works-in-other-domains">How Certification Works in Other Domains</a> </li><li style="margin-left: 12px"> <a href="#aviation">Aviation</a> </li><li style="margin-left: 12px"> <a href="#medical-devices">Medical Devices</a> </li><li style="margin-left: 12px"> <a href="#product-safety">Product Safety</a> </li><li style="margin-left: 12px"> <a href="#common-features">Common Features</a> </li><li style="margin-left: 0px"> <a href="#what-ai-certification-might-look-like">What AI Certification Might Look Like</a> </li><li style="margin-left: 12px"> <a href="#pre-deployment-assessment">Pre-Deployment Assessment</a> </li><li style="margin-left: 12px"> <a href="#deployment-approval">Deployment Approval</a> </li><li style="margin-left: 12px"> <a href="#ongoing-monitoring">Ongoing Monitoring</a> </li><li style="margin-left: 12px"> <a href="#tiered-approaches">Tiered Approaches</a> </li><li style="margin-left: 0px"> <a href="#potential-benefits">Potential Benefits</a> </li><li style="margin-left: 12px"> <a href="#quality-assurance">Quality Assurance</a> </li><li style="margin-left: 12px"> <a href="#liability-clarity">Liability Clarity</a> </li><li style="margin-left: 12px"> <a href="#public-trust">Public Trust</a> </li><li style="margin-left: 12px"> <a href="#level-playing-field">Level Playing Field</a> </li><li style="margin-left: 12px"> <a href="#market-development">Market Development</a> </li><li style="margin-left: 0px"> <a href="#significant-challenges">Significant Challenges</a> </li><li style="margin-left: 12px"> <a href="#what-would-be-certified">What Would Be Certified?</a> </li><li style="margin-left: 12px"> <a href="#against-what-standards">Against What Standards?</a> </li><li style="margin-left: 12px"> <a href="#how-would-testing-work">How Would Testing Work?</a> </li><li style="margin-left: 12px"> <a href="#post-deployment-drift">Post-Deployment Drift</a> </li><li style="margin-left: 12px"> <a href="#resource-requirements">Resource Requirements</a> </li><li style="margin-left: 12px"> <a href="#regulatory-capacity">Regulatory Capacity</a> </li><li style="margin-left: 12px"> <a href="#circumvention-risks">Circumvention Risks</a> </li><li style="margin-left: 0px"> <a href="#hybrid-approaches">Hybrid Approaches</a> </li><li style="margin-left: 12px"> <a href="#process-certification">Process Certification</a> </li><li style="margin-left: 12px"> <a href="#conformity-assessment">Conformity Assessment</a> </li><li style="margin-left: 12px"> <a href="#continuous-certification">Continuous Certification</a> </li><li style="margin-left: 12px"> <a href="#self-certification-with-accountability">Self-Certification with Accountability</a> </li><li style="margin-left: 0px"> <a href="#the-reflexive-dimension">The Reflexive Dimension</a> </li><li style="margin-left: 0px"> <a href="#recommendations">Recommendations</a> </li><li style="margin-left: 0px"> <a href="#conclusion">Conclusion</a> </li><li style="margin-left: 0px"> <a href="#further-reading">Further Reading</a> </li> </ul> </div> </aside> </div> <div class="scroll-progress" id="scroll-progress"></div> <script type="module">const s=document.getElementById("scroll-progress");s&&window.addEventListener("scroll",()=>{const o=window.scrollY,e=document.documentElement.scrollHeight-window.innerHeight,t=o/e*100;s.style.width=`${t}%`});const r=document.querySelectorAll(".toc-sidebar__list a"),n=document.querySelectorAll(".article__content h2, .article__content h3");if(r.length>0&&n.length>0){const o=new IntersectionObserver(e=>{e.forEach(t=>{if(t.isIntersecting){r.forEach(i=>i.classList.remove("active"));const c=document.querySelector(`.toc-sidebar__list a[href="#${t.target.id}"]`);c&&c.classList.add("active")}})},{rootMargin:"-20% 0% -60% 0%"});n.forEach(e=>o.observe(e))}</script>  </main> <footer class="footer"> <div class="container footer__inner"> <a href="/" class="footer__brand"> <img src="/logo.png" alt="" class="footer__logo"> <span>Reflexive AI Initiative</span> </a> <div class="footer__links"> <a href="https://github.com/Reflexive-AI" class="footer__link" target="_blank" rel="noopener">GitHub</a> <a href="/research" class="footer__link">Research</a> <a href="/tags" class="footer__link">Tags</a> <a href="/contribute" class="footer__link">Contribute</a> </div> <div class="footer__meta"> <span>Maintained by <a href="https://eugenekondratov.eu" target="_blank" rel="noopener">Eugene Kondratov</a></span> <span>·</span> <a href="https://creativecommons.org/licenses/by/4.0/" class="footer__license" target="_blank" rel="noopener">CC BY 4.0</a> </div> </div> </footer> </body></html>