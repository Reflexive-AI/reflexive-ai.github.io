<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Compute is one of the few measurable inputs to AI development. Governing at the compute layer is appealing but faces significant challenges. An honest assessment."><meta name="generator" content="Astro v5.17.1"><!-- Fonts --><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Source+Serif+4:ital,wght@0,400;0,500;0,600;1,400&display=swap" rel="stylesheet"><!-- Favicon --><link rel="icon" type="image/png" href="/logo.png"><!-- Open Graph --><meta property="og:title" content="Compute Governance: Promises and Limits | Reflexive AI Initiative"><meta property="og:description" content="Compute is one of the few measurable inputs to AI development. Governing at the compute layer is appealing but faces significant challenges. An honest assessment."><meta property="og:type" content="website"><meta property="og:site_name" content="Reflexive AI Initiative"><title>Compute Governance: Promises and Limits | Reflexive AI Initiative</title><link rel="stylesheet" href="/_astro/_slug_.BtA_RPCv.css"></head> <body>  <header class="header"> <div class="container header__inner"> <a href="/" class="header__brand"> <img src="/logo.png" alt="" class="header__logo"> <div> <span class="header__title">Reflexive AI</span> <span class="header__tagline">Governance · Reflexivity · Constraint</span> </div> </a> <nav class="header__nav"> <a href="/about" class="header__link">About</a> <a href="/research" class="header__link">Research</a> <a href="/contribute" class="header__link">Contribute</a> </nav> </div> </header>  <main>  <div class="article-layout"> <article class="article"> <header class="article__header"> <div class="article__meta"> <a href="/research" class="article__category">Technical Analysis</a><a href="/research" class="article__category">Governance Analysis</a> <span>·</span> <time datetime="2026-01-05T00:00:00.000Z"> January 5, 2026 </time> </div> <h1 class="article__title">Compute Governance: Promises and Limits</h1> <p class="article__excerpt">Compute is one of the few measurable inputs to AI development. Governing at the compute layer is appealing but faces significant challenges. An honest assessment.</p> </header>  <div class="toc-mobile"> <button class="toc-mobile__button" aria-expanded="false" onclick="this.setAttribute('aria-expanded', this.getAttribute('aria-expanded') === 'true' ? 'false' : 'true'); this.nextElementSibling.classList.toggle('open');"> <span>On This Page</span> <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M4 6L8 10L12 6" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </button> <nav class="toc-mobile__content"> <ul class="toc-mobile__list"> <li style="margin-left: 0px"> <a href="#the-appeal-of-compute">The Appeal of Compute</a> </li><li style="margin-left: 0px"> <a href="#what-compute-governance-can-do">What Compute Governance Can Do</a> </li><li style="margin-left: 12px"> <a href="#visibility">Visibility</a> </li><li style="margin-left: 12px"> <a href="#choke-points">Choke Points</a> </li><li style="margin-left: 12px"> <a href="#enforcement-mechanism">Enforcement Mechanism</a> </li><li style="margin-left: 12px"> <a href="#threshold-triggers">Threshold Triggers</a> </li><li style="margin-left: 0px"> <a href="#the-limits">The Limits</a> </li><li style="margin-left: 12px"> <a href="#compute-is-a-proxy">Compute Is a Proxy</a> </li><li style="margin-left: 12px"> <a href="#the-threshold-problem">The Threshold Problem</a> </li><li style="margin-left: 12px"> <a href="#distributed-training">Distributed Training</a> </li><li style="margin-left: 12px"> <a href="#gaming-and-evasion">Gaming and Evasion</a> </li><li style="margin-left: 12px"> <a href="#cloud-vs-on-premises">Cloud vs. On-Premises</a> </li><li style="margin-left: 12px"> <a href="#international-coordination">International Coordination</a> </li><li style="margin-left: 12px"> <a href="#inference-vs-training">Inference vs. Training</a> </li><li style="margin-left: 0px"> <a href="#a-realistic-assessment">A Realistic Assessment</a> </li><li style="margin-left: 0px"> <a href="#conclusion">Conclusion</a> </li><li style="margin-left: 0px"> <a href="#related-research">Related Research</a> </li> </ul> </nav> </div> <div class="article__content">  <h2 id="the-appeal-of-compute">The Appeal of Compute</h2>
<p>Of the three inputs to modern AI—data, algorithms, and compute—compute is the most measurable. Training runs can be quantified in FLOPs. GPU clusters can be counted. Energy consumption can be monitored.</p>
<p>This measurability makes compute an attractive target for governance. Instead of trying to regulate intangible capabilities or ambiguous behaviors, regulate the physical resources that enable them. Know where large training runs are happening. Require notification above certain thresholds. Perhaps even license access to frontier-scale compute.</p>
<p>The appeal is understandable. AI governance struggles with the difficulty of measuring and verifying capabilities—a challenge we explored in <a href="/research/009-capability-overhang/">the capability overhang problem</a>. Compute offers something governance usually lacks: a concrete, quantifiable input.</p>
<p>But compute governance also has significant limitations. This analysis examines both the promise and the limits.</p>
<h2 id="what-compute-governance-can-do">What Compute Governance Can Do</h2>
<p>Compute governance can serve several legitimate purposes.</p>
<h3 id="visibility">Visibility</h3>
<p>Governments currently have limited insight into who is training large AI models. Compute monitoring provides visibility. Requirements to register large training runs, or to notify regulators when compute usage exceeds thresholds, create awareness of frontier development activity.</p>
<p>This visibility has intrinsic value. Governance is impossible if regulators don’t know what’s happening. Even if compute monitoring doesn’t restrict development, it enables other governance mechanisms by revealing who is developing what.</p>
<h3 id="choke-points">Choke Points</h3>
<p>The supply chain for advanced AI compute is concentrated. Only a few companies manufacture cutting-edge GPUs. Only a few cloud providers offer large-scale AI infrastructure. These choke points enable governance interventions that would be impossible for more distributed resources.</p>
<p>Export controls on advanced chips are already an example of compute governance. By restricting chip flows to certain countries or entities, governments can influence who has access to frontier AI development resources.</p>
<h3 id="enforcement-mechanism">Enforcement Mechanism</h3>
<p>Compute requirements create an enforcement lever. If other AI regulations are violated, compute access can be restricted. Cloud providers can be required to verify that customers meet regulatory requirements before providing frontier-scale resources.</p>
<p>This mirrors how financial regulations use banking access as an enforcement mechanism. Entities that violate rules lose access to the financial system. Similarly, entities that violate AI safety requirements might lose access to compute.</p>
<h3 id="threshold-triggers">Threshold Triggers</h3>
<p>Compute thresholds can trigger additional oversight requirements. The EU AI Act, for example, uses training compute (along with other criteria) to identify foundation models requiring heightened obligations.</p>
<p>This is a form of the proportionality principle we explored in <a href="/research/001-proportionality-disclosure/">proportionality in model disclosure</a>—more capable systems face more intensive governance.</p>
<h2 id="the-limits">The Limits</h2>
<p>Compute governance is appealing but not sufficient. Several limitations constrain what it can achieve.</p>
<h3 id="compute-is-a-proxy">Compute Is a Proxy</h3>
<p>Compute is a proxy for capability, not capability itself. The correlation between compute and capability is imperfect and changing.</p>
<p>Algorithmic improvements can achieve the same capabilities with less compute. Fine-tuning and scaffolding can amplify base model capabilities without additional training compute. Inference-time compute can unlock capabilities that pure training didn’t produce.</p>
<p>A governance regime calibrated to training compute thresholds may miss dangerous capabilities achieved through algorithmic innovation or novel architectures. Worse, it may create incentives for exactly these compute-efficient approaches, pushing development in directions that are harder to monitor.</p>
<h3 id="the-threshold-problem">The Threshold Problem</h3>
<p>Any compute-based threshold will be arbitrary. Why 10^25 FLOPs and not 10^24 or 10^26? The relationship between compute and risk is not a step function with a clear break point.</p>
<p>Thresholds that are too low capture many low-risk systems, creating compliance burden without safety benefit. Thresholds that are too high miss dangerous systems that fall just below. And any fixed threshold becomes outdated as algorithmic efficiency improves.</p>
<h3 id="distributed-training">Distributed Training</h3>
<p>Large training runs have historically required concentrated compute—massive GPU clusters in single locations. This concentration enables monitoring.</p>
<p>But distributed training techniques are improving. Training across multiple data centers, or even across many smaller facilities, becomes more feasible. If training can be distributed enough, concentration-based monitoring becomes ineffective.</p>
<p>The trend toward distributed approaches may be driven by efficiency considerations rather than governance evasion, but the effect on governability is the same.</p>
<h3 id="gaming-and-evasion">Gaming and Evasion</h3>
<p>Entities seeking to evade compute-based governance have options.</p>
<p>Multiple smaller training runs that individually fall below thresholds can be combined in various ways. Fine-tuning approaches can build on publicly available base models, with the fine-tuning step falling below thresholds even if the effective capability is high. Training can be moved to jurisdictions with less oversight.</p>
<p>Some evasion is technically difficult. Others are trivial. Governance that relies heavily on compute thresholds invites gaming by sophisticated actors.</p>
<h3 id="cloud-vs-on-premises">Cloud vs. On-Premises</h3>
<p>Compute governance is much easier for cloud-based training than for on-premises. Cloud providers can be regulated as intermediaries, required to know their customers and enforce requirements.</p>
<p>On-premises compute is harder to monitor. Large organizations can purchase and operate their own GPU clusters without intermediary oversight. Export controls can restrict acquisition, but once hardware is in place, usage is difficult to observe.</p>
<p>The trend toward proprietary compute infrastructure, driven partly by supply chain concerns, complicates governance that assumes cloud-mediated access.</p>
<h3 id="international-coordination">International Coordination</h3>
<p>Compute governance requires international coordination to be effective. If one jurisdiction imposes restrictions, development can move elsewhere. If export controls limit chip access for some countries, alternative supply chains may develop.</p>
<p>Current coordination is limited. The US has imposed export controls unilaterally; other countries have not necessarily followed. Compute installed before controls remains usable. And the global distribution of training data means that restricting compute doesn’t restrict all inputs to AI development.</p>
<p>We explored related dynamics in <a href="/research/008-regulatory-arbitrage/">regulatory arbitrage</a>. AI development seeks paths of least resistance, and compute governance creates incentives to find those paths.</p>
<h3 id="inference-vs-training">Inference vs. Training</h3>
<p>Compute governance typically focuses on training—the phase where models are created. But inference—running trained models—may also be relevant to governance.</p>
<p>Dangerous capabilities exist at inference time, not training time. A model that can assist with harmful tasks does so when queried, regardless of when or where it was trained. Governing training compute doesn’t address inference-time risks.</p>
<p>Governing inference compute is much harder. Inference is distributed, occurs at smaller scale per interaction, and involves many more actors. The governance approaches that work for concentrated training don’t translate to distributed inference.</p>
<h2 id="a-realistic-assessment">A Realistic Assessment</h2>
<p>Compute governance is useful but insufficient. It provides visibility into frontier development, creates enforcement levers, and can trigger proportional oversight for large training runs.</p>
<p>But it cannot be the sole or primary mechanism for AI safety governance. Compute thresholds are proxies that will become less accurate over time. Evasion is possible. Inference-time risks are not addressed. International coordination is limited.</p>
<p>Compute governance should be part of a layered approach that includes:</p>
<ul>
<li><strong>Capability-based evaluation</strong> to assess what systems can actually do, regardless of how much compute was used to create them</li>
<li><strong>Behavioral monitoring</strong> at inference time to detect concerning patterns</li>
<li><strong>Reflexive mechanisms</strong> where systems themselves participate in governance, as we’ve explored in <a href="/research/011-reflexive-misuse-detection/">reflexive misuse detection</a></li>
<li><strong>Supply chain governance</strong> that addresses fine-tuning, scaffolding, and other capability amplification</li>
<li><strong>International coordination</strong> to limit arbitrage</li>
</ul>
<p>Compute governance is a valuable component of this layered approach. It is not a substitute for other governance mechanisms.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Compute’s measurability makes it attractive for governance in a domain where most things are hard to measure. But measurability is not the same as sufficiency. Compute governance can provide visibility and enforcement levers, but cannot by itself ensure AI safety.</p>
<p>The most dangerous AI development scenarios might involve exactly the compute-efficient approaches that slip through compute-based thresholds. Governance that relies too heavily on compute creates incentives for these approaches.</p>
<p>Effective AI governance must address capabilities, behaviors, and deployments—not just inputs. Compute governance is a useful tool in the governance toolkit. It is not a complete solution.</p>
<h2 id="related-research">Related Research</h2>
<ul>
<li><a href="/research/009-capability-overhang/">The Capability Overhang Problem</a></li>
<li><a href="/research/001-proportionality-disclosure/">Proportionality in Model Disclosure</a></li>
<li><a href="/research/008-regulatory-arbitrage/">Regulatory Arbitrage in AI Deployment</a></li>
<li><a href="/research/011-reflexive-misuse-detection/">Can AI Systems Detect Their Own Misuse?</a></li>
</ul>  </div> <footer class="article__footer" style="margin-top: var(--space-12); padding-top: var(--space-6); border-top: 1px solid var(--color-border);"> <div class="article-card__meta"> <a href="/tags" class="article-card__tag">compute</a><a href="/tags" class="article-card__tag">governance</a><a href="/tags" class="article-card__tag">regulation</a><a href="/tags" class="article-card__tag">safety</a><a href="/tags" class="article-card__tag">enforcement</a> </div> </footer> </article>  <aside class="toc-sidebar" id="toc-sidebar"> <div class="toc-sidebar__inner"> <div class="toc-sidebar__header"> <span class="toc-sidebar__title">On This Page</span> <button class="toc-sidebar__toggle" aria-label="Toggle table of contents" onclick="document.getElementById('toc-sidebar').classList.toggle('collapsed');"> <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M4 6L8 10L12 6" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </button> </div> <ul class="toc-sidebar__list"> <li style="margin-left: 0px"> <a href="#the-appeal-of-compute">The Appeal of Compute</a> </li><li style="margin-left: 0px"> <a href="#what-compute-governance-can-do">What Compute Governance Can Do</a> </li><li style="margin-left: 12px"> <a href="#visibility">Visibility</a> </li><li style="margin-left: 12px"> <a href="#choke-points">Choke Points</a> </li><li style="margin-left: 12px"> <a href="#enforcement-mechanism">Enforcement Mechanism</a> </li><li style="margin-left: 12px"> <a href="#threshold-triggers">Threshold Triggers</a> </li><li style="margin-left: 0px"> <a href="#the-limits">The Limits</a> </li><li style="margin-left: 12px"> <a href="#compute-is-a-proxy">Compute Is a Proxy</a> </li><li style="margin-left: 12px"> <a href="#the-threshold-problem">The Threshold Problem</a> </li><li style="margin-left: 12px"> <a href="#distributed-training">Distributed Training</a> </li><li style="margin-left: 12px"> <a href="#gaming-and-evasion">Gaming and Evasion</a> </li><li style="margin-left: 12px"> <a href="#cloud-vs-on-premises">Cloud vs. On-Premises</a> </li><li style="margin-left: 12px"> <a href="#international-coordination">International Coordination</a> </li><li style="margin-left: 12px"> <a href="#inference-vs-training">Inference vs. Training</a> </li><li style="margin-left: 0px"> <a href="#a-realistic-assessment">A Realistic Assessment</a> </li><li style="margin-left: 0px"> <a href="#conclusion">Conclusion</a> </li><li style="margin-left: 0px"> <a href="#related-research">Related Research</a> </li> </ul> </div> </aside> </div> <div class="scroll-progress" id="scroll-progress"></div> <script type="module">const s=document.getElementById("scroll-progress");s&&window.addEventListener("scroll",()=>{const o=window.scrollY,e=document.documentElement.scrollHeight-window.innerHeight,t=o/e*100;s.style.width=`${t}%`});const r=document.querySelectorAll(".toc-sidebar__list a"),n=document.querySelectorAll(".article__content h2, .article__content h3");if(r.length>0&&n.length>0){const o=new IntersectionObserver(e=>{e.forEach(t=>{if(t.isIntersecting){r.forEach(i=>i.classList.remove("active"));const c=document.querySelector(`.toc-sidebar__list a[href="#${t.target.id}"]`);c&&c.classList.add("active")}})},{rootMargin:"-20% 0% -60% 0%"});n.forEach(e=>o.observe(e))}</script>  </main> <footer class="footer"> <div class="container footer__inner"> <a href="/" class="footer__brand"> <img src="/logo.png" alt="" class="footer__logo"> <span>Reflexive AI Initiative</span> </a> <div class="footer__links"> <a href="https://github.com/Reflexive-AI" class="footer__link" target="_blank" rel="noopener">GitHub</a> <a href="/research" class="footer__link">Research</a> <a href="/tags" class="footer__link">Tags</a> <a href="/contribute" class="footer__link">Contribute</a> </div> <div class="footer__meta"> <span>Maintained by <a href="https://eugenekondratov.eu" target="_blank" rel="noopener">Eugene Kondratov</a></span> <span>·</span> <a href="https://creativecommons.org/licenses/by/4.0/" class="footer__license" target="_blank" rel="noopener">CC BY 4.0</a> </div> </div> </footer> </body></html>