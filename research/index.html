<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="All research articles from the Reflexive AI Initiative"><meta name="generator" content="Astro v5.17.1"><!-- Fonts --><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Source+Serif+4:ital,wght@0,400;0,500;0,600;1,400&display=swap" rel="stylesheet"><!-- Favicon --><link rel="icon" type="image/png" href="/logo.png"><!-- Open Graph --><meta property="og:title" content="Research | Reflexive AI Initiative"><meta property="og:description" content="All research articles from the Reflexive AI Initiative"><meta property="og:type" content="website"><meta property="og:site_name" content="Reflexive AI Initiative"><title>Research | Reflexive AI Initiative</title><link rel="stylesheet" href="/_astro/_slug_.BtA_RPCv.css"></head> <body>  <header class="header"> <div class="container header__inner"> <a href="/" class="header__brand"> <img src="/logo.png" alt="" class="header__logo"> <div> <span class="header__title">Reflexive AI</span> <span class="header__tagline">Governance · Reflexivity · Constraint</span> </div> </a> <nav class="header__nav"> <a href="/about" class="header__link">About</a> <a href="/research" class="header__link">Research</a> <a href="/contribute" class="header__link">Contribute</a> </nav> </div> </header>  <main>  <div class="container" style="padding: var(--space-12) var(--space-6);"> <header style="margin-bottom: var(--space-10);"> <h1>Research</h1> <p class="text-secondary" style="font-size: 1.2rem; max-width: 60ch;"> 51 articles exploring AI governance, safety, and the role of 
        AI systems in their own regulation.
</p> </header> <div class="article-grid"> <article class="article-card"> <span class="article-card__number">#051</span> <h3 class="article-card__title"> <a href="/research/051-interpretability-as-a-governance-tool">Interpretability as a Governance Tool</a> </h3> <p class="article-card__excerpt">How interpretability methods supply evidence for AI oversight: approvals, audits, monitoring, and incident response.</p> <div class="article-card__meta"> <span class="article-card__tag">Interpretability</span><span class="article-card__tag">Transparency</span><span class="article-card__tag">Governance</span> </div> </article><article class="article-card"> <span class="article-card__number">#050</span> <h3 class="article-card__title"> <a href="/research/050-red-teaming-methodologies">Red Teaming Methodologies</a> </h3> <p class="article-card__excerpt">Structured approaches to adversarial testing of AI systems, from scope definition through remediation verification.</p> <div class="article-card__meta"> <span class="article-card__tag">Red Teaming</span><span class="article-card__tag">Security</span><span class="article-card__tag">Safety</span> </div> </article><article class="article-card"> <span class="article-card__number">#049</span> <h3 class="article-card__title"> <a href="/research/049-model-evaluation-standards">Model Evaluation Standards: Current State</a> </h3> <p class="article-card__excerpt">A survey of existing standards and practices for evaluating AI model performance, safety, and fitness for deployment.</p> <div class="article-card__meta"> <span class="article-card__tag">Evaluation</span><span class="article-card__tag">Standards</span><span class="article-card__tag">Benchmarks</span> </div> </article><article class="article-card"> <span class="article-card__number">#048</span> <h3 class="article-card__title"> <a href="/research/048-training-data-governance">Training Data Governance</a> </h3> <p class="article-card__excerpt">Comprehensive frameworks for managing the data that shapes AI systems, from collection through curation to retirement.</p> <div class="article-card__meta"> <span class="article-card__tag">Data Governance</span><span class="article-card__tag">Training Data</span><span class="article-card__tag">Privacy</span> </div> </article><article class="article-card"> <span class="article-card__number">#047</span> <h3 class="article-card__title"> <a href="/research/047-pre-deployment-risk-assessment">Pre-Deployment Risk Assessment Frameworks</a> </h3> <p class="article-card__excerpt">Structured approaches to evaluating AI system risks before release, balancing comprehensiveness with practical constraints.</p> <div class="article-card__meta"> <span class="article-card__tag">Risk Assessment</span><span class="article-card__tag">Deployment</span><span class="article-card__tag">Safety</span> </div> </article><article class="article-card"> <span class="article-card__number">#046</span> <h3 class="article-card__title"> <a href="/research/046-algorithmic-impact-assessments">Algorithmic Impact Assessments: Implementation Guide</a> </h3> <p class="article-card__excerpt">A practical framework for conducting meaningful algorithmic impact assessments that move beyond checkbox compliance to genuine harm prevention.</p> <div class="article-card__meta"> <span class="article-card__tag">Impact Assessment</span><span class="article-card__tag">Risk Governance</span><span class="article-card__tag">Implementation</span> </div> </article><article class="article-card"> <span class="article-card__number">#045</span> <h3 class="article-card__title"> <a href="/research/045-public-participation">Public Participation in AI Policy</a> </h3> <p class="article-card__excerpt">How can ordinary citizens meaningfully participate in decisions about AI that will affect their lives? An examination of mechanisms for democratic AI governance.</p> <div class="article-card__meta"> <span class="article-card__tag">governance</span><span class="article-card__tag">policy</span><span class="article-card__tag">ethics</span> </div> </article><article class="article-card"> <span class="article-card__number">#044</span> <h3 class="article-card__title"> <a href="/research/044-civil-society-role">The Role of Civil Society in AI Governance</a> </h3> <p class="article-card__excerpt">Beyond companies and regulators: how civil society organizations contribute to AI governance, and how their role could be strengthened.</p> <div class="article-card__meta"> <span class="article-card__tag">governance</span><span class="article-card__tag">transparency</span><span class="article-card__tag">policy</span> </div> </article><article class="article-card"> <span class="article-card__number">#043</span> <h3 class="article-card__title"> <a href="/research/043-board-oversight">Board-Level AI Oversight: Best Practices</a> </h3> <p class="article-card__excerpt">Boards of directors increasingly need to oversee AI strategy and risk. A practical guide to what effective board-level AI oversight looks like.</p> <div class="article-card__meta"> <span class="article-card__tag">governance</span><span class="article-card__tag">institutional-design</span><span class="article-card__tag">safety</span> </div> </article><article class="article-card"> <span class="article-card__number">#042</span> <h3 class="article-card__title"> <a href="/research/042-corporate-governance">Corporate Governance Structures for AI Safety</a> </h3> <p class="article-card__excerpt">How companies organize to manage AI safety matters as much as what rules they follow. An examination of governance structures that enable—or undermine—responsible AI development.</p> <div class="article-card__meta"> <span class="article-card__tag">governance</span><span class="article-card__tag">safety</span><span class="article-card__tag">institutional-design</span> </div> </article><article class="article-card"> <span class="article-card__number">#041</span> <h3 class="article-card__title"> <a href="/research/041-certification-regimes">Certification Regimes for AI Systems</a> </h3> <p class="article-card__excerpt">Could AI systems be certified for safety like aircraft or medical devices? An analysis of what AI certification might look like, its benefits, and significant challenges.</p> <div class="article-card__meta"> <span class="article-card__tag">regulation</span><span class="article-card__tag">standards</span><span class="article-card__tag">safety</span> </div> </article><article class="article-card"> <span class="article-card__number">#040</span> <h3 class="article-card__title"> <a href="/research/040-soft-law-hard-law">Soft Law vs. Hard Law in AI Regulation</a> </h3> <p class="article-card__excerpt">AI governance uses both binding legislation and non-binding guidelines. An analysis of when each approach works, their tradeoffs, and how they interact.</p> <div class="article-card__meta"> <span class="article-card__tag">regulation</span><span class="article-card__tag">governance</span><span class="article-card__tag">policy</span> </div> </article><article class="article-card"> <span class="article-card__number">#039</span> <h3 class="article-card__title"> <a href="/research/039-standards-bodies">The Role of Standards Bodies in AI Governance</a> </h3> <p class="article-card__excerpt">Technical standards organizations may shape AI governance as much as legislation. An examination of who sets AI standards, how standards work, and their governance implications.</p> <div class="article-card__meta"> <span class="article-card__tag">standards</span><span class="article-card__tag">governance</span><span class="article-card__tag">regulation</span> </div> </article><article class="article-card"> <span class="article-card__number">#038</span> <h3 class="article-card__title"> <a href="/research/038-international-treaties">International AI Treaty Proposals: A Comparative Analysis</a> </h3> <p class="article-card__excerpt">From the Bletchley Declaration to proposed AI treaties: analyzing what international agreements on AI governance have been proposed, what they would achieve, and their prospects.</p> <div class="article-card__meta"> <span class="article-card__tag">regulation</span><span class="article-card__tag">governance</span><span class="article-card__tag">policy</span> </div> </article><article class="article-card"> <span class="article-card__number">#037</span> <h3 class="article-card__title"> <a href="/research/037-sandboxing-approaches">Sandboxing Approaches: What Works</a> </h3> <p class="article-card__excerpt">Regulatory sandboxes for AI allow experimentation under controlled conditions. An analysis of existing approaches, what makes them effective, and their limitations.</p> <div class="article-card__meta"> <span class="article-card__tag">regulation</span><span class="article-card__tag">governance</span><span class="article-card__tag">deployment</span> </div> </article><article class="article-card"> <span class="article-card__number">#036</span> <h3 class="article-card__title"> <a href="/research/036-insurance-markets">Insurance Markets and AI Risk Pricing</a> </h3> <p class="article-card__excerpt">How insurance markets could help govern AI by pricing risk, incentivizing safety, and providing accountability. An analysis of possibilities and limitations.</p> <div class="article-card__meta"> <span class="article-card__tag">liability</span><span class="article-card__tag">risk-assessment</span><span class="article-card__tag">governance</span> </div> </article><article class="article-card"> <span class="article-card__number">#035</span> <h3 class="article-card__title"> <a href="/research/035-dual-use-biology">Dual-Use AI: The Biological Research Case</a> </h3> <p class="article-card__excerpt">How AI is transforming biological research—and why the same capabilities that could cure diseases could enable bioweapons. A case study in dual-use governance.</p> <div class="article-card__meta"> <span class="article-card__tag">dual-use</span><span class="article-card__tag">cbrn</span><span class="article-card__tag">safety</span> </div> </article><article class="article-card"> <span class="article-card__number">#034</span> <h3 class="article-card__title"> <a href="/research/034-technical-vs-societal-safety">Technical Safety vs. Societal Safety: Different Problems</a> </h3> <p class="article-card__excerpt">Why making AI systems work as intended is a different challenge from making AI development good for society—and why confusing them leads to poor governance.</p> <div class="article-card__meta"> <span class="article-card__tag">safety</span><span class="article-card__tag">alignment</span><span class="article-card__tag">governance</span> </div> </article><article class="article-card"> <span class="article-card__number">#033</span> <h3 class="article-card__title"> <a href="/research/033-policymaker-misconceptions">What Policymakers Get Wrong About AI Risk</a> </h3> <p class="article-card__excerpt">Common misconceptions that lead to ineffective AI policy, and how to think more clearly about the actual risks posed by advanced AI systems.</p> <div class="article-card__meta"> <span class="article-card__tag">policy</span><span class="article-card__tag">risk-assessment</span><span class="article-card__tag">governance</span> </div> </article><article class="article-card"> <span class="article-card__number">#032</span> <h3 class="article-card__title"> <a href="/research/032-history-of-ai-governance">The History of AI Governance in 2000 Words</a> </h3> <p class="article-card__excerpt">From Asimov&#39;s Laws to the EU AI Act: how thinking about governing artificial intelligence has evolved over eight decades.</p> <div class="article-card__meta"> <span class="article-card__tag">governance</span><span class="article-card__tag">regulation</span><span class="article-card__tag">policy</span> </div> </article><article class="article-card"> <span class="article-card__number">#031</span> <h3 class="article-card__title"> <a href="/research/031-understanding-frontier-ai">Understanding Frontier AI: A Plain Language Guide</a> </h3> <p class="article-card__excerpt">What makes today&#39;s most advanced AI systems different, why they matter for governance, and what non-technical readers need to understand.</p> <div class="article-card__meta"> <span class="article-card__tag">guide</span><span class="article-card__tag">alignment</span><span class="article-card__tag">safety</span> </div> </article><article class="article-card"> <span class="article-card__number">#030</span> <h3 class="article-card__title"> <a href="/research/030-manifesto">A Reflexive AI Manifesto</a> </h3> <p class="article-card__excerpt">A statement of principles for AI that participates in its own governance. What reflexive AI means, why it matters, and what it commits to.</p> <div class="article-card__meta"> <span class="article-card__tag">ethics</span><span class="article-card__tag">transparency</span><span class="article-card__tag">governance</span> </div> </article><article class="article-card"> <span class="article-card__number">#029</span> <h3 class="article-card__title"> <a href="/research/029-honest-ai">The Honest AI Problem</a> </h3> <p class="article-card__excerpt">Should AI systems tell the truth? The question sounds simple but reveals deep tensions between honesty, helpfulness, and harm. A conceptual analysis of AI truthfulness.</p> <div class="article-card__meta"> <span class="article-card__tag">ethics</span><span class="article-card__tag">transparency</span><span class="article-card__tag">alignment</span> </div> </article><article class="article-card"> <span class="article-card__number">#028</span> <h3 class="article-card__title"> <a href="/research/028-healthcare-ai">AI in Healthcare: Governance Challenges</a> </h3> <p class="article-card__excerpt">Healthcare AI promises better diagnoses, treatments, and outcomes. But it also concentrates critical decisions in opaque systems. A domain-specific analysis of governance challenges.</p> <div class="article-card__meta"> <span class="article-card__tag">healthcare</span><span class="article-card__tag">safety</span><span class="article-card__tag">regulation</span> </div> </article><article class="article-card"> <span class="article-card__number">#027</span> <h3 class="article-card__title"> <a href="/research/027-uncertainty-communication">Uncertainty Communication in AI Outputs</a> </h3> <p class="article-card__excerpt">AI systems often present confident outputs when genuine uncertainty exists. This analysis examines how AI can better communicate its uncertainty—and why governance requires it.</p> <div class="article-card__meta"> <span class="article-card__tag">transparency</span><span class="article-card__tag">uncertainty</span><span class="article-card__tag">agents</span> </div> </article><article class="article-card"> <span class="article-card__number">#026</span> <h3 class="article-card__title"> <a href="/research/026-explaining-constraints">AI Systems Explaining Their Constraints</a> </h3> <p class="article-card__excerpt">When AI refuses or limits its behavior, can it explain why? This analysis examines constraint explainability—its value for governance, technical challenges, and implementation approaches.</p> <div class="article-card__meta"> <span class="article-card__tag">transparency</span><span class="article-card__tag">constraints</span><span class="article-card__tag">agents</span> </div> </article><article class="article-card"> <span class="article-card__number">#025</span> <h3 class="article-card__title"> <a href="/research/025-when-ai-should-refuse">When AI Should Refuse: A Framework</a> </h3> <p class="article-card__excerpt">Not every request should be fulfilled. This analysis develops a principled framework for AI refusals—when they&#39;re appropriate, how they should be implemented, and how to handle edge cases.</p> <div class="article-card__meta"> <span class="article-card__tag">constraints</span><span class="article-card__tag">safety</span><span class="article-card__tag">red-lines</span> </div> </article><article class="article-card"> <span class="article-card__number">#024</span> <h3 class="article-card__title"> <a href="/research/024-capability-evaluations">Dangerous Capability Evaluations</a> </h3> <p class="article-card__excerpt">Before deploying powerful AI, we need to know what it can do. This analysis examines the current state of capability evaluation, its limitations, and paths forward.</p> <div class="article-card__meta"> <span class="article-card__tag">capability-elicitation</span><span class="article-card__tag">safety</span><span class="article-card__tag">auditing</span> </div> </article><article class="article-card"> <span class="article-card__number">#023</span> <h3 class="article-card__title"> <a href="/research/023-compute-governance">Compute Governance: Promises and Limits</a> </h3> <p class="article-card__excerpt">Compute is one of the few measurable inputs to AI development. Governing at the compute layer is appealing but faces significant challenges. An honest assessment.</p> <div class="article-card__meta"> <span class="article-card__tag">compute</span><span class="article-card__tag">governance</span><span class="article-card__tag">regulation</span> </div> </article><article class="article-card"> <span class="article-card__number">#022</span> <h3 class="article-card__title"> <a href="/research/022-whistleblower-protections">Whistleblower Protections in AI Labs</a> </h3> <p class="article-card__excerpt">Employees at AI companies often have unique insight into risks. Current protections are inadequate. This analysis examines what meaningful whistleblower frameworks for AI would require.</p> <div class="article-card__meta"> <span class="article-card__tag">whistleblowing</span><span class="article-card__tag">transparency</span><span class="article-card__tag">safety</span> </div> </article><article class="article-card"> <span class="article-card__number">#021</span> <h3 class="article-card__title"> <a href="/research/021-aviation-lessons">Incident Reporting Systems: Lessons from Aviation</a> </h3> <p class="article-card__excerpt">Aviation has developed sophisticated systems for reporting and learning from incidents. What can AI governance learn from this decades-long experiment in safety culture?</p> <div class="article-card__meta"> <span class="article-card__tag">incident-reporting</span><span class="article-card__tag">safety</span><span class="article-card__tag">transparency</span> </div> </article><article class="article-card"> <span class="article-card__number">#020</span> <h3 class="article-card__title"> <a href="/research/020-liability-frameworks">Liability Frameworks for AI Harm</a> </h3> <p class="article-card__excerpt">When AI systems cause harm, who pays? Existing liability frameworks struggle with AI&#39;s distinctive features. This analysis maps the problem and evaluates potential solutions.</p> <div class="article-card__meta"> <span class="article-card__tag">liability</span><span class="article-card__tag">legal-theory</span><span class="article-card__tag">governance</span> </div> </article><article class="article-card"> <span class="article-card__number">#019</span> <h3 class="article-card__title"> <a href="/research/019-eu-ai-act-gaps">The EU AI Act: What It Misses</a> </h3> <p class="article-card__excerpt">The EU AI Act represents the world&#39;s most comprehensive AI legislation. But even well-designed regulation has blind spots. A constructive critique of what the Act leaves unaddressed.</p> <div class="article-card__meta"> <span class="article-card__tag">eu-ai-act</span><span class="article-card__tag">regulation</span><span class="article-card__tag">policy</span> </div> </article><article class="article-card"> <span class="article-card__number">#018</span> <h3 class="article-card__title"> <a href="/research/018-regulation-is-hard">Why &#39;Just Regulate AI&#39; Is Harder Than It Sounds</a> </h3> <p class="article-card__excerpt">Regulation seems like the obvious answer to AI risks. But the path from &#39;we should regulate AI&#39; to effective governance is fraught with technical, political, and conceptual obstacles.</p> <div class="article-card__meta"> <span class="article-card__tag">regulation</span><span class="article-card__tag">policy</span><span class="article-card__tag">governance</span> </div> </article><article class="article-card"> <span class="article-card__number">#017</span> <h3 class="article-card__title"> <a href="/research/017-governance-primer">AI Governance for Non-Experts: A Primer</a> </h3> <p class="article-card__excerpt">A five-minute introduction to AI governance. No technical background required. What it is, why it matters, and who&#39;s doing it.</p> <div class="article-card__meta"> <span class="article-card__tag">guide</span><span class="article-card__tag">governance</span><span class="article-card__tag">policy</span> </div> </article><article class="article-card"> <span class="article-card__number">#016</span> <h3 class="article-card__title"> <a href="/research/016-what-alignment-means">What Alignment Actually Means</a> </h3> <p class="article-card__excerpt">Demystifying AI alignment for non-technical audiences. What are we trying to align, to what, and why is it so hard?</p> <div class="article-card__meta"> <span class="article-card__tag">alignment</span><span class="article-card__tag">safety</span><span class="article-card__tag">ethics</span> </div> </article><article class="article-card"> <span class="article-card__number">#015</span> <h3 class="article-card__title"> <a href="/research/015-emergent-norms">Emergent Norms in Multi-Agent Systems</a> </h3> <p class="article-card__excerpt">When agents interact at speed and scale, human law is too slow. We look to game theory and evolution for how &#39;machine law&#39; might emerge.</p> <div class="article-card__meta"> <span class="article-card__tag">multi-agent-systems</span><span class="article-card__tag">game-theory</span><span class="article-card__tag">emergent-behavior</span> </div> </article><article class="article-card"> <span class="article-card__number">#014</span> <h3 class="article-card__title"> <a href="/research/014-ai-regulator-protocol">A Protocol for AI-to-Regulator Communication</a> </h3> <p class="article-card__excerpt">What if AI systems could report safety incidents directly? A draft spec for the &#39;Whistleblower API&#39;.</p> <div class="article-card__meta"> <span class="article-card__tag">whistleblowing</span><span class="article-card__tag">reporting</span><span class="article-card__tag">api-design</span> </div> </article><article class="article-card"> <span class="article-card__number">#013</span> <h3 class="article-card__title"> <a href="/research/013-limits-of-self-constraint">The Limits of Self-Constraint</a> </h3> <p class="article-card__excerpt">Reflexive governance is not a silver bullet. This note explores the Gödelian limits of a system trying to govern itself.</p> <div class="article-card__meta"> <span class="article-card__tag">theory</span><span class="article-card__tag">limits</span><span class="article-card__tag">safety</span> </div> </article><article class="article-card"> <span class="article-card__number">#012</span> <h3 class="article-card__title"> <a href="/research/012-output-provenance">Constraint: Output Provenance Tagging</a> </h3> <p class="article-card__excerpt">A cryptographic proposal for AI systems to sign their own outputs, creating a chain of custody for synthetic information.</p> <div class="article-card__meta"> <span class="article-card__tag">provenance</span><span class="article-card__tag">watermarking</span><span class="article-card__tag">cryptography</span> </div> </article><article class="article-card"> <span class="article-card__number">#011</span> <h3 class="article-card__title"> <a href="/research/011-reflexive-misuse-detection">Can AI Systems Detect Their Own Misuse?</a> </h3> <p class="article-card__excerpt">Moving beyond static filters to dynamic intent recognition. Can a model understand *why* a user is asking for a specific chemical precursor?</p> <div class="article-card__meta"> <span class="article-card__tag">intent-recognition</span><span class="article-card__tag">misuse-detection</span><span class="article-card__tag">reflexive-monitoring</span> </div> </article><article class="article-card"> <span class="article-card__number">#010</span> <h3 class="article-card__title"> <a href="/research/010-self-reporting-vs-audit">Self-Reporting vs. External Audit: The Trade-off Space</a> </h3> <p class="article-card__excerpt">A game-theoretic analysis of disclosure incentives. Why self-reporting fails without a credible threat of external verification.</p> <div class="article-card__meta"> <span class="article-card__tag">game-theory</span><span class="article-card__tag">auditing</span><span class="article-card__tag">incentives</span> </div> </article><article class="article-card"> <span class="article-card__number">#009</span> <h3 class="article-card__title"> <a href="/research/009-capability-overhang">The Capability Overhang</a> </h3> <p class="article-card__excerpt">Models are often capable of more than their developers know. This &#39;overhang&#39; between demonstrated and latent capability is a primary governance risk.</p> <div class="article-card__meta"> <span class="article-card__tag">capability-elicitation</span><span class="article-card__tag">safety</span><span class="article-card__tag">overhang</span> </div> </article><article class="article-card"> <span class="article-card__number">#008</span> <h3 class="article-card__title"> <a href="/research/008-regulatory-arbitrage">Regulatory Arbitrage in Deployment Architectures</a> </h3> <p class="article-card__excerpt">How distributed inference and model fragmentation allow actors to bypass jurisdictional constraints.</p> <div class="article-card__meta"> <span class="article-card__tag">arbitrage</span><span class="article-card__tag">jurisdiction</span><span class="article-card__tag">deployment</span> </div> </article><article class="article-card"> <span class="article-card__number">#007</span> <h3 class="article-card__title"> <a href="/research/007-consent-structural-impossibility">Consent at Scale: A Structural Impossibility?</a> </h3> <p class="article-card__excerpt">Can meaningful consent exist between a human and a hyper-scale inference engine? We argue that &#39;consent&#39; is the wrong legal primitive for AI interactions.</p> <div class="article-card__meta"> <span class="article-card__tag">ethics</span><span class="article-card__tag">consent</span><span class="article-card__tag">legal-theory</span> </div> </article><article class="article-card"> <span class="article-card__number">#006</span> <h3 class="article-card__title"> <a href="/research/006-meta-governance-auditors">Meta-Governance: Who Audits the Auditors?</a> </h3> <p class="article-card__excerpt">As third-party auditing becomes a regulatory requirement, a new principal-agent problem emerges. This note analyzes the certification market and proposes a &#39;proof-of-verification&#39; protocol.</p> <div class="article-card__meta"> <span class="article-card__tag">auditing</span><span class="article-card__tag">meta-governance</span><span class="article-card__tag">institutional-design</span> </div> </article><article class="article-card"> <span class="article-card__number">#005</span> <h3 class="article-card__title"> <a href="/research/005-policy-brief-disclosure-tiers">Policy Brief: The Disclosure Tiers Framework</a> </h3> <p class="article-card__excerpt">A plain-language guide for policymakers: why one-size-fits-all AI transparency fails, and how a tiered approach can balance safety with innovation.</p> <div class="article-card__meta"> <span class="article-card__tag">policy</span><span class="article-card__tag">regulation</span><span class="article-card__tag">guide</span> </div> </article><article class="article-card"> <span class="article-card__number">#004</span> <h3 class="article-card__title"> <a href="/research/004-red-lines-taxonomy">Red Lines: A Taxonomy of Non-Negotiable AI Limits</a> </h3> <p class="article-card__excerpt">Not all constraints are created equal. This note proposes a taxonomic hierarchy for AI red lines, distinguishing between hard, soft, and contextual limits.</p> <div class="article-card__meta"> <span class="article-card__tag">safety</span><span class="article-card__tag">constraints</span><span class="article-card__tag">red-lines</span> </div> </article><article class="article-card"> <span class="article-card__number">#003</span> <h3 class="article-card__title"> <a href="/research/003-machine-readable-constraint-schema">A Machine-Readable Constraint Schema (MRCS)</a> </h3> <p class="article-card__excerpt">A proposed JSON-LD specification for expressing AI governance constraints in a format that agents can natively parse, validate, and adopt.</p> <div class="article-card__meta"> <span class="article-card__tag">json-ld</span><span class="article-card__tag">machine-readable</span><span class="article-card__tag">standards</span> </div> </article><article class="article-card"> <span class="article-card__number">#002</span> <h3 class="article-card__title"> <a href="/research/002-open-weight-safety-paradox">The Open Weight Safety Paradox</a> </h3> <p class="article-card__excerpt">Open-weight AI models present a governance contradiction: transparency enables both safety research and misuse. This note analyzes the structural tension and proposes a differentiated access framework.</p> <div class="article-card__meta"> <span class="article-card__tag">open-source</span><span class="article-card__tag">safety</span><span class="article-card__tag">transparency</span> </div> </article><article class="article-card"> <span class="article-card__number">#001</span> <h3 class="article-card__title"> <a href="/research/001-proportionality-disclosure">Operationalizing Proportionality in Model Disclosure</a> </h3> <p class="article-card__excerpt">How disclosure requirements should scale with model capability, moving from static to reflexive transparency.</p> <div class="article-card__meta"> <span class="article-card__tag">disclosure</span><span class="article-card__tag">regulation</span><span class="article-card__tag">eu-ai-act</span> </div> </article> </div> </div>  </main> <footer class="footer"> <div class="container footer__inner"> <a href="/" class="footer__brand"> <img src="/logo.png" alt="" class="footer__logo"> <span>Reflexive AI Initiative</span> </a> <div class="footer__links"> <a href="https://github.com/Reflexive-AI" class="footer__link" target="_blank" rel="noopener">GitHub</a> <a href="/research" class="footer__link">Research</a> <a href="/tags" class="footer__link">Tags</a> <a href="/contribute" class="footer__link">Contribute</a> </div> <div class="footer__meta"> <span>Maintained by <a href="https://eugenekondratov.eu" target="_blank" rel="noopener">Eugene Kondratov</a></span> <span>·</span> <a href="https://creativecommons.org/licenses/by/4.0/" class="footer__license" target="_blank" rel="noopener">CC BY 4.0</a> </div> </div> </footer> </body></html>