<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="From the Bletchley Declaration to proposed AI treaties: analyzing what international agreements on AI governance have been proposed, what they would achieve, and their prospects."><meta name="generator" content="Astro v5.17.1"><!-- Fonts --><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Source+Serif+4:ital,wght@0,400;0,500;0,600;1,400&display=swap" rel="stylesheet"><!-- Favicon --><link rel="icon" type="image/png" href="/logo.png"><!-- Open Graph --><meta property="og:title" content="International AI Treaty Proposals: A Comparative Analysis | Reflexive AI Initiative"><meta property="og:description" content="From the Bletchley Declaration to proposed AI treaties: analyzing what international agreements on AI governance have been proposed, what they would achieve, and their prospects."><meta property="og:type" content="website"><meta property="og:site_name" content="Reflexive AI Initiative"><title>International AI Treaty Proposals: A Comparative Analysis | Reflexive AI Initiative</title><link rel="stylesheet" href="/_astro/_slug_.BtA_RPCv.css"></head> <body>  <header class="header"> <div class="container header__inner"> <a href="/" class="header__brand"> <img src="/logo.png" alt="" class="header__logo"> <div> <span class="header__title">Reflexive AI</span> <span class="header__tagline">Governance · Reflexivity · Constraint</span> </div> </a> <nav class="header__nav"> <a href="/about" class="header__link">About</a> <a href="/research" class="header__link">Research</a> <a href="/contribute" class="header__link">Contribute</a> </nav> </div> </header>  <main>  <div class="article-layout"> <article class="article"> <header class="article__header"> <div class="article__meta"> <a href="/research" class="article__category">Governance Analysis</a><a href="/research" class="article__category">Public</a> <span>·</span> <time datetime="2026-01-20T00:00:00.000Z"> January 20, 2026 </time> </div> <h1 class="article__title">International AI Treaty Proposals: A Comparative Analysis</h1> <p class="article__excerpt">From the Bletchley Declaration to proposed AI treaties: analyzing what international agreements on AI governance have been proposed, what they would achieve, and their prospects.</p> </header>  <div class="toc-mobile"> <button class="toc-mobile__button" aria-expanded="false" onclick="this.setAttribute('aria-expanded', this.getAttribute('aria-expanded') === 'true' ? 'false' : 'true'); this.nextElementSibling.classList.toggle('open');"> <span>On This Page</span> <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M4 6L8 10L12 6" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </button> <nav class="toc-mobile__content"> <ul class="toc-mobile__list"> <li style="margin-left: 0px"> <a href="#the-case-for-international-ai-governance">The Case for International AI Governance</a> </li><li style="margin-left: 0px"> <a href="#current-international-arrangements">Current International Arrangements</a> </li><li style="margin-left: 12px"> <a href="#bletchley-declaration-2023">Bletchley Declaration (2023)</a> </li><li style="margin-left: 12px"> <a href="#g7-hiroshima-ai-process">G7 Hiroshima AI Process</a> </li><li style="margin-left: 12px"> <a href="#oecd-ai-principles">OECD AI Principles</a> </li><li style="margin-left: 12px"> <a href="#council-of-europe-ai-convention">Council of Europe AI Convention</a> </li><li style="margin-left: 12px"> <a href="#bilateral-arrangements">Bilateral Arrangements</a> </li><li style="margin-left: 0px"> <a href="#proposed-treaty-models">Proposed Treaty Models</a> </li><li style="margin-left: 12px"> <a href="#nuclear-analogy-iaea-for-ai">Nuclear Analogy: IAEA for AI</a> </li><li style="margin-left: 12px"> <a href="#arms-control-model">Arms Control Model</a> </li><li style="margin-left: 12px"> <a href="#biosecurity-model">Biosecurity Model</a> </li><li style="margin-left: 12px"> <a href="#climate-model">Climate Model</a> </li><li style="margin-left: 12px"> <a href="#internet-governance-model">Internet Governance Model</a> </li><li style="margin-left: 0px"> <a href="#what-agreements-might-cover">What Agreements Might Cover</a> </li><li style="margin-left: 12px"> <a href="#safety-standards">Safety Standards</a> </li><li style="margin-left: 12px"> <a href="#incident-reporting">Incident Reporting</a> </li><li style="margin-left: 12px"> <a href="#prohibited-applications">Prohibited Applications</a> </li><li style="margin-left: 12px"> <a href="#transparency">Transparency</a> </li><li style="margin-left: 12px"> <a href="#compute-governance">Compute Governance</a> </li><li style="margin-left: 12px"> <a href="#research-cooperation">Research Cooperation</a> </li><li style="margin-left: 0px"> <a href="#obstacles-to-agreement">Obstacles to Agreement</a> </li><li style="margin-left: 12px"> <a href="#great-power-competition">Great Power Competition</a> </li><li style="margin-left: 12px"> <a href="#verification-challenges">Verification Challenges</a> </li><li style="margin-left: 12px"> <a href="#definitional-difficulties">Definitional Difficulties</a> </li><li style="margin-left: 12px"> <a href="#private-sector-role">Private Sector Role</a> </li><li style="margin-left: 12px"> <a href="#speed-of-change">Speed of Change</a> </li><li style="margin-left: 12px"> <a href="#incentive-misalignment">Incentive Misalignment</a> </li><li style="margin-left: 0px"> <a href="#realistic-near-term-prospects">Realistic Near-Term Prospects</a> </li><li style="margin-left: 12px"> <a href="#continued-soft-law-development">Continued Soft Law Development</a> </li><li style="margin-left: 12px"> <a href="#bilateral-and-minilateral-agreements">Bilateral and Minilateral Agreements</a> </li><li style="margin-left: 12px"> <a href="#technical-standards-coordination">Technical Standards Coordination</a> </li><li style="margin-left: 12px"> <a href="#issue-specific-agreements">Issue-Specific Agreements</a> </li><li style="margin-left: 12px"> <a href="#crisis-driven-progress">Crisis-Driven Progress</a> </li><li style="margin-left: 0px"> <a href="#conclusion">Conclusion</a> </li><li style="margin-left: 0px"> <a href="#further-reading">Further Reading</a> </li> </ul> </nav> </div> <div class="article__content">  <h2 id="the-case-for-international-ai-governance">The Case for International AI Governance</h2>
<p>AI development is global; effective governance arguably must be too. Several features of AI suggest that purely national governance is insufficient:</p>
<p><strong>Cross-border effects.</strong> AI systems developed in one country affect people worldwide. An AI system trained in California might make decisions about users in Germany, generate content consumed in Brazil, and run on servers in Singapore.</p>
<p><strong>Competitive dynamics.</strong> National regulation creates competitive pressures. Countries fear that strict domestic rules will drive AI development elsewhere. This can create races to the bottom unless international coordination establishes common standards.</p>
<p><strong>Shared risks.</strong> Some AI risks—catastrophic misalignment, biological weapons assistance, massive disinformation—transcend national boundaries. No country alone can manage risks that could affect humanity collectively.</p>
<p><strong>Concentration.</strong> Frontier AI development is concentrated in a small number of countries, primarily the United States and China, with significant activity in the UK, France, and elsewhere. Agreements among few actors are more feasible than among many.</p>
<p>This analysis examines what international AI agreements have been proposed or achieved, what different proposals would accomplish, and what obstacles they face.</p>
<h2 id="current-international-arrangements">Current International Arrangements</h2>
<p>Several international AI governance arrangements already exist, though none constitutes comprehensive treaty-based governance.</p>
<h3 id="bletchley-declaration-2023">Bletchley Declaration (2023)</h3>
<p>The AI Safety Summit at Bletchley Park produced a declaration signed by 28 countries, including the US and China. Key elements:</p>
<ul>
<li>Recognition that frontier AI presents safety risks</li>
<li>Acknowledgment that risks are international in scope</li>
<li>Commitment to cooperation on AI safety</li>
<li>Establishment of ongoing international dialogue</li>
</ul>
<p><strong>Significance:</strong> The declaration established that AI safety is a legitimate topic for international engagement and achieved surprisingly broad participation. However, it is non-binding and contains no specific commitments or enforcement mechanisms.</p>
<h3 id="g7-hiroshima-ai-process">G7 Hiroshima AI Process</h3>
<p>The G7 developed AI governance principles and a code of conduct for AI developers. Key features:</p>
<ul>
<li>Voluntary commitments for advanced AI developers</li>
<li>Focus on foundation models and generative AI</li>
<li>Principles covering safety, transparency, and responsible development</li>
</ul>
<p><strong>Limitations:</strong> Applies only to G7 countries and is voluntary. Doesn’t address AI development outside the G7, notably China.</p>
<h3 id="oecd-ai-principles">OECD AI Principles</h3>
<p>The OECD adopted AI principles in 2019, endorsed by over 40 countries:</p>
<ul>
<li>Human-centered values and fairness</li>
<li>Transparency and explainability</li>
<li>Robustness, security, and safety</li>
<li>Accountability</li>
</ul>
<p><strong>Significance:</strong> Broad international endorsement of principles. However, principles are high-level and implementation is national, creating significant variation in practice.</p>
<h3 id="council-of-europe-ai-convention">Council of Europe AI Convention</h3>
<p>The Council of Europe developed a binding convention on AI and human rights:</p>
<ul>
<li>Applies to AI systems in the public sector</li>
<li>Requires human rights impact assessments</li>
<li>Establishes accountability requirements</li>
<li>Opens for signature to non-Council of Europe members</li>
</ul>
<p><strong>Significance:</strong> The first binding international treaty on AI. However, scope is limited to human rights applications, and enforcement relies on domestic implementation.</p>
<h3 id="bilateral-arrangements">Bilateral Arrangements</h3>
<p>Various bilateral discussions and agreements address AI:</p>
<ul>
<li>US-EU Trade and Technology Council discussions on AI standards</li>
<li>US-UK AI safety cooperation</li>
<li>Limited US-China dialogue on AI risks</li>
</ul>
<p>These arrangements are important but fragmented and often informal.</p>
<h2 id="proposed-treaty-models">Proposed Treaty Models</h2>
<p>Several models for more comprehensive international AI agreements have been proposed.</p>
<h3 id="nuclear-analogy-iaea-for-ai">Nuclear Analogy: IAEA for AI</h3>
<p>Drawing on nuclear governance, some propose an International AI Agency modeled on the IAEA:</p>
<ul>
<li>Verification of AI development activities</li>
<li>Safety standards and inspections</li>
<li>Technical assistance for safe AI development</li>
<li>Information sharing on risks and capabilities</li>
</ul>
<p><strong>Advantages:</strong> Proven model for governing dangerous technology. Addresses verification challenges.</p>
<p><strong>Challenges:</strong> AI differs from nuclear technology—it’s distributed, dual-use by default, and developed primarily by private actors. Inspection regimes that work for nuclear facilities translate poorly to AI labs. We explored related challenges in <a href="/research/023-compute-governance/">compute governance</a>.</p>
<h3 id="arms-control-model">Arms Control Model</h3>
<p>Some propose AI agreements modeled on arms control treaties:</p>
<ul>
<li>Limits on development of specific AI capabilities</li>
<li>Transparency and verification measures</li>
<li>Confidence-building mechanisms</li>
<li>Crisis communication channels</li>
</ul>
<p><strong>Advantages:</strong> Addresses competitive dynamics between major powers. Proven template for managing dangerous technologies.</p>
<p><strong>Challenges:</strong> AI “capabilities” are harder to define and verify than weapon systems. Dual-use nature makes drawing lines between civilian and military AI difficult. Unlike nuclear weapons, AI development doesn’t require observable physical infrastructure.</p>
<h3 id="biosecurity-model">Biosecurity Model</h3>
<p>The Biological Weapons Convention (BWC) offers another analogy:</p>
<ul>
<li>Prohibition of specific applications</li>
<li>Confidence-building measures</li>
<li>Expert review processes</li>
<li>Norm development</li>
</ul>
<p><strong>Advantages:</strong> Addresses dual-use technology with civilian and military applications.</p>
<p><strong>Challenges:</strong> The BWC’s weakness—lack of verification—would likely apply to AI agreements. As we discussed in <a href="/research/035-dual-use-biology/">dual-use AI in biology</a>, AI makes biosecurity harder, not easier.</p>
<h3 id="climate-model">Climate Model</h3>
<p>Climate governance offers different insights:</p>
<ul>
<li>Framework convention establishing principles</li>
<li>Conference of parties for ongoing negotiation</li>
<li>Nationally determined contributions</li>
<li>Transparency and review mechanisms</li>
<li>Financial mechanisms for developing countries</li>
</ul>
<p><strong>Advantages:</strong> Accommodates different national circumstances. Creates ongoing engagement. Combines hard and soft law.</p>
<p><strong>Challenges:</strong> Climate governance has achieved limited emissions reductions. AI changes faster than climate negotiation timelines accommodate.</p>
<h3 id="internet-governance-model">Internet Governance Model</h3>
<p>Multi-stakeholder internet governance offers another template:</p>
<ul>
<li>Involvement of governments, companies, civil society, and technical community</li>
<li>Technical standards developed through expert bodies</li>
<li>Norms developed through multiple forums</li>
<li>Limited formal treaty structure</li>
</ul>
<p><strong>Advantages:</strong> Flexibility and adaptability. Includes non-state actors central to AI development.</p>
<p><strong>Challenges:</strong> Internet governance has significant gaps and conflicts. Multi-stakeholder approaches can obscure accountability.</p>
<h2 id="what-agreements-might-cover">What Agreements Might Cover</h2>
<p>Different aspects of AI governance might benefit from international coordination.</p>
<h3 id="safety-standards">Safety Standards</h3>
<p>International standards for AI safety testing, evaluation, and deployment could reduce fragmentation and races to the bottom. This connects to our analysis of <a href="/research/024-capability-evaluations/">capability evaluations</a>.</p>
<h3 id="incident-reporting">Incident Reporting</h3>
<p>International mechanisms for reporting and sharing information about AI incidents could improve collective learning. Aviation’s ICAO offers a model, as we discussed in <a href="/research/021-aviation-lessons/">aviation incident reporting lessons</a>.</p>
<h3 id="prohibited-applications">Prohibited Applications</h3>
<p>Agreement on AI applications that should be universally prohibited—perhaps CBRN weapon development, mass surveillance, or autonomous weapons—could establish global norms. Our <a href="/research/004-red-lines-taxonomy/">red lines taxonomy</a> identifies candidates.</p>
<h3 id="transparency">Transparency</h3>
<p>Agreements on what AI developers should disclose could address <a href="/research/008-regulatory-arbitrage/">regulatory arbitrage</a> and support consistent global oversight.</p>
<h3 id="compute-governance">Compute Governance</h3>
<p>Given compute’s role in frontier AI development, international coordination on compute access and tracking could support governance objectives. See our <a href="/research/023-compute-governance/">compute governance analysis</a>.</p>
<h3 id="research-cooperation">Research Cooperation</h3>
<p>Agreements could facilitate international cooperation on AI safety research, sharing knowledge that benefits global rather than national safety.</p>
<h2 id="obstacles-to-agreement">Obstacles to Agreement</h2>
<p>Significant obstacles impede international AI governance.</p>
<h3 id="great-power-competition">Great Power Competition</h3>
<p>The US-China relationship currently prioritizes competition over cooperation. Neither country is likely to accept agreements that constrain its AI development while competitors benefit.</p>
<h3 id="verification-challenges">Verification Challenges</h3>
<p>Unlike nuclear weapons or chemical agents, AI capabilities are difficult to observe and verify. Software can be copied and concealed. Training runs occur on distributed infrastructure. Inspections would struggle to confirm compliance.</p>
<h3 id="definitional-difficulties">Definitional Difficulties</h3>
<p>What is “AI” for treaty purposes? What capabilities warrant international concern? Drawing lines that are specific enough to be meaningful but flexible enough to remain relevant is extremely difficult.</p>
<h3 id="private-sector-role">Private Sector Role</h3>
<p>Unlike nuclear or military technology, AI development is driven primarily by private companies. International agreements between states don’t directly bind corporate actors.</p>
<h3 id="speed-of-change">Speed of Change</h3>
<p>AI capabilities change faster than international negotiation processes. A treaty negotiated over years might be obsolete before ratification.</p>
<h3 id="incentive-misalignment">Incentive Misalignment</h3>
<p>Countries leading in AI development benefit from the status quo and may resist constraints. Countries lagging may see constraints as locking in disadvantage.</p>
<h2 id="realistic-near-term-prospects">Realistic Near-Term Prospects</h2>
<p>Given these obstacles, what international AI governance might actually emerge?</p>
<h3 id="continued-soft-law-development">Continued Soft Law Development</h3>
<p>Principles, guidelines, and voluntary commitments will likely continue expanding. These are easier to achieve than binding treaties but have limited enforcement.</p>
<h3 id="bilateral-and-minilateral-agreements">Bilateral and Minilateral Agreements</h3>
<p>Smaller-scale agreements among like-minded countries are more feasible than global treaties. The US, UK, and EU might achieve meaningful coordination even if China doesn’t participate.</p>
<h3 id="technical-standards-coordination">Technical Standards Coordination</h3>
<p>International standards bodies (ISO, IEEE) can develop AI standards that achieve de facto international application through market adoption rather than treaty obligation.</p>
<h3 id="issue-specific-agreements">Issue-Specific Agreements</h3>
<p>Narrow agreements on specific issues—perhaps autonomous weapons, biological weapons applications, or compute tracking—might be achievable even if comprehensive governance isn’t.</p>
<h3 id="crisis-driven-progress">Crisis-Driven Progress</h3>
<p>Major AI-related incidents might create political windows for governance progress that isn’t currently possible. This is unfortunate but historically common in technology governance.</p>
<h2 id="conclusion">Conclusion</h2>
<p>International AI governance is both necessary and extraordinarily difficult. Current arrangements are fragmented and largely non-binding. Comprehensive treaty-based governance faces significant obstacles.</p>
<p>The realistic path forward likely involves:</p>
<ul>
<li>Continued development of principles and norms</li>
<li>Bilateral and minilateral agreements among willing parties</li>
<li>Technical standards with de facto international reach</li>
<li>Issue-specific agreements where alignment exists</li>
<li>Building institutional capacity for future, stronger governance</li>
</ul>
<p>The goal should be establishing foundations for more robust international governance as political conditions permit—recognizing that those conditions may require either steady diplomatic work or crisis-driven urgency to emerge.</p>
<h2 id="further-reading">Further Reading</h2>
<ul>
<li><a href="/research/018-regulation-is-hard/">Why “Just Regulate AI” Is Harder Than It Sounds</a></li>
<li><a href="/research/008-regulatory-arbitrage/">Regulatory Arbitrage in AI Deployment</a></li>
<li><a href="/research/023-compute-governance/">Compute Governance: Promises and Limits</a></li>
<li><a href="/research/021-aviation-lessons/">Incident Reporting Systems: Lessons from Aviation</a></li>
</ul>  </div> <footer class="article__footer" style="margin-top: var(--space-12); padding-top: var(--space-6); border-top: 1px solid var(--color-border);"> <div class="article-card__meta"> <a href="/tags" class="article-card__tag">regulation</a><a href="/tags" class="article-card__tag">governance</a><a href="/tags" class="article-card__tag">policy</a><a href="/tags" class="article-card__tag">jurisdiction</a> </div> </footer> </article>  <aside class="toc-sidebar" id="toc-sidebar"> <div class="toc-sidebar__inner"> <div class="toc-sidebar__header"> <span class="toc-sidebar__title">On This Page</span> <button class="toc-sidebar__toggle" aria-label="Toggle table of contents" onclick="document.getElementById('toc-sidebar').classList.toggle('collapsed');"> <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M4 6L8 10L12 6" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </button> </div> <ul class="toc-sidebar__list"> <li style="margin-left: 0px"> <a href="#the-case-for-international-ai-governance">The Case for International AI Governance</a> </li><li style="margin-left: 0px"> <a href="#current-international-arrangements">Current International Arrangements</a> </li><li style="margin-left: 12px"> <a href="#bletchley-declaration-2023">Bletchley Declaration (2023)</a> </li><li style="margin-left: 12px"> <a href="#g7-hiroshima-ai-process">G7 Hiroshima AI Process</a> </li><li style="margin-left: 12px"> <a href="#oecd-ai-principles">OECD AI Principles</a> </li><li style="margin-left: 12px"> <a href="#council-of-europe-ai-convention">Council of Europe AI Convention</a> </li><li style="margin-left: 12px"> <a href="#bilateral-arrangements">Bilateral Arrangements</a> </li><li style="margin-left: 0px"> <a href="#proposed-treaty-models">Proposed Treaty Models</a> </li><li style="margin-left: 12px"> <a href="#nuclear-analogy-iaea-for-ai">Nuclear Analogy: IAEA for AI</a> </li><li style="margin-left: 12px"> <a href="#arms-control-model">Arms Control Model</a> </li><li style="margin-left: 12px"> <a href="#biosecurity-model">Biosecurity Model</a> </li><li style="margin-left: 12px"> <a href="#climate-model">Climate Model</a> </li><li style="margin-left: 12px"> <a href="#internet-governance-model">Internet Governance Model</a> </li><li style="margin-left: 0px"> <a href="#what-agreements-might-cover">What Agreements Might Cover</a> </li><li style="margin-left: 12px"> <a href="#safety-standards">Safety Standards</a> </li><li style="margin-left: 12px"> <a href="#incident-reporting">Incident Reporting</a> </li><li style="margin-left: 12px"> <a href="#prohibited-applications">Prohibited Applications</a> </li><li style="margin-left: 12px"> <a href="#transparency">Transparency</a> </li><li style="margin-left: 12px"> <a href="#compute-governance">Compute Governance</a> </li><li style="margin-left: 12px"> <a href="#research-cooperation">Research Cooperation</a> </li><li style="margin-left: 0px"> <a href="#obstacles-to-agreement">Obstacles to Agreement</a> </li><li style="margin-left: 12px"> <a href="#great-power-competition">Great Power Competition</a> </li><li style="margin-left: 12px"> <a href="#verification-challenges">Verification Challenges</a> </li><li style="margin-left: 12px"> <a href="#definitional-difficulties">Definitional Difficulties</a> </li><li style="margin-left: 12px"> <a href="#private-sector-role">Private Sector Role</a> </li><li style="margin-left: 12px"> <a href="#speed-of-change">Speed of Change</a> </li><li style="margin-left: 12px"> <a href="#incentive-misalignment">Incentive Misalignment</a> </li><li style="margin-left: 0px"> <a href="#realistic-near-term-prospects">Realistic Near-Term Prospects</a> </li><li style="margin-left: 12px"> <a href="#continued-soft-law-development">Continued Soft Law Development</a> </li><li style="margin-left: 12px"> <a href="#bilateral-and-minilateral-agreements">Bilateral and Minilateral Agreements</a> </li><li style="margin-left: 12px"> <a href="#technical-standards-coordination">Technical Standards Coordination</a> </li><li style="margin-left: 12px"> <a href="#issue-specific-agreements">Issue-Specific Agreements</a> </li><li style="margin-left: 12px"> <a href="#crisis-driven-progress">Crisis-Driven Progress</a> </li><li style="margin-left: 0px"> <a href="#conclusion">Conclusion</a> </li><li style="margin-left: 0px"> <a href="#further-reading">Further Reading</a> </li> </ul> </div> </aside> </div> <div class="scroll-progress" id="scroll-progress"></div> <script type="module">const s=document.getElementById("scroll-progress");s&&window.addEventListener("scroll",()=>{const o=window.scrollY,e=document.documentElement.scrollHeight-window.innerHeight,t=o/e*100;s.style.width=`${t}%`});const r=document.querySelectorAll(".toc-sidebar__list a"),n=document.querySelectorAll(".article__content h2, .article__content h3");if(r.length>0&&n.length>0){const o=new IntersectionObserver(e=>{e.forEach(t=>{if(t.isIntersecting){r.forEach(i=>i.classList.remove("active"));const c=document.querySelector(`.toc-sidebar__list a[href="#${t.target.id}"]`);c&&c.classList.add("active")}})},{rootMargin:"-20% 0% -60% 0%"});n.forEach(e=>o.observe(e))}</script>  </main> <footer class="footer"> <div class="container footer__inner"> <a href="/" class="footer__brand"> <img src="/logo.png" alt="" class="footer__logo"> <span>Reflexive AI Initiative</span> </a> <div class="footer__links"> <a href="https://github.com/Reflexive-AI" class="footer__link" target="_blank" rel="noopener">GitHub</a> <a href="/research" class="footer__link">Research</a> <a href="/tags" class="footer__link">Tags</a> <a href="/contribute" class="footer__link">Contribute</a> </div> <div class="footer__meta"> <span>Maintained by <a href="https://eugenekondratov.eu" target="_blank" rel="noopener">Eugene Kondratov</a></span> <span>·</span> <a href="https://creativecommons.org/licenses/by/4.0/" class="footer__license" target="_blank" rel="noopener">CC BY 4.0</a> </div> </div> </footer> </body></html>