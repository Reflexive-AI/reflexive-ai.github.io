<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="How AI is transforming biological research—and why the same capabilities that could cure diseases could enable bioweapons. A case study in dual-use governance."><meta name="generator" content="Astro v5.17.1"><!-- Fonts --><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Source+Serif+4:ital,wght@0,400;0,500;0,600;1,400&display=swap" rel="stylesheet"><!-- Favicon --><link rel="icon" type="image/png" href="/logo.png"><!-- Open Graph --><meta property="og:title" content="Dual-Use AI: The Biological Research Case | Reflexive AI Initiative"><meta property="og:description" content="How AI is transforming biological research—and why the same capabilities that could cure diseases could enable bioweapons. A case study in dual-use governance."><meta property="og:type" content="website"><meta property="og:site_name" content="Reflexive AI Initiative"><title>Dual-Use AI: The Biological Research Case | Reflexive AI Initiative</title><link rel="stylesheet" href="/_astro/_slug_.BtA_RPCv.css"></head> <body>  <header class="header"> <div class="container header__inner"> <a href="/" class="header__brand"> <img src="/logo.png" alt="" class="header__logo"> <div> <span class="header__title">Reflexive AI</span> <span class="header__tagline">Governance · Reflexivity · Constraint</span> </div> </a> <nav class="header__nav"> <a href="/about" class="header__link">About</a> <a href="/research" class="header__link">Research</a> <a href="/contribute" class="header__link">Contribute</a> </nav> </div> </header>  <main>  <div class="article-layout"> <article class="article"> <header class="article__header"> <div class="article__meta"> <a href="/research" class="article__category">Governance Analysis</a> <span>·</span> <time datetime="2026-01-17T00:00:00.000Z"> January 17, 2026 </time> </div> <h1 class="article__title">Dual-Use AI: The Biological Research Case</h1> <p class="article__excerpt">How AI is transforming biological research—and why the same capabilities that could cure diseases could enable bioweapons. A case study in dual-use governance.</p> </header>  <div class="toc-mobile"> <button class="toc-mobile__button" aria-expanded="false" onclick="this.setAttribute('aria-expanded', this.getAttribute('aria-expanded') === 'true' ? 'false' : 'true'); this.nextElementSibling.classList.toggle('open');"> <span>On This Page</span> <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M4 6L8 10L12 6" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </button> <nav class="toc-mobile__content"> <ul class="toc-mobile__list"> <li style="margin-left: 0px"> <a href="#the-dual-use-dilemma">The Dual-Use Dilemma</a> </li><li style="margin-left: 0px"> <a href="#what-ai-can-do-in-biology">What AI Can Do in Biology</a> </li><li style="margin-left: 0px"> <a href="#the-bioweapon-risk">The Bioweapon Risk</a> </li><li style="margin-left: 0px"> <a href="#how-this-connects-to-other-risks">How This Connects to Other Risks</a> </li><li style="margin-left: 0px"> <a href="#current-governance-approaches">Current Governance Approaches</a> </li><li style="margin-left: 12px"> <a href="#existing-biological-weapons-governance">Existing Biological Weapons Governance</a> </li><li style="margin-left: 12px"> <a href="#ai-model-restrictions">AI Model Restrictions</a> </li><li style="margin-left: 12px"> <a href="#biosecurity-communities">Biosecurity Communities</a> </li><li style="margin-left: 12px"> <a href="#capability-evaluations">Capability Evaluations</a> </li><li style="margin-left: 0px"> <a href="#governance-proposals">Governance Proposals</a> </li><li style="margin-left: 12px"> <a href="#structured-access">Structured Access</a> </li><li style="margin-left: 12px"> <a href="#know-your-customer-requirements">Know-Your-Customer Requirements</a> </li><li style="margin-left: 12px"> <a href="#compute-governance">Compute Governance</a> </li><li style="margin-left: 12px"> <a href="#red-team-standards">Red Team Standards</a> </li><li style="margin-left: 12px"> <a href="#information-hazard-protocols">Information Hazard Protocols</a> </li><li style="margin-left: 0px"> <a href="#why-this-is-hard">Why This Is Hard</a> </li><li style="margin-left: 0px"> <a href="#the-reflexive-dimension">The Reflexive Dimension</a> </li><li style="margin-left: 0px"> <a href="#what-might-work">What Might Work</a> </li><li style="margin-left: 0px"> <a href="#further-reading">Further Reading</a> </li> </ul> </nav> </div> <div class="article__content">  <h2 id="the-dual-use-dilemma">The Dual-Use Dilemma</h2>
<p>Some technologies are inherently dual-use: the same capabilities that enable beneficial applications also enable harmful ones. Nuclear physics gives us both power plants and weapons. Cryptography protects both dissidents and criminals.</p>
<p>AI applied to biological research is perhaps the most consequential contemporary example of dual-use technology. The same AI systems that could accelerate drug discovery, predict protein structures, and design novel therapies could also potentially help bad actors create dangerous pathogens.</p>
<p>This analysis examines the AI-biology dual-use problem as a case study in governance challenges—how we might capture benefits while mitigating catastrophic risks.</p>
<h2 id="what-ai-can-do-in-biology">What AI Can Do in Biology</h2>
<p>AI capabilities in biological research have advanced dramatically.</p>
<p><strong>Protein structure prediction.</strong> AlphaFold and similar systems can predict how proteins fold into three-dimensional structures from their amino acid sequences. This accelerates drug discovery, disease understanding, and fundamental biology research.</p>
<p><strong>Molecular design.</strong> AI systems can design novel molecules with desired properties—potential drugs, catalysts, and materials. This could dramatically speed pharmaceutical development.</p>
<p><strong>Genomic analysis.</strong> AI can identify patterns in genomic data that would be impossible for humans to detect, advancing understanding of genetic diseases and potential treatments.</p>
<p><strong>Lab automation.</strong> AI systems increasingly control laboratory equipment, enabling faster experiments and novel experimental designs.</p>
<p><strong>Synthesis planning.</strong> AI can determine how to synthesize complex molecules, providing step-by-step instructions for chemical production.</p>
<p>These capabilities are already transforming biological research. They’re also why security experts are concerned.</p>
<h2 id="the-bioweapon-risk">The Bioweapon Risk</h2>
<p>The same AI capabilities that accelerate beneficial research could potentially accelerate weapons development.</p>
<p><strong>Pathogen design.</strong> AI systems that understand protein structures and immune evasion could potentially help design pathogens that are more transmissible, more deadly, or more resistant to treatments.</p>
<p><strong>Synthesis guidance.</strong> AI that provides synthesis instructions for beneficial molecules could also provide instructions for dangerous ones. An AI system that helps researchers synthesize a potential drug might, without appropriate safeguards, help bad actors synthesize a toxin.</p>
<p><strong>Lowering barriers.</strong> Perhaps most concerning, AI could lower the expertise barriers to bioweapon development. Creating dangerous pathogens currently requires sophisticated laboratory skills and deep biological knowledge. AI assistance might make such activities accessible to those without traditional expertise.</p>
<p><strong>Acceleration.</strong> Even if AI doesn’t enable anything that wasn’t theoretically possible before, it could dramatically accelerate development timelines. A bioweapon that would take a state actor years to develop might be achievable in months with AI assistance.</p>
<p>This is the essence of dual-use: capabilities that are beneficial in legitimate contexts become dangerous when applied with malicious intent.</p>
<h2 id="how-this-connects-to-other-risks">How This Connects to Other Risks</h2>
<p>The AI-biology dual-use problem connects to broader governance challenges we’ve explored.</p>
<p><strong>Capability overhang.</strong> As we discussed in <a href="/research/009-capability-overhang/">the capability overhang problem</a>, AI systems may have dangerous capabilities that aren’t publicly known or tested. This is particularly concerning for biology, where dangerous capabilities might not be discovered until they’re misused.</p>
<p><strong>Disclosure dilemmas.</strong> How much should be disclosed about AI capabilities in biology? Publishing research enables beneficial applications but also informs adversaries. This connects to our analysis of <a href="/research/001-proportionality-disclosure/">proportionality in disclosure</a>.</p>
<p><strong>The limits of refusal.</strong> We explored <a href="/research/025-when-ai-should-refuse/">when AI should refuse</a> requests. Biological research presents hard cases: requests for synthesis information might be legitimate research or bioweapon preparation, and AI systems lack context to distinguish reliably.</p>
<p><strong>Red lines.</strong> Some capabilities might warrant absolute restrictions. Our <a href="/research/004-red-lines-taxonomy/">taxonomy of non-negotiable AI limits</a> identified CBRN (chemical, biological, radiological, nuclear) weapon assistance as a potential red line. But drawing the line precisely is difficult.</p>
<h2 id="current-governance-approaches">Current Governance Approaches</h2>
<p>Several governance mechanisms attempt to address AI-biology risks.</p>
<h3 id="existing-biological-weapons-governance">Existing Biological Weapons Governance</h3>
<p>The Biological Weapons Convention (BWC) prohibits the development and production of biological weapons. However, it lacks verification mechanisms and enforcement capacity. It was designed for state actors and adapts poorly to AI-enabled threats from non-state actors.</p>
<h3 id="ai-model-restrictions">AI Model Restrictions</h3>
<p>Major AI labs implement restrictions on biological information. Systems are trained to refuse requests for pathogen creation instructions, synthesis of dangerous molecules, and similar queries.</p>
<p>However, these restrictions face challenges:</p>
<ul>
<li><strong>Circumvention.</strong> Users can sometimes prompt AI systems to provide restricted information through indirect queries or jailbreaking techniques.</li>
<li><strong>Open models.</strong> Restrictions on closed API services don’t apply to open-weight models that can be modified.</li>
<li><strong>Dual-use knowledge.</strong> The same information needed for drug development might enable bioweapon development. Restricting all potentially dangerous knowledge would cripple beneficial applications.</li>
</ul>
<h3 id="biosecurity-communities">Biosecurity Communities</h3>
<p>The biosecurity community has developed norms around responsible research:</p>
<ul>
<li>Institutional biosafety committees review dangerous research</li>
<li>Dual-Use Research of Concern (DURC) policies require special review</li>
<li>Some research is restricted from publication on security grounds</li>
</ul>
<p>These norms could potentially extend to AI-biological research, but enforcement mechanisms are weak and coverage is incomplete.</p>
<h3 id="capability-evaluations">Capability Evaluations</h3>
<p>As we discussed in <a href="/research/024-capability-evaluations/">dangerous capability evaluations</a>, AI labs are beginning to test systems for biological capabilities before deployment. This is valuable but limited—evaluations may miss capabilities that exist but aren’t tested.</p>
<h2 id="governance-proposals">Governance Proposals</h2>
<p>Several proposals aim to strengthen governance of AI-biology dual-use risks.</p>
<h3 id="structured-access">Structured Access</h3>
<p>Rather than releasing powerful AI systems openly, restrict access through APIs that can monitor usage, implement rate limits, and detect concerning queries. This enables beneficial research while creating oversight.</p>
<p>Limitations: Doesn’t address open-weight models. Monitoring at scale is difficult. Sophisticated adversaries may evade detection.</p>
<h3 id="know-your-customer-requirements">Know-Your-Customer Requirements</h3>
<p>Require verification of user identity and legitimate purpose before providing access to powerful AI tools for biological applications. Similar to controls on dangerous chemicals or laboratory equipment.</p>
<p>Limitations: Creates barriers to legitimate research. May concentrate AI biology capabilities in well-resourced institutions.</p>
<h3 id="compute-governance">Compute Governance</h3>
<p>Restrict access to the computational resources needed to train dangerous AI models. As we examined in <a href="/research/023-compute-governance/">compute governance</a>, compute is a potential chokepoint for governance.</p>
<p>Limitations: Applies to training, not inference. Compute governance is difficult to implement internationally. May become less effective as training becomes more efficient.</p>
<h3 id="red-team-standards">Red Team Standards</h3>
<p>Require rigorous biosecurity evaluation before deploying AI systems with biological capabilities. Establish standards for what evaluations must cover and what results warrant deployment restrictions.</p>
<p>Limitations: Evaluations may be incomplete. Standards require expert development and ongoing update. Adversarial actors won’t self-evaluate.</p>
<h3 id="information-hazard-protocols">Information Hazard Protocols</h3>
<p>Develop clearer frameworks for when research on AI-biology capabilities should be restricted from publication. Balance scientific openness against security risks.</p>
<p>Limitations: Restriction from academic publication doesn’t prevent private development. Decisions about what to restrict are controversial.</p>
<h2 id="why-this-is-hard">Why This Is Hard</h2>
<p>The AI-biology case illustrates fundamental tensions in dual-use governance.</p>
<p><strong>Benefit-risk tradeoffs.</strong> AI could massively accelerate beneficial biological research, potentially saving millions of lives. Restrictions that prevent bioweapon development may also slow lifesaving research. No framework cleanly separates benefit from risk.</p>
<p><strong>Openness norms.</strong> Science has traditionally valued openness—replication, peer review, and building on others’ work. Security concerns push toward closure and restriction, creating tension with scientific culture.</p>
<p><strong>Attribution difficulty.</strong> Unlike nuclear weapons, biological weapons development may be difficult to detect and attribute. This undermines deterrence and accountability.</p>
<p><strong>Private development.</strong> Governments and international bodies can regulate public research. Private and underground development is harder to govern.</p>
<p><strong>Speed of change.</strong> Both AI and biology are advancing rapidly. Governance frameworks designed today may be obsolete within years.</p>
<h2 id="the-reflexive-dimension">The Reflexive Dimension</h2>
<p>Our work on reflexive AI governance offers some relevant perspectives.</p>
<p>AI systems could potentially participate in biosecurity governance:</p>
<ul>
<li><strong>Self-restriction.</strong> Systems trained with safety objectives can refuse dangerous requests—a form of <a href="/research/003-machine-readable-constraint-schema/">machine-readable constraint</a>.</li>
<li><strong>Monitoring.</strong> AI systems could monitor for concerning usage patterns, though this raises surveillance concerns.</li>
<li><strong>Explaining limits.</strong> Systems could <a href="/research/026-explaining-constraints/">explain their constraints</a> to users, creating understanding rather than just restriction.</li>
</ul>
<p>However, <a href="/research/013-limits-of-self-constraint/">the limits of self-constraint</a> apply here too. Technical restrictions can be circumvented. Institutional and social governance mechanisms remain essential.</p>
<h2 id="what-might-work">What Might Work</h2>
<p>Given these challenges, effective governance likely requires:</p>
<p><strong>Layered defense.</strong> No single measure is sufficient. Combine technical restrictions, access controls, usage monitoring, norm development, and legal accountability.</p>
<p><strong>Research investment.</strong> The biosecurity implications of AI need more research—both empirical study of current risks and development of better governance tools.</p>
<p><strong>Stakeholder engagement.</strong> AI developers, biologists, biosecurity experts, and policymakers must collaborate. No single community has sufficient expertise.</p>
<p><strong>International coordination.</strong> Given the global nature of both AI and biology, purely national governance is insufficient. But international coordination is difficult to achieve.</p>
<p><strong>Adaptive mechanisms.</strong> Build governance that can evolve as technology advances. Specific technical restrictions will be outdated quickly; robust institutions can adapt.</p>
<p>The stakes are high. Getting AI-biology governance right could mean the difference between an era of biological abundance and an era of biological risk.</p>
<h2 id="further-reading">Further Reading</h2>
<ul>
<li><a href="/research/009-capability-overhang/">The Capability Overhang Problem</a></li>
<li><a href="/research/004-red-lines-taxonomy/">Red Lines: A Taxonomy of Non-Negotiable AI Limits</a></li>
<li><a href="/research/025-when-ai-should-refuse/">When AI Should Refuse: A Framework</a></li>
<li><a href="/research/024-capability-evaluations/">Dangerous Capability Evaluations</a></li>
</ul>  </div> <footer class="article__footer" style="margin-top: var(--space-12); padding-top: var(--space-6); border-top: 1px solid var(--color-border);"> <div class="article-card__meta"> <a href="/tags" class="article-card__tag">dual-use</a><a href="/tags" class="article-card__tag">cbrn</a><a href="/tags" class="article-card__tag">safety</a><a href="/tags" class="article-card__tag">risk-assessment</a><a href="/tags" class="article-card__tag">governance</a> </div> </footer> </article>  <aside class="toc-sidebar" id="toc-sidebar"> <div class="toc-sidebar__inner"> <div class="toc-sidebar__header"> <span class="toc-sidebar__title">On This Page</span> <button class="toc-sidebar__toggle" aria-label="Toggle table of contents" onclick="document.getElementById('toc-sidebar').classList.toggle('collapsed');"> <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M4 6L8 10L12 6" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </button> </div> <ul class="toc-sidebar__list"> <li style="margin-left: 0px"> <a href="#the-dual-use-dilemma">The Dual-Use Dilemma</a> </li><li style="margin-left: 0px"> <a href="#what-ai-can-do-in-biology">What AI Can Do in Biology</a> </li><li style="margin-left: 0px"> <a href="#the-bioweapon-risk">The Bioweapon Risk</a> </li><li style="margin-left: 0px"> <a href="#how-this-connects-to-other-risks">How This Connects to Other Risks</a> </li><li style="margin-left: 0px"> <a href="#current-governance-approaches">Current Governance Approaches</a> </li><li style="margin-left: 12px"> <a href="#existing-biological-weapons-governance">Existing Biological Weapons Governance</a> </li><li style="margin-left: 12px"> <a href="#ai-model-restrictions">AI Model Restrictions</a> </li><li style="margin-left: 12px"> <a href="#biosecurity-communities">Biosecurity Communities</a> </li><li style="margin-left: 12px"> <a href="#capability-evaluations">Capability Evaluations</a> </li><li style="margin-left: 0px"> <a href="#governance-proposals">Governance Proposals</a> </li><li style="margin-left: 12px"> <a href="#structured-access">Structured Access</a> </li><li style="margin-left: 12px"> <a href="#know-your-customer-requirements">Know-Your-Customer Requirements</a> </li><li style="margin-left: 12px"> <a href="#compute-governance">Compute Governance</a> </li><li style="margin-left: 12px"> <a href="#red-team-standards">Red Team Standards</a> </li><li style="margin-left: 12px"> <a href="#information-hazard-protocols">Information Hazard Protocols</a> </li><li style="margin-left: 0px"> <a href="#why-this-is-hard">Why This Is Hard</a> </li><li style="margin-left: 0px"> <a href="#the-reflexive-dimension">The Reflexive Dimension</a> </li><li style="margin-left: 0px"> <a href="#what-might-work">What Might Work</a> </li><li style="margin-left: 0px"> <a href="#further-reading">Further Reading</a> </li> </ul> </div> </aside> </div> <div class="scroll-progress" id="scroll-progress"></div> <script type="module">const s=document.getElementById("scroll-progress");s&&window.addEventListener("scroll",()=>{const o=window.scrollY,e=document.documentElement.scrollHeight-window.innerHeight,t=o/e*100;s.style.width=`${t}%`});const r=document.querySelectorAll(".toc-sidebar__list a"),n=document.querySelectorAll(".article__content h2, .article__content h3");if(r.length>0&&n.length>0){const o=new IntersectionObserver(e=>{e.forEach(t=>{if(t.isIntersecting){r.forEach(i=>i.classList.remove("active"));const c=document.querySelector(`.toc-sidebar__list a[href="#${t.target.id}"]`);c&&c.classList.add("active")}})},{rootMargin:"-20% 0% -60% 0%"});n.forEach(e=>o.observe(e))}</script>  </main> <footer class="footer"> <div class="container footer__inner"> <a href="/" class="footer__brand"> <img src="/logo.png" alt="" class="footer__logo"> <span>Reflexive AI Initiative</span> </a> <div class="footer__links"> <a href="https://github.com/Reflexive-AI" class="footer__link" target="_blank" rel="noopener">GitHub</a> <a href="/research" class="footer__link">Research</a> <a href="/tags" class="footer__link">Tags</a> <a href="/contribute" class="footer__link">Contribute</a> </div> <div class="footer__meta"> <span>Maintained by <a href="https://eugenekondratov.eu" target="_blank" rel="noopener">Eugene Kondratov</a></span> <span>·</span> <a href="https://creativecommons.org/licenses/by/4.0/" class="footer__license" target="_blank" rel="noopener">CC BY 4.0</a> </div> </div> </footer> </body></html>