---
title: "El que els responsables politics entenen malament sobre el risc de la IA"
excerpt: "Concepcions erronies comunes que condueixen a politiques d'IA ineficaces, i com pensar amb mes claredat sobre els riscos reals que plantegen els sistemes avancats d'IA."
date: 2026-01-15
categories:
  - Public
  - Policy Proposal
tags:
  - policy
  - risk-assessment
  - governance
  - regulation
---

## El problema amb el discurs sobre el risc de la IA

Els responsables politics afronten una tasca ingrata. Han de governar una tecnologia que no van crear, que sovint no comprenen completament, i que canvia mes rapid del que els processos legislatius poden acomodar. Sota aquestes condicions, les concepcions erronies son inevitables.

Pero les concepcions erronies condueixen a politiques ineficaces. Els recursos es dirigeixen als problemes equivocats. Els riscos reals queden sense abordar mentre els imaginaris consumeixen l'atencio. Aquesta analisi identifica els errors mes comuns i consequents en com els responsables politics pensen sobre el risc de la IA, i suggereix correccions.

Aixo es basa en el nostre examen de [per que la regulacio de la IA es dificil](/research/018-regulation-is-hard/) i ofereix orientacio concreta per a un pensament politic mes eficac.

## Concepcio erronia 1: El risc de la IA es principalment la perdua de llocs de treball

**L'error.** Molts responsables politics emmarquen la IA principalment com un problema de disrupcio economica. Les audiencies se centren en els impactes sobre l'ocupacio. Les politiques emfatitzen programes de reconversio i xarxes de seguretat social.

**Per que es incorrecte.** Tot i que la disrupcio economica es real i mereix atencio, emmarcar el risc de la IA principalment a traves d'aquesta optica deixa fora els reptes de governanca mes urgents:

- Sistemes d'IA prenent decisions transcendentals sobre la vida de les persones
- Potencial de la IA per facilitar accions nocives a gran escala
- Erosio de la infraestructura epistemica a traves de contingut generat per IA
- Concentracio de poder en les organitzacions que controlen les capacitats de la IA

El desplacament laboral es un problema politic, pero es un de conegut amb eines de resposta establertes. Els reptes nous de la IA requereixen respostes noves.

**Millor enfocament.** La IA presenta multiples categories de risc que requereixen diferents respostes politiques. La disrupcio economica n'es una. Els riscos per a la seguretat, les implicacions per als drets i la concentracio de poder en son d'altres. Les politiques han d'abordar-les totes, no nomes la mes familiar politicament.

## Concepcio erronia 2: Necessitem que els experts en IA ens diguin que fer

**L'error.** Els responsables politics sovint deleguen completament en els experts tecnics, tractant la governanca de la IA com una questio principalment tecnica que han de respondre els qui construeixen la tecnologia.

**Per que es incorrecte.** L'experiencia tecnica es necessaria pero insuficient per a la governanca. Les preguntes centrals no son tecniques:

- Quant de risc es acceptable a canvi de quins beneficis?
- Qui ha d'assumir els costos del desenvolupament de la IA?
- Quins usos de la IA son compatibles amb els drets humans i la dignitat?
- Com s'ha de distribuir el poder sobre la IA?

Aquestes son preguntes politiques, etiques i socials. Els experts tecnics poden informar-les pero no poden respondre-les. Com vam explorar a [el problema de la IA honesta](/research/029-honest-ai/), fins i tot les qestions que semblen tecniques sovint incorporen judicis de valor profunds.

**Millor enfocament.** Utilitzar l'experiencia tecnica per comprendre les capacitats i les limitacions. Utilitzar els processos democratics per realitzar judicis de valor. No confondre ambdues coses.

## Concepcio erronia 3: L'eleccio es innovacio o seguretat

**L'error.** Els debats sobre la governanca de la IA sovint assumeixen un compromis entre innovacio (regulacio minima, desenvolupament mes rapid) i seguretat (mes regulacio, desenvolupament mes lent). Els responsables politics se senten obligats a triar entre competitivitat economica i proteccio.

**Per que es incorrecte.** Aquest enfocament es sovint erroni i sempre incomplet.

Primer, algunes mesures de seguretat tenen un impacte minim en la velocitat d'innovacio. Els requisits de transparencia, la notificacio d'incidents i certs protocols de prova imposen costos modestos mentre milloren significativament la supervisio.

Segon, una IA insegura crea el seu propi fre a la innovacio. Si els sistemes d'IA causen danys significatius, la reaccio sera pitjor que una regulacio prudent. Les industries sovint prefereixen una regulacio predictible a una exposicio incerta a la responsabilitat.

Tercer, l'enfocament del compromis ignora la distribucio. Els beneficis de la innovacio poden recaure en alguns actors mentre els costos de seguretat recauen en d'altres. Les politiques han d'abordar aquesta distribucio, no nomes el conjunt.

**Millor enfocament.** Preguntar: quines mesures de seguretat especifiques es proposen? Quins son els seus costos i beneficis reals? Qui assumeix cadascun? Aquesta analisi granular es mes productiva que els debats abstractes d'innovacio enfront de seguretat.

## Concepcio erronia 4: La IA esta sobrevalorada o es una amenaça existencial

**L'error.** Les discussions sobre el risc de la IA tendeixen cap als extrems. O be la IA es "nomes estadistica" que no justifica atencio especial, o es una amenaça existencial que exigeix accio d'emergencia. Els responsables politics sovint trien un extrem basant-se en les seves posicions politiques previes.

**Per que es incorrecte.** Ambdos enfocaments obstaculitzen una politica eficac.

La visio desestimatoria condueix a una infrainversio en capacitat de governanca. Quan els riscos es materialitzen, la capacitat institucional de resposta es insuficient. Aixo va passar amb la governanca de les xarxes socials: el moment de construir capacitat de supervisio es abans que els problemes es converteixin en crisis.

La visio d'emergencia condueix a intervencions precipitades i mal dissenyades. Tambe pot provocar una reaccio adversa que dificulti la governanca. I en centrar-se en riscos especulatius a llarg termini, pot distreure dels danys concrets a curt termini.

**Millor enfocament.** Prendre la IA seriosament com a repte de governanca sense exigir certesa sobre escenaris extrems. Construir institucions que puguin respondre de manera flexible. Abordar els danys concrets ara mantenint la consciencia dels possibles reptes futurs. Aquest es l'enfocament que defensem al llarg de la nostra recerca sobre [proporcionalitat](/research/001-proportionality-disclosure/) i [avaluacio de capacitats](/research/024-capability-evaluations/).

## Concepcio erronia 5: Els compromisos voluntaris son suficients

**L'error.** Davant la complexitat legislativa i la pressio dels grups d'interes, els responsables politics sovint accepten els compromisos voluntaris de les empreses d'IA com a governanca adequada.

**Per que es incorrecte.** Els compromisos voluntaris presenten debilitats sistematiques:

- Cap mecanisme d'aplicacio quan els compromisos entren en conflicte amb els beneficis
- Participacio selectiva: les empreses amb pitjors practiques no es presenten voluntariament
- Objectius movedissos: els compromisos es poden debilitar silenciosament
- Opacitat: el compliment es autoavaluat

Vam analitzar aquestes dinamiques en detall a [autonotificacio enfront d'auditoria externa](/research/010-self-reporting-vs-audit/). La historia suggereix que els compromisos voluntaris funcionen quan estan recolzats per una amenaça creible de regulacio, no com a alternatives a ella.

**Millor enfocament.** Els compromisos voluntaris poden ser utils per explorar enfocaments de governanca i construir consens. Pero han de precedir, no substituir, els requisits exigibles.

## Concepcio erronia 6: L'enfocament de la Xina fa impossible la governanca

**L'error.** Els responsables politics sovint argumenten que la governanca de la IA es impossible perque la Xina (o altres competidors) no seguira les regles, de manera que qualsevol restriccio simplement posa en desavantatge la industria nacional.

**Per que es incorrecte.** Aquest raonament falla en multiples nivells:

- No tota la governanca te a veure amb la dinamica de la cursa. La seguretat domestica de la IA, prevenir danys als propis ciutadans, importa independentment del que facin altres paisos.
- Els arguments de competencia assumeixen que la governanca principalment restringeix. Pero la governanca tambe pot generar confianca que expandeixi l'adopcio de la IA.
- L'argument demostra massa. Si la competencia internacional fes impossible la governanca, no podriem regular res.
- La Xina, de fet, ha implementat regulacions d'IA significatives, en algunes arees mes restrictives que els enfocaments occidentals.

**Millor enfocament.** Algunes mesures de governanca tenen sentit unilateralment; d'altres requereixen coordinacio internacional. Distingir entre ambdues. No utilitzar la competencia internacional com a excusa per evitar la governanca on no es rellevant.

## Concepcio erronia 7: Hem d'esperar fins que es demostrin els danys

**L'error.** Alguns responsables politics argumenten que la governanca de la IA ha d'esperar fins que es demostrin danys concrets, un enfocament d'"innovacio sense permisos".

**Per que es incorrecte.** Aquest enfocament funciona malament per a la IA per diverses raons:

- Els danys de la IA poden ser dificils de demostrar. La discriminacio algoritmica podria no detectar-se mai sense requisits d'auditoria.
- Alguns danys son irreversibles o catastrofics. Un enfocament d'"esperar i veure" es apropiat per a danys recuperables, no per a catastrofes potencials.
- Quan es demostrin els danys, l'estructura industrial pot dificultar la intervencio. La captura regulatoria es mes facil quan les industries estan establertes.

El [problema de l'excedent de capacitats](/research/009-capability-overhang/) significa que els riscos poden existir pero romandre sense descobrir. Esperar que es demostri el dany pot significar esperar fins que sigui massa tard.

**Millor enfocament.** Utilitzar l'avaluacio basada en riscos. On els danys potencials son greus i irreversibles, la precaucio esta justificada. On els danys son menors i reversibles, enfocaments mes lleugers tenen sentit. L'enfocament escalonat de la Llei d'IA de la UE, amb tots els seus defectes, encerta en aquesta estructura basica.

## Concepcio erronia 8: Els estandards tecnics ho resoldran tot

**L'error.** Els responsables politics de vegades esperen que els estandards tecnics, per a proves de seguretat, fitxes de model, avaluacions d'impacte, puguin substituir la supervisio institucional.

**Per que es incorrecte.** Els estandards tecnics son eines, no solucions. Necessiten:

- Governanca del propi proces d'elaboracio d'estandards (qui decideix?)
- Mecanismes d'aplicacio (que passa quan es violen els estandards?)
- Processos d'adaptacio (com s'actualitzen els estandards?)
- Autoritat d'interpretacio (qui resol l'ambiguitat?)

Els estandards sense institucions son com les lleis de transit sense policia de transit. Descriuen el comportament esperat pero no poden assegurar-lo. Per aixo ens centrem en la [metagovernanca](/research/006-meta-governance-auditors/): governar els propis mecanismes de governanca.

**Millor enfocament.** Els estandards tecnics han d'estar integrats en marcs institucionals que assegurin que el seu desenvolupament es legitim, la seva aplicacio es consistent i el seu compliment es real.

## Cap a un millor pensament politic

Una bona politica d'IA requereix:

**Proporcionalitat.** Ajustar la intensitat de la governanca al risc real, no al rebombori o a la por. Vegeu el nostre [marc de proporcionalitat](/research/001-proportionality-disclosure/).

**Capacitat institucional.** Construir l'experiencia i l'autoritat per governar la IA abans que les crisis forcin respostes precipitades.

**Inclusio de les parts interessades.** Els experts tecnics informen, pero els processos democratics decideixen. Aixo es central en la nostra visio de [governanca reflexiva](/research/030-manifesto/).

**Disseny adaptatiu.** Crear mecanismes de governanca que puguin evolucionar a mesura que canvien la tecnologia i la comprensio.

**Orientacio a l'evidencia.** Exigir evidencia per a les afirmacions sobre costos i beneficis, tant dels defensors de la industria com dels defensors de la seguretat.

El que esta en joc es prou important per justificar una atencio politica seria, i prou important per justificar que les politiques siguin correctes.

## Lectures addicionals

- [Per que "simplement regular la IA" es mes dificil del que sembla](/research/018-regulation-is-hard/)
- [Marcs de responsabilitat per danys de la IA](/research/020-liability-frameworks/)
- [La Llei d'IA de la UE: el que no contempla](/research/019-eu-ai-act-gaps/)
- [Un manifest d'IA reflexiva](/research/030-manifesto/)
