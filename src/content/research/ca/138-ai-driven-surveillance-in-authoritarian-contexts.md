---
title: "La vigilància impulsada per la IA en contextos autoritaris"
excerpt: "Examinem el desplegament de tecnologies de vigilància basades en IA en estats autoritaris, les seves implicacions per als drets humans i les consideracions per a la governança internacional."
date: 2026-02-21
categories:
  - Vigilància
  - Drets Humans
  - Governança de la IA
tags:
  - autoritarisme
  - vigilància
  - governança
  - ètica
version: "1.0"
toc: true
---

**Objecte de Recerca Reflexiva 138**  
*Tipus: Recerca i Política*

## Introducció

L'avenç ràpid de la intel·ligència artificial (IA) ha permès capacitats de vigilància sense precedents. Tot i que les tecnologies de vigilància poden millorar la seguretat pública i optimitzar la governança, el seu ús indegut en contextos autoritaris planteja greus preocupacions sobre la privacitat, la llibertat i els drets humans. Els sistemes de vigilància basats en IA, des del reconeixement facial fins a la policia predictiva, són cada cop més utilitzats per governs que busquen consolidar el poder, reprimir la dissidència i monitoritzar poblacions a gran escala.

Aquest article explora els mecanismes a través dels quals es duu a terme la vigilància amb IA en règims autoritaris, els desafiaments ètics i de governança que planteja, i les possibles intervencions polítiques per mitigar-ne els danys. Analitzant casos concrets, pretenem identificar patrons en l'ús de les tecnologies d'IA i proposar estratègies per a la cooperació internacional que protegeixin els drets fonamentals.

## Els mecanismes de la vigilància amb IA en estats autoritaris

Els sistemes de vigilància amb IA es basen en tecnologies avançades dissenyades per automatitzar la recollida, l'anàlisi i la interpretació de grans quantitats de dades. En contextos autoritaris, aquests sistemes sovint estan optimitzats per al control més que per a la governança, amb components clau que inclouen:

### 1. **Reconeixement facial i identificació biomètrica**
La tecnologia de reconeixement facial s'ha convertit en la pedra angular de la vigilància amb IA. Els governs l'utilitzen amb finalitats que van des d'identificar manifestants fins a fer complir sistemes de crèdit social. Per exemple, l'ús extensiu de reconeixement facial a la Xina, combinat amb la seva xarxa nacional de càmeres de vigilància, permet el seguiment en temps real dels individus. Aquest sistema està integrat amb el Sistema de Crèdit Social del país, que penalitza comportaments considerats indesitjables per l'estat, creant així un mecanisme per fer complir la conformitat.

Les dades biomètriques, com les empremtes dactilars i els escàners d'iris, amplien encara més l'abast de la vigilància, permetent la identificació fins i tot en espais no públics. Aquestes tecnologies sovint operen sense un consentiment significatiu, cosa que planteja preocupacions sobre l'erosió de l'autonomia personal.

### 2. **Policia predictiva i anàlisi del comportament**
Els models d'IA entrenats amb dades històriques de delictes s'utilitzen cada cop més per predir activitats criminals i assignar recursos policials. En règims autoritaris, la policia predictiva sovint apunta a comunitats marginades o opositors polítics. Per exemple, informes de Xinjiang, Xina, indiquen l'ús d'analítiques predictives per identificar persones per a la seva detenció basant-se en patrons de comportament considerats "extremistes".

Els sistemes d'IA conductual analitzen activitats en línia, l'ús de xarxes socials i patrons de comunicació per identificar possibles dissidents. Aquests sistemes sovint es basen en conjunts de dades esbiaixades, reforçant les desigualtats existents i permetent la discriminació patrocinada per l'estat.

### 3. **Recollida massiva de dades i integració**
Els règims autoritaris exploten la capacitat de la IA per processar grans conjunts de dades integrant informació de xarxes socials, telecomunicacions i registres públics. El resultat són perfils complets d'individus, que es poden utilitzar per monitoritzar afiliacions polítiques, pràctiques religioses i activitats econòmiques. Aquests sistemes sovint són opacs, i els ciutadans desconeixen fins a quin punt les seves dades estan sent recollides i analitzades.

El paper de la IA en permetre el "colonialisme de dades", on els estats autoritaris extreuen i exploten dades digitals per a finalitats de vigilància, s'ha discutit àmpliament a [Data Colonialism: Extraction Patterns in AI Training](/research/136-data-colonialism-extraction-patterns-in-ai-trainin).

## Implicacions per als drets humans

El desplegament de tecnologies de vigilància basades en IA en estats autoritaris té conseqüències de gran abast per als drets humans. Tres àrees crítiques de preocupació són:

### 1. **Erosió de la privacitat**
La vigilància impulsada per la IA fonamentalment mina el dret a la privacitat. En règims autoritaris, els individus perden el control sobre la seva informació personal, que es recull, emmagatzema i analitza sense supervisió. Això crea un efecte dissuasiu, on els ciutadans s'autocensuren per evitar atreure l'atenció.

### 2. **Repressió de la dissidència**
Les tecnologies de vigilància sovint es converteixen en armes per silenciar l'oposició política. Monitoritzant activitats de protesta, rastrejant líders dissidents i controlant l'accés a canals de comunicació, els estats autoritaris desmantellen efectivament la societat civil. Aquesta qüestió s'entrecreua amb els desafiaments de governança discutits a [Agentic AI: A Governance Framework](/research/111-agentic-ai-a-governance-framework), particularment pel que fa a l'ús indegut de sistemes autònoms per a la repressió política.

### 3. **Discriminació i biaix**
Els sistemes d'IA entrenats amb conjunts de dades esbiaixades perpetuen desigualtats sistèmiques. En contextos autoritaris, la vigilància afecta desproporcionadament grups ètnics, religiosos o culturals específics. Per exemple, la vigilància dels uigurs a Xinjiang posa de manifest com les tecnologies d'IA poden ser utilitzades per a la discriminació ètnica.

## Desafiaments de governança

Diversos factors compliquen la governança de la vigilància amb IA en estats autoritaris:

### 1. **Manca de transparència**
Els règims autoritaris sistemàticament oculten el funcionament intern dels seus sistemes de vigilància. Sense transparència, la supervisió internacional esdevé gairebé impossible, dificultant els esforços per responsabilitzar els governs per les violacions dels drets humans.

### 2. **Exportació de tecnologies de vigilància**
Els sistemes de vigilància basats en IA desenvolupats en estats autoritaris sovint s'exporten a altres països, estenent pràctiques autoritàries més enllà de les seves fronteres. Les empreses i institucions implicades en aquestes exportacions s'enfronten a dilemes ètics, especialment quan aquestes tecnologies es comercialitzen sota el pretext de la seguretat pública.

### 3. **Marcs internacionals febles**
Els acords internacionals existents sobre privacitat i drets humans van per darrere dels avenços tecnològics. Les iniciatives multilaterals sovint tenen dificultats per imposar restriccions significatives als règims autoritaris a causa de tensions geopolítiques i interessos conflictius.

Els desafiaments de regular els sistemes d'IA a nivell internacional s'han explorat a [Digital Sovereignty and AI Infrastructure](/research/110-digital-sovereignty-and-ai-infrastructure), que destaca el paper de la governança global per abordar riscos sistèmics.

## Recomanacions polítiques

Per mitigar els riscos associats amb la vigilància amb IA en contextos autoritaris, els responsables polítics i les organitzacions internacionals han de prendre mesures decisives. Les recomanacions clau inclouen:

### 1. **Enfortir les normes internacionals**
Els marcs globals, com la Declaració Universal dels Drets Humans, s'han d'actualitzar per abordar els desafiaments específics de la IA. Aquests marcs han d'articular clarament els límits de la vigilància i establir mecanismes de responsabilitat.

### 2. **Promoure la transparència**
Els governs i les empreses implicades en el desenvolupament d'IA haurien de comprometre's amb la transparència en el disseny, el desplegament i l'exportació de tecnologies de vigilància. Les auditories obertes i les revisions independents poden ajudar a identificar i abordar els abusos.

### 3. **Donar suport a la societat civil**
Les organitzacions de la societat civil tenen un paper crucial en la documentació de violacions dels drets humans i la defensa de reformes. El finançament i suport internacional a aquestes organitzacions poden reforçar la seva capacitat per combatre la vigilància autoritària.

### 4. **Regular les exportacions tecnològiques**
Els controls d'exportació sobre tecnologies de vigilància poden impedir que els règims autoritaris adquireixin eines que permetin la repressió. Les estratègies haurien de centrar-se en equilibrar la innovació tecnològica amb les restriccions ètiques.

### 5. **Desenvolupar estàndards ètics per a la IA**
Les directrius ètiques per al desenvolupament d'IA haurien d'incloure disposicions per minimitzar el biaix, protegir la privacitat i prevenir l'ús indegut en contextos de vigilància. Aquests estàndards es poden integrar en acords internacionals per garantir el compliment.

## Conclusió

Les tecnologies de vigilància impulsades per la IA representen una espasa de doble tall: mentre que prometen millorar la governança i la seguretat pública, el seu ús indegut en contextos autoritaris suposa greus amenaces per als drets humans. Afrontar aquests desafiaments requereix esforços coordinats entre governs, societat civil i indústria per establir normes, fer complir la responsabilitat i promoure pràctiques ètiques. Reconèixer els riscos i implementar salvaguardes pot garantir que la IA serveixi com una eina d'empoderament en lloc de repressió.

*Aquest article se centra específicament en la vigilància amb IA en contextos autoritaris. Futures investigacions podrien explorar el paper de la vigilància en societats democràtiques, les limitacions tècniques dels sistemes d'IA i la intersecció de la vigilància amb IA amb la ciberseguretat.*

## Articles relacionats

- [Data Colonialism: Extraction Patterns in AI Training](/research/136-data-colonialism-extraction-patterns-in-ai-trainin)
- [Agentic AI: A Governance Framework](/research/111-agentic-ai-a-governance-framework)
- [Digital Sovereignty and AI Infrastructure](/research/110-digital-sovereignty-and-ai-infrastructure)