---
title: "L'economia de la seguretat de la IA: qui paga i per què importa"
excerpt: "La seguretat costa diners. Qui assumeix aquests costos determina quin treball de seguretat es realitza. Aquest article examina l'economia de la seguretat de la IA: estructures de finançament, desalineacions d'incentius i quins sistemes econòmics donarien suport adequat a la seguretat."
date: 2026-02-04
categories:
  - Governance Analysis
  - Policy Proposal
tags:
  - economics
  - funding
  - incentives
  - safety
  - investment
---

## La seguretat no és gratuïta

La seguretat de la IA requereix recursos: salaris d'investigadors, computació per a experiments, temps per a proves, infraestructura per a auditories. Aquests recursos no són gratuïts.

Qui paga el treball de seguretat determina quin treball es realitza. Si el finançament de la seguretat prové de laboratoris comercials, reflecteix prioritats comercials. Si prové de governs, reflecteix prioritats polítiques. Si prové de la filantropia, reflecteix prioritats dels donants.

Comprendre l'economia de la seguretat de la IA és essencial per entendre per què certs treballs es realitzen i d'altres no.

## El panorama de finançament actual

El finançament de la seguretat de la IA prové de diverses fonts.

### Laboratoris comercials

Les empreses d'IA més grans, OpenAI, Anthropic, Google DeepMind, financen recerca interna en seguretat. Aquest finançament és substancial en termes absoluts però petit en relació amb la inversió en capacitats.

El finançament comercial crea una alineació entre la recerca en seguretat i els interessos de l'empresa. El treball que ajuda les empreses a desplegar de forma segura rep finançament. El treball que podria alentir el desplegament o imposar costos resulta menys atractiu.

Els equips comercials de seguretat també afronten pressions polítiques internes. Els investigadors de seguretat que restringeixen els productes de manera massa agressiva poden veure reduïda la seva influència.

### Filantropia

Les fundacions privades i els individus rics financen una recerca significativa en seguretat de la IA, particularment a institucions acadèmiques i organitzacions sense ànim de lucre. Open Philanthropy ha estat especialment prominent.

El finançament filantròpic permet recerca independent dels interessos comercials. Però reflecteix les visions del món dels donants. Els filàntrops centrats en el risc existencial financen treball sobre risc existencial. El treball sobre danys a curt termini rep menys atenció filantròpica.

El finançament filantròpic també és incert. Les prioritats dels donants canvien. Les fundacions es tanquen. Les agendes de recerca dependents de la filantropia continuada afronten riscos de sostenibilitat.

### Govern

El finançament governamental per a la seguretat de la IA està creixent, però segueix sent limitat en relació amb el finançament de capacitats. Les agències de defensa, els consells de recerca i els organismes reguladors proporcionen cert suport.

El finançament governamental reflecteix prioritats polítiques. La recerca alineada amb la seguretat nacional rep més suport. El treball que podria restringir la indústria nacional resulta menys atractiu.

El finançament governamental també implica burocràcia, requisits d'informes i restriccions que alguns investigadors troben onerosos.

### Acadèmia

Les universitats financen part de la recerca en seguretat de la IA a través de pressupostos acadèmics generals. Aquest finançament és modest i està subjecte als incentius acadèmics estàndard: pressió per publicar, requisits de titularitat, cerca de subvencions.

El finançament acadèmic permet recerca independent, però no és adequat per al treball de seguretat aplicada que requereix infraestructura costosa o iteració ràpida.

## Desalineacions d'incentius

Les estructures de finançament actuals creen desalineacions sistemàtiques.

### La seguretat com a centre de cost

Dins de les organitzacions comercials, la seguretat és típicament un centre de cost: consumeix recursos sense generar ingressos directament. Els centres de cost afronten pressió durant les restriccions pressupostàries.

Això contrasta amb la recerca en capacitats, que es percep com a inversió en avantatge competitiu. Quan els recursos són escassos, els centres de cost es retallen abans que les inversions.

### Curt termini enfront de llarg termini

Les pressions dels resultats trimestrals fomenten el pensament a curt termini. Les inversions en seguretat amb retorns a llarg termini s'infravaloren en relació amb la generació d'ingressos a curt termini.

Això és particularment problemàtic perquè les fallades de seguretat sovint tenen conseqüències a llarg termini: reacció regulatòria, dany reputacional o esdeveniments catastròfics. Però aquestes conseqüències es descompten davant les pressions competitives immediates.

### Externalitats

Les fallades de seguretat sovint imposen costos a tercers: usuaris perjudicats pels sistemes, societat afectada per incidents d'IA, generacions futures que afronten riscos existencials. Aquests costos són externalitats que els desenvolupadors no assumeixen.

Quan els desenvolupadors no assumeixen el cost total de les fallades de seguretat, inverteixen menys en seguretat del que seria socialment òptim.

### Problemes d'aprofitament gratuït

Si una empresa inverteix en recerca de seguretat els beneficis de la qual es comparteixen a tota la indústria, els competidors se n'aprofiten. Això desincentiva la inversió en recerca de seguretat com a bé públic.

La recerca fonamental en seguretat que beneficia tothom pot estar infrafinançada perquè cap actor individual captura retorns suficients.

## Com seria un finançament adequat?

Com sabríem si la seguretat de la IA està adequadament finançada?

### Proporcionalitat

Un punt de referència: despesa en seguretat proporcional a la despesa en capacitats. Si el 10% dels recursos es destinessin a seguretat, això podria representar una atenció adequada.

Les proporcions actuals són molt inferiors. Les estimacions varien, però la despesa en seguretat probablement representa entre l'1% i el 5% de la R+D en IA dels principals laboratoris.

### Inversió ajustada al risc

La inversió hauria de ser proporcional al risc. Els sistemes de major risc justifiquen una major inversió en seguretat. La inversió actual no segueix òbviament aquest patró.

Això requeriria sistemes per avaluar el risc, que per si mateixos estan poc desenvolupats.

### Comparació amb altres sectors

Altres sectors d'alt risc (farmacèutic, aeroespacial, nuclear) tenen normes establertes de despesa en seguretat. La inversió en seguretat de la IA podria comparar-se amb aquests sectors.

Aquesta comparació suggereix que la seguretat de la IA està dramàticament infrainvertida en relació amb els riscos involucrats.

## Mecanismes de polítiques públiques

Diversos mecanismes de polítiques públiques podrien alterar l'economia de la seguretat de la IA.

### Responsabilitat legal

Si les empreses assumeixen responsabilitat financera pels danys de la IA, internalitzen els costos de les externalitats. Això crea incentius per a la inversió en seguretat proporcional al risc.

Els [marcs de responsabilitat](/research/020-liability-frameworks/) requereixen que els danys siguin atribuïbles i recuperables. Les estructures legals actuals dificulten això.

### Fiscalitat i subvencions

Els governs podrien gravar els sistemes d'IA de forma proporcional al risc i utilitzar els ingressos per finançar recerca en seguretat. Això internalitzaria les externalitats i finançaria béns públics simultàniament.

Alternativament, les subvencions per a la recerca en seguretat podrien augmentar la inversió sense necessitat de reformes en matèria de responsabilitat.

### Requisits regulatoris

Les inversions obligatòries en seguretat, similars als requisits d'assajos farmacèutics, podrien garantir nivells mínims de despesa.

Aquest enfocament requereix reguladors capaços d'especificar i verificar una inversió adequada en seguretat, cosa que actualment és deficient.

### Assegurances

Les assegurances obligatòries per als sistemes d'IA crearien incentius de mercat per a la seguretat. Les asseguradores fixarien el preu del risc i exigirien mesures de seguretat.

Els [mercats d'assegurances](/research/036-insurance-markets/) podrien convertir-se així en mecanismes de governança, amb la fixació de preus incentivant la inversió en seguretat.

### Acords col·lectius

Els acords sectorials sobre despesa en seguretat impedirien que empreses individuals obtinguessin avantatge escatimant en seguretat.

Aquests acords afronten problemes de coordinació i preocupacions antimonopoli, però tenen precedents en altres sectors.

## El problema dels béns públics

Part de la recerca en seguretat és un bé públic: els seus beneficis són no excloïbles i no rivals. La recerca en interpretabilitat, els marcs de governança i els estàndards de seguretat beneficien tothom.

Els béns públics estan clàssicament infrafinançats pels mercats. El finançament governamental o filantròpic és la solució estàndard.

Això suggereix que, fins i tot si els incentius comercials s'alineen per al treball de seguretat propietari, la recerca en seguretat com a bé públic pot seguir infrafinançada sense una intervenció deliberada.

Possibles enfocaments:

- **Instituts de recerca governamentals** dedicats a la seguretat de la IA, anàlegs als laboratoris nacionals en altres àmbits
- **Contribucions obligatòries** a la recerca compartida en seguretat, similars als consorcis industrials en altres sectors
- **Tractament fiscal** que afavoreixi la recerca oberta en seguretat enfront del treball propietari
- **Cooperació internacional** per finançar béns públics globals en seguretat de la IA

## Qui decideix les prioritats?

Més enllà del finançament total, qui decideix quin treball de seguretat prioritzar?

Les estructures actuals concentren la fixació de prioritats entre un petit nombre d'actors: la direcció dels laboratoris, els principals filàntrops i els funcionaris governamentals. Això genera riscos de punts cecs, biaixos i captura.

Estructures alternatives podrien ampliar la fixació de prioritats:

- **Fonts de finançament diverses** impedeixen que un sol actor domini
- **Participació comunitària** a les agendes de recerca incorpora perspectives més àmplies
- **Avaluació independent** de les bretxes de seguretat identifica àrees amb inversió insuficient
- **Rotació dels decisors** prevé els avantatges de la incumbència

## Conclusió

La seguretat de la IA està configurada per l'economia. Les estructures actuals creen una infrainversió sistemàtica, particularment en béns públics i riscos a llarg termini.

Abordar això requereix canviar els incentius: internalitzar les externalitats mitjançant la responsabilitat legal, finançar béns públics mitjançant la fiscalitat o la filantropia, i coordinar-se per prevenir l'aprofitament gratuït.

La qüestió no és només "hi ha prou seguretat?", sinó "qui paga, qui decideix i quin treball en resulta?" L'anàlisi econòmica és essencial per respondre aquestes preguntes.

## Recerca relacionada

- [Liability Frameworks for AI Harm](/research/020-liability-frameworks/)
- [Insurance Markets and AI Risk Pricing](/research/036-insurance-markets/)
- [The Speed-Safety Tradeoff: Making the Implicit Explicit](/research/077-speed-safety-tradeoff/)
- [The Game Theory of AI Disclosure](/research/067-game-theory-disclosure/)
