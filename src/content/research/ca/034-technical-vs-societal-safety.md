---
title: "Seguretat tecnica enfront de seguretat social: problemes diferents"
excerpt: "Per que fer que els sistemes d'IA funcionin segons el previst es un repte diferent de fer que el desenvolupament de la IA sigui bo per a la societat, i per que confondre'ls condueix a una governanca deficient."
date: 2026-01-16
categories:
  - Governance Analysis
  - Public
tags:
  - safety
  - alignment
  - governance
  - ethics
---

## Dos significats de "seguretat de la IA"

Quan algu diu que treballa en "seguretat de la IA", pot referir-se a dues coses molt diferents.

**La seguretat tecnica** se centra a fer que els sistemes d'IA es comportin segons el previst. Aixo inclou evitar que els sistemes produeixin resultats nocius, evitar comportaments no desitjats, garantir la robustesa davant entrades adversaries i construir una IA que faci de manera fiable el que els seus operadors volen.

**La seguretat social** se centra a fer que el desenvolupament de la IA sigui beneficios per a la humanitat. Aixo inclou distribuir els beneficis de la IA de manera justa, prevenir la concentracio de poder, protegir els drets i la democracia, i assegurar que la IA serveixi al benestar collectiu en lloc d'interessos limitats.

Aquests problemes se superposen pero son fonamentalment diferents. Confondre'ls condueix a un discurs confus i a una governanca deficient.

Aquesta analisi examina per que la distincio importa, com la confusio causa problemes i que significa aixo per a la governanca de la IA.

## El problema de la seguretat tecnica

La seguretat tecnica es principalment un repte d'enginyeria. L'objectiu son sistemes d'IA fiables, predictibles i controlables.

### Preguntes clau

- Com especifiquem el que volem que faci la IA amb prou precisio perque realment ho faci? (El problema d'alineament que vam explorar a [que significa realment l'alineament](/research/016-what-alignment-means/).)
- Com evitem que la IA produeixi resultats nocius com instruccions perilloses o contingut manipulador?
- Com assegurem que els sistemes d'IA es comportin de manera consistent en diferents contextos i amb diferents entrades?
- Com mantenim la supervisio humana a mesura que els sistemes es tornen mes autonoms?

### Qui hi treballa

La seguretat tecnica es treballada principalment per investigadors d'aprenentatge automatic, sovint dins dels laboratoris d'IA. Es una agenda de recerca tecnica amb articles, punts de referencia i experiments.

### Com es l'exit

Un sistema d'IA tecnicament segur fa el que els seus operadors pretenen, no produeix resultats nocius i pot ser controlat i supervisat de manera fiable. Funciona segons el disseny.

### Limitacions

Un sistema tecnicament segur encara pot causar dany social. Un sistema de vigilancia que identifica perfectament els dissidents es tecnicament exitosos pero socialment nociu. Un algorisme de recomanacio que maximitza eficientment la participacio pot ser tecnicament robust mentre soscava la salut mental o el discurs democratic.

La seguretat tecnica es necessaria pero no suficient per a una IA beneficiosa.

## El problema de la seguretat social

La seguretat social es principalment un repte politic i institucional. L'objectiu es un desenvolupament de la IA que beneficii ampliament la humanitat.

### Preguntes clau

- Qui controla les decisions de desenvolupament i desplegament de la IA?
- Com es distribueixen els beneficis i costos de la IA a la societat?
- Quines proteccions existeixen per als qui son perjudicats pels sistemes d'IA?
- Com prevenim que la IA s'utilitzi per concentrar poder o soscavar la democracia?
- Quines estructures institucionals asseguren que la IA serveixi als interessos collectius?

### Qui hi treballa

La seguretat social es treballada per una comunitat diversa: responsables politics, defensors de la societat civil, juristes, etics, cientifics socials i, cada vegada mes, investigadors tecnics que reconeixen que les solucions tecniques soles son insuficients.

### Com es l'exit

Un desenvolupament d'IA socialment segur produeix beneficis amplis, inclou proteccions robustes per als vulnerables, mante la governanca democratica i preveu la concentracio perillosa de poder. La tecnologia serveix la humanitat en lloc del contrari.

### Limitacions

Les mesures de seguretat social no poden substituir les capacitats tecniques. Cap quantitat de governanca pot fer fiable un sistema poc fiable. I les intervencions socials sovint no poden seguir el ritme del canvi tecnic.

## Com la confusio causa problemes

Quan no distingim entre seguretat tecnica i social, sorgeixen diversos problemes.

### Investigadors tecnics que afirmen resoldre problemes politics

El treball en seguretat tecnica es valuos, pero no pot respondre a preguntes com "a qui ha de servir la IA?" o "com s'han de distribuir els beneficis?" Quan els investigadors tecnics insinuen que la recerca sobre alineament resol la governanca de la IA, es passen, i potencialment distreuen de la necessaria participacio politica.

Aixo esta relacionat amb el que vam identificar a [el problema de la IA honesta](/research/029-honest-ai/): les solucions tecniques incorporen judicis de valor, pero aquests judicis s'han de fer explicitament a traves de processos democratics, no implicitament a traves de decisions d'enginyeria.

### Responsables politics que deleguen en "solucions" tecniques

Els responsables politics de vegades tracten la governanca de la IA com un problema tecnic que els experts tecnics han de resoldre. Aixo suposa abdicar de la responsabilitat democratica. Les preguntes sobre el risc acceptable, la distribucio de beneficis i els drets fonamentals son qestions politiques que requereixen decisions politiques.

Com vam discutir a [el que els responsables politics entenen malament sobre el risc de la IA](/research/033-policymaker-misconceptions/), l'experiencia tecnica ha d'informar la governanca pero no pot substituir la deliberacio democratica.

### Equips de seguretat fent etica (i viceversa)

Les empreses d'IA sovint confonen els equips de seguretat i d'etica, donant-los mandats superposats. Aixo pot funcionar be quan els problemes genuinament se superposen. Pero tambe pot significar que cap problema rep l'atencio adequada: les preocupacions etiques es tracten com a problemes d'enginyeria, mentre que els problemes d'enginyeria es dilueixen amb consideracions socials mes amples.

### No veure la interseccio

De vegades els problemes requereixen tant solucions tecniques com socials. El biaix algoritmic, per exemple, te aspectes tecnics (com els sistemes amplifiquen els biaixos de les dades d'entrenament) i aspectes socials (quins biaixos importen, que requereix l'equitat, qui decideix). Abordar nomes una dimensio deixa el problema sense resoldre.

## On s'intersequen

Els problemes no estan completament separats. Diverses qestions requereixen abordar ambdues dimensions.

### Poder i control

Les qestions tecniques sobre la controlabilitat de la IA es connecten amb les qestions socials sobre qui controla la IA. Un sistema que es tecnicament controlable pero controlat per actors nocius no es segur en cap sentit significatiu.

### Transparencia i rendicio de comptes

La recerca tecnica en interpretabilitat es connecta amb les demandes socials de rendicio de comptes. Pero els sistemes transparents encara poden ser mal utilitzats, i la rendicio de comptes requereix infraestructura institucional mes enlla de les capacitats tecniques.

### Capacitat i risc

Els nivells de capacitat tecnica tenen implicacions socials. Els sistemes mes capacos creen riscos socials mes grans si la governanca es inadequada. Les decisions tecniques sobre quines capacitats desenvolupar son, per tant, tambe decisions socials.

### Concentracio

Les economies d'escala tecniques en el desenvolupament d'IA es connecten amb les preocupacions socials sobre la concentracio de poder. El fet que la IA de frontera requereixi recursos massius es tant una realitat tecnica com un repte de governanca.

## Implicacions per a la governanca

Aquesta distincio te implicacions practiques per a com governem la IA.

### Supervisio separada pero coordinada

La seguretat tecnica i l'impacte social requereixen mecanismes de supervisio diferents. Els organismes d'estandards tecnics han d'abordar el comportament dels sistemes. Les institucions democratiques han d'abordar les condicions de desplegament, la proteccio de drets i la distribucio de beneficis. Aquests organismes s'han de coordinar pero no fusionar.

### Diferent experiencia per a diferents problemes

La seguretat tecnica requereix experiencia en aprenentatge automatic. La seguretat social requereix experiencia diversa: dret, economia, etica, ciencies socials, coneixement del domini. Les estructures de governanca han d'incorporar ambdues sense confondre-les.

### Multiples intervencions en multiples punts

Les intervencions tecniques durant el desenvolupament (proves, verificacio, monitoratge) aborden la seguretat tecnica. Les intervencions socials al voltant del desplegament (llicencies, auditoria, responsabilitat) aborden la seguretat social. Ambdues son necessaries; cap es suficient.

### No deixar que una substitueixi l'altra

Els desenvolupadors d'IA no han d'afirmar que el treball en seguretat tecnica aborda les preocupacions socials. Els responsables politics no han d'assumir que la governanca pot substituir la robustesa tecnica. Cada problema requereix les seves propies solucions.

## La connexio reflexiva

El nostre treball sobre governanca reflexiva intenta fer de pont entre aquests dominis. La idea que [els sistemes d'IA poden participar en la seva propia governanca](/research/030-manifesto/) es tant una proposta tecnica (sistemes que informen restriccions, expliquen limits) com social (fer la IA mes llegible i responsable).

Les [restriccions llegibles per maquina](/research/003-machine-readable-constraint-schema/) son un artefacte tecnic que serveix a proposits socials. Els [protocols de comunicacio d'IA a regulador](/research/014-ai-regulator-protocol/) requereixen tant infraestructura tecnica com capacitat institucional.

Aquesta integracio es la contribucio distintiva dels enfocaments reflexius: reconeixer que el tecnic i el social son diferents pero han d'estar connectats, i construir ponts que respectin ambdos dominis.

## Lectures addicionals

- [Que significa realment l'alineament](/research/016-what-alignment-means/)
- [El problema de la IA honesta](/research/029-honest-ai/)
- [Un manifest d'IA reflexiva](/research/030-manifesto/)
- [El que els responsables politics entenen malament sobre el risc de la IA](/research/033-policymaker-misconceptions/)
