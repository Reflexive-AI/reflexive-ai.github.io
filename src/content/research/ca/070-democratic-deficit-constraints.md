---
title: "Qui decideix què hauria de rebutjar la IA? El dèficit democràtic en el disseny de restriccions"
excerpt: "Els rebutjos de la IA codifiquen judicis de valor. Actualment, petits equips als laboratoris d'IA prenen aquestes decisions. Això és legítim? Exploració del dèficit democràtic en el disseny de restriccions de la IA i possibles alternatives."
date: 2026-02-04
toc: true
categories:
  - Governance Analysis
  - Public
tags:
  - democracy
  - legitimacy
  - refusals
  - constraints
  - participation
---

## El poder ocult

Quan un sistema d'IA rebutja una sol·licitud, emet un judici de valor. Ha determinat que la sol·licitud queda fora del que hauria de fer. Aquesta determinació reflecteix decisions preses per algú, en algun lloc, sobre el que els sistemes d'IA haurien i no haurien de permetre.

Qui pren aquestes decisions?

Actualment: petits equips d'investigadors, personal de polítiques i executius a empreses d'IA. Aquests equips decideixen si rebutjar sol·licituds sobre armes, drogues, política, sexualitat, religió i innombrables altres dominis. Les seves decisions modelen el que milers de milions d'usuaris poden i no poden fer amb la IA.

Aquesta és una concentració de poder notable. I planteja una pregunta de legitimitat: amb quina autoritat aquests equips prenen decisions carregades de valors per al món?

## La magnitud del problema

Considerem la gamma de decisions incorporades en les polítiques de rebutg de la IA.

**Qüestions polítiques en disputa.** Haurien els sistemes d'IA de discutir sobre l'avortament, els drets d'armes o la immigració? Haurien de negar-se a ajudar amb activitats legals que alguns consideren immorals? Haurien de negar-se a criticar governs, religions o ideologies?

**Variació cultural.** El que es considera ofensiu varia entre cultures. El que és educació sexual acceptable en un país és contingut prohibit en un altre. Les normes de qui haurien d'aplicar els sistemes globals?

**Capacitats de doble ús.** Moltes capacitats tenen usos tant beneficiosos com danyosos. El coneixement de química permet la medicina i les armes. L'assistència en programació permet la seguretat i els atacs. On s'haurien de traçar les línies?

**Casos límit.** Hauria la IA d'ajudar un adolescent a escriure un assaig persuasiu argumentant a favor de reduir l'edat per beure? Hauria de simular ser un terapeuta? Hauria de generar contingut que és legal però estigmatitzat?

Aquestes no són preguntes tècniques. Són preguntes de valors. Diferents persones raonables, informades per diferents cultures, experiències i creences, les respondrien de forma diferent.

## La situació actual

A la pràctica, les empreses d'IA prenen aquestes decisions a través de:

**Equips interns de polítiques.** Les empreses empren professionals de confiança i seguretat que redacten polítiques de contingut i directrius de rebutg. Aquests equips tenen experiència rellevant però representen una demografia i un conjunt de valors estrets.

**Entrenament RLHF.** Avaluadors humans qualifiquen les sortides dels models. Les seves preferències modelen el comportament del model. Qui són aquests avaluadors? Majoritàriament contractistes, sovint en països de salaris baixos, seleccionats i gestionats per les empreses.

**Retroalimentació de red teams.** Les proves adversarials identifiquen modes de fallada. Els red teams influeixen en quins comportaments es consideren prou problemàtics per abordar.

**Judici executiu.** En última instància, els executius de les empreses aproven les polítiques. Els seus incentius inclouen la posició competitiva, el risc regulatori i les preocupacions reputacionals juntament amb la seguretat.

**Pressió regulatòria.** Els requisits governamentals en diferents jurisdiccions modelen les polítiques. Això introdueix una mica de participació externa però reflecteix els valors de governs poderosos, no necessàriament de les poblacions afectades.

Aquest procés no és [transparent](/research/001-proportionality-disclosure/). Els usuaris no saben què rebutjaran els sistemes d'IA fins que es troben amb els rebutjos. El raonament darrere de les polítiques rarament es publica. No existeix un mecanisme sistemàtic perquè les parts afectades proporcionin la seva opinió.

## Per què això importa

El dèficit democràtic en el disseny de restriccions importa per diverses raons.

**Legitimitat.** Les decisions que afecten milers de milions haurien de reflectir alguna forma de consentiment o representació. La discreció corporativa pura no satisfà aquest estàndard, independentment de com reflexius siguin els prenedors de decisions.

**Precisió.** Els equips estrets ometen perspectives que una participació més àmplia captaria. Les polítiques de restricció desenvolupades per treballadors tecnològics de Silicon Valley no reflecteixen les necessitats i valors d'usuaris a tot el món.

**Confiança.** Els usuaris que no entenen per què els sistemes rebutgen poden desconfiar-ne. La manca de participació fomenta la sospita sobre agendes ocultes.

**Rendició de comptes.** Qui és responsable quan les polítiques de rebutg causen dany? Si un sistema es nega a discutir la prevenció del suïcidi perquè el tema sembla arriscat, qui assumeix la responsabilitat per la persona que necessitava aquella informació?

**Biaix.** Els equips homogenis reprodueixen els seus biaixos en el disseny de restriccions. El que sembla neutral per als professionals de la indústria tecnològica incorpora suposicions polítiques o culturals particulars.

## Possibles alternatives

Existeixen diverses alternatives a la discreció corporativa pura, cadascuna amb compensacions.

### Mandats regulatoris

Els governs podrien especificar què han de rebutjar els sistemes d'IA. Això introdueix participació democràtica a través de representants electes.

**Avantatges:** Proporciona legitimitat en societats democràtiques. Crea requisits legals clars. Permet la rendició de comptes a través de processos polítics.

**Desavantatges:** Diferents jurisdiccions tenen diferents valors. Els mandats governamentals poden reflectir preferències de la majoria que perjudiquen les minories. La regulació es mou lentament mentre la tecnologia evoluciona ràpidament. Els governs autoritaris podrien exigir restriccions danyoses.

### Consulta pública

Les empreses podrien sol·licitar opinions del públic sobre les polítiques de restricció abans de la implementació, similar als processos de comentari públic en l'elaboració de regulacions.

**Avantatges:** Incorpora perspectives diverses. Crea transparència sobre el desenvolupament de polítiques. Senyalitza respecte per les parts afectades.

**Desavantatges:** Afavoreix els grups organitzats sobre els públics difusos. No pot resoldre desacords profunds de valors. Podria tornar-se performativa en lloc de substantiva.

### Personalització per l'usuari

Dins de certs límits, els usuaris podrien personalitzar els nivells de restricció. Un investigador pot deshabilitar rebutjos per a consultes acadèmiques. Un pare pot reforçar les restriccions per al compte d'un fill.

**Avantatges:** Respecta l'autonomia de l'usuari. Reconeix la variació legítima en les necessitats. Redueix els conflictes de talla única.

**Desavantatges:** Algunes restriccions no haurien de ser personalitzables (com les [línies vermelles](/research/004-red-lines-taxonomy/)). Els usuaris sofisticats poden explotar la personalització per accedir a capacitats danyoses. Crea complexitat i potencial de confusió.

### Governança participativa

Les polítiques de restricció podrien desenvolupar-se a través de processos que incloguin empreses, societat civil, governs i representants d'usuaris. Això s'assembla als models multiactor de la [governança d'internet](/research/066-internet-governance-lessons/).

**Avantatges:** Incorpora perspectives diverses institucionalment. Crea rendició de comptes contínua. Permet la negociació entre interessos.

**Desavantatges:** Lent i potencialment capturat per actors poderosos. No existeix un mecanisme clar per resoldre desacords. La legitimitat dels "representants" pot ser qüestionada.

### Supervisió electa

Els òrgans democràtics podrien supervisar les polítiques de restricció de la IA, de manera similar a com els funcionaris electes supervisen altres institucions poderoses.

**Avantatges:** Màxima legitimitat democràtica. Rendició de comptes clara.

**Desavantatges:** Els polítics manquen d'experiència tècnica. Els cicles electorals creen inestabilitat. La tecnologia global governada per la política nacional crea fragmentació.

## Un enfocament reflexiu

La Reflexive AI Initiative proposa que els mateixos sistemes d'IA poden contribuir a aquest problema, encara que no resoldre'l.

**Restriccions transparents.** Els [esquemes de restriccions llegibles per màquines](/research/003-machine-readable-constraint-schema/) fan les polítiques explícites i comparables. Els usuaris poden veure quines restriccions existeixen en lloc de descobrir-les per assaig i error.

**Explicació dels rebutjos.** Els sistemes que [expliquen les seves restriccions](/research/026-explaining-constraints/) ajuden els usuaris a comprendre el raonament darrere dels rebutjos, fins i tot si no hi estan d'acord.

**Mecanismes de retroalimentació.** Els sistemes poden recopilar retroalimentació estructurada sobre els rebutjos, identificant patrons on les restriccions poden ser inapropiades.

**Auditoria de restriccions.** Els auditors independents poden avaluar si les restriccions declarades coincideixen amb el comportament real, fent que les empreses rendeixin comptes de les seves polítiques publicades.

Aquests mecanismes no resolen la pregunta de legitimitat. No responen qui hauria de decidir. Però creen infraestructura per a la rendició de comptes independentment de qui decideixi.

## No hi ha solució perfecta

No existeix una solució perfecta al dèficit democràtic. Cada alternativa té debilitats.

Els mandats regulatoris requereixen governs que representin les seves poblacions, estiguin d'acord entre si i puguin mantenir el ritme de la tecnologia. Aquestes condicions sovint no es compleixen.

La consulta pública pot convertir-se en teatre. La personalització per l'usuari pot crear asimetries danyoses. La governança multiactor pot ser capturada. La supervisió electa pot ser polititzada.

La pregunta no és quina solució perfecta adoptar sinó quina combinació imperfecta perseguir. Alguns principis poden guiar aquesta elecció:

**Transparència.** Qualsevol que sigui el procés, les restriccions resultants haurien de ser públiques i comprensibles.

**Rendició de comptes.** Algú hauria de respondre per les decisions de restricció i les seves conseqüències.

**Parts afectades.** Qui es veu afectat per les restriccions hauria de tenir alguna veu en el seu disseny.

**No negociables protegits.** Les [línies vermelles](/research/004-red-lines-taxonomy/) que prevenen danys catastròfics no haurien d'estar subjectes a l'anul·lació de l'usuari ni a la negociació política.

**Adaptabilitat.** Els processos de restricció haurien de permetre l'actualització a mesura que millora la comprensió i canvien els contextos.

## Conclusió

El dèficit democràtic en el disseny de restriccions de la IA no és un problema tècnic que requereixi una solució tècnica. És un problema polític que requereix solucions polítiques.

Actualment, petits equips prenen decisions carregades de valors que afecten milers de milions. Aquesta concentració de poder és inevitable en el desplegament primerenc de la IA, però no és òbviament legítima.

Avançar cap a un disseny de restriccions més legítim requereix transparència sobre els processos actuals, mecanismes per a una participació més àmplia i rendició de comptes pels resultats. També requereix acceptar que els desacords de valors són genuïns i no es resoldran amb millors algorismes o més dades.

El marc de governança reflexiva contribueix amb infraestructura per a la rendició de comptes sense resoldre la pregunta subjacent de legitimitat. Aquesta pregunta requereix innovació política i institucional, no només desenvolupament tècnic.

## Recerca relacionada

- [Un esquema de restriccions llegible per màquines](/research/003-machine-readable-constraint-schema/)
- [Línies vermelles: una taxonomia de límits no negociables de la IA](/research/004-red-lines-taxonomy/)
- [Sistemes d'IA que expliquen les seves restriccions](/research/026-explaining-constraints/)
- [Participació pública en la política d'IA](/research/045-public-participation/)
- [El paper de la societat civil en la governança de la IA](/research/044-civil-society-role/)
