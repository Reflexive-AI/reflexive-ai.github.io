---
title: "IA d'us dual: el cas de la recerca biologica"
excerpt: "Com la IA esta transformant la recerca biologica, i per que les mateixes capacitats que podrien curar malalties podrien facilitar armes biologiques. Un estudi de cas en governanca d'us dual."
date: 2026-01-17
categories:
  - Governance Analysis
tags:
  - dual-use
  - cbrn
  - safety
  - risk-assessment
  - governance
---

## El dilema de l'us dual

Algunes tecnologies son inherentment d'us dual: les mateixes capacitats que permeten aplicacions beneficioses tambe permeten aplicacions nocives. La fisica nuclear ens dona tant centrals electriques com armes. La criptografia protegeix tant dissidents com delinquents.

La IA aplicada a la recerca biologica es potser l'exemple contemporani mes important de tecnologia d'us dual. Els mateixos sistemes d'IA que podrien accelerar el descobriment de farmacs, predir estructures de proteines i dissenyar terapies noves tambe podrien potencialment ajudar actors maliciosos a crear patogens perillosos.

Aquesta analisi examina el problema d'us dual entre IA i biologia com un estudi de cas en reptes de governanca: com podem capturar els beneficis mitigant al mateix temps els riscos catastrofics.

## El que la IA pot fer en biologia

Les capacitats de la IA en la recerca biologica han avancat dramaticament.

**Prediccio d'estructures de proteines.** AlphaFold i sistemes similars poden predir com les proteines es pleguen en estructures tridimensionals a partir de les seves sequencies d'aminoacids. Aixo accelera el descobriment de farmacs, la comprensio de malalties i la recerca biologica fonamental.

**Disseny molecular.** Els sistemes d'IA poden dissenyar molecules noves amb propietats desitjades: farmacs potencials, catalitzadors i materials. Aixo podria accelerar dramaticament el desenvolupament farmaceutic.

**Analisi genomica.** La IA pot identificar patrons en dades genomiques que serien impossibles de detectar per als humans, avancant en la comprensio de malalties genetiques i tractaments potencials.

**Automatitzacio de laboratoris.** Els sistemes d'IA controlen cada vegada mes els equips de laboratori, permetent experiments mes rapids i dissenys experimentals nous.

**Planificacio de sintesi.** La IA pot determinar com sintetitzar molecules complexes, proporcionant instruccions pas a pas per a la produccio quimica.

Aquestes capacitats ja estan transformant la recerca biologica. Tambe son la rao per la qual els experts en seguretat estan preocupats.

## El risc d'armes biologiques

Les mateixes capacitats de la IA que acceleren la recerca beneficiosa podrien potencialment accelerar el desenvolupament d'armes.

**Disseny de patogens.** Els sistemes d'IA que comprenen les estructures de les proteines i l'evasio immunologica podrien potencialment ajudar a dissenyar patogens que siguin mes transmissibles, mes letals o mes resistents als tractaments.

**Orientacio per a la sintesi.** La IA que proporciona instruccions de sintesi per a molecules beneficioses tambe podria proporcionar instruccions per a molecules perilloses. Un sistema d'IA que ajuda els investigadors a sintetitzar un farmac potencial podria, sense les salvaguardes adequades, ajudar actors maliciosos a sintetitzar una toxina.

**Reduccio de barreres.** Potser el mes preocupant es que la IA podria reduir les barreres d'experiencia per al desenvolupament d'armes biologiques. Crear patogens perillosos actualment requereix habilitats de laboratori sofisticades i un coneixement biologic profund. L'assistencia de la IA podria fer que aquestes activitats siguin accessibles per a aquells que no tenen l'experiencia tradicional.

**Acceleracio.** Fins i tot si la IA no permet res que no fos teoricament possible abans, podria accelerar dramaticament els terminis de desenvolupament. Una arma biologica que portaria a un actor estatal anys de desenvolupament podria ser assolible en mesos amb assistencia d'IA.

Aquesta es l'essencia de l'us dual: les capacitats que son beneficioses en contextos legitims es tornen perilloses quan s'apliquen amb intencio maliciosa.

## Com aixo es connecta amb altres riscos

El problema d'us dual entre IA i biologia es connecta amb reptes de governanca mes amplis que hem explorat.

**Excedent de capacitats.** Com vam discutir a [el problema de l'excedent de capacitats](/research/009-capability-overhang/), els sistemes d'IA poden tenir capacitats perilloses que no son conegudes publicament ni provades. Aixo es particularment preocupant per a la biologia, on les capacitats perilloses podrien no descobrir-se fins que s'utilitzin indegudament.

**Dilemes de divulgacio.** Quant s'ha de divulgar sobre les capacitats de la IA en biologia? Publicar recerca permet aplicacions beneficioses pero tambe informa els adversaris. Aixo connecta amb la nostra analisi de [la proporcionalitat en la divulgacio](/research/001-proportionality-disclosure/).

**Els limits del refus.** Vam explorar [quan la IA ha de refusar](/research/025-when-ai-should-refuse/) sollicituds. La recerca biologica presenta casos dificils: les sollicituds d'informacio sobre sintesi poden ser recerca legitima o preparacio d'armes biologiques, i els sistemes d'IA no tenen prou context per distingir de manera fiable.

**Linies vermelles.** Algunes capacitats podrien justificar restriccions absolutes. La nostra [taxonomia de limits no negociables de la IA](/research/004-red-lines-taxonomy/) va identificar l'assistencia amb armes QBRN (quimiques, biologiques, radiologiques, nuclears) com una possible linia vermella. Pero tracar la linia amb precisio es dificil.

## Enfocaments actuals de governanca

Diversos mecanismes de governanca intenten abordar els riscos entre IA i biologia.

### Governanca existent d'armes biologiques

La Convencio sobre Armes Biologiques (CAB) prohibeix el desenvolupament i la produccio d'armes biologiques. No obstant aixo, no te mecanismes de verificacio ni capacitat d'aplicacio. Va ser dissenyada per a actors estatals i s'adapta malament a les amenaces habilitades per IA d'actors no estatals.

### Restriccions de models d'IA

Els principals laboratoris d'IA implementen restriccions sobre informacio biologica. Els sistemes son entrenats per refusar sollicituds d'instruccions per a la creacio de patogens, la sintesi de molecules perilloses i consultes similars.

No obstant aixo, aquestes restriccions afronten reptes:

- **Evasio.** Els usuaris de vegades poden fer que els sistemes d'IA proporcionin informacio restringida a traves de consultes indirectes o tecniques de jailbreaking.
- **Models oberts.** Les restriccions en els serveis tancats d'API no s'apliquen als models de pesos oberts que es poden modificar.
- **Coneixement d'us dual.** La mateixa informacio necessaria per al desenvolupament de farmacs podria permetre el desenvolupament d'armes biologiques. Restringir tot el coneixement potencialment perillos paralitzaria les aplicacions beneficioses.

### Comunitats de bioseguretat

La comunitat de bioseguretat ha desenvolupat normes sobre recerca responsable:

- Els comites institucionals de bioseguretat revisen la recerca perillosa
- Les politiques de Recerca d'Us Dual Preocupant (DURC) requereixen revisio especial
- Algunes recerques es restringeixen de la publicacio per raons de seguretat

Aquestes normes podrien potencialment estendre's a la recerca biologica amb IA, pero els mecanismes d'aplicacio son febles i la cobertura es incompleta.

### Avaluacions de capacitats

Com vam discutir a [avaluacions de capacitats perilloses](/research/024-capability-evaluations/), els laboratoris d'IA estan comencant a provar els sistemes per detectar capacitats biologiques abans del desplegament. Aixo es valuos pero limitat: les avaluacions poden no detectar capacitats que existeixen pero no es proven.

## Propostes de governanca

Diverses propostes busquen enfortiir la governanca dels riscos d'us dual entre IA i biologia.

### Acces estructurat

En lloc d'alliberar sistemes d'IA potents de manera oberta, restringir l'acces a traves d'APIs que puguin monitoritzar l'us, implementar limits d'us i detectar consultes preocupants. Aixo permet la recerca beneficiosa mentre crea supervisio.

Limitacions: No aborda els models de pesos oberts. El monitoratge a escala es dificil. Els adversaris sofisticats poden evadir la deteccio.

### Requisits de coneixement del client

Requerir la verificacio de la identitat de l'usuari i del proposit legitim abans de proporcionar acces a eines d'IA potents per a aplicacions biologiques. Similar als controls sobre productes quimics perillosos o equips de laboratori.

Limitacions: Crea barreres a la recerca legitima. Pot concentrar les capacitats d'IA biologica en institucions amb molts recursos.

### Governanca del comput

Restringir l'acces als recursos computacionals necessaris per entrenar models d'IA perillosos. Com vam examinar a [la governanca del comput](/research/023-compute-governance/), el comput es un possible punt d'estrangulament per a la governanca.

Limitacions: S'aplica a l'entrenament, no a la inferencia. La governanca del comput es dificil d'implementar internacionalment. Pot tornar-se menys eficac a mesura que l'entrenament es fa mes eficient.

### Estandards d'equips vermells

Requerir una avaluacio rigorosa de bioseguretat abans de desplegar sistemes d'IA amb capacitats biologiques. Establir estandards sobre que han de cobrir les avaluacions i quins resultats justifiquen restriccions de desplegament.

Limitacions: Les avaluacions poden ser incompletes. Els estandards requereixen desenvolupament expert i actualitzacio continua. Els actors adversaris no s'autoavaluaran.

### Protocols de risc informacional

Desenvolupar marcs mes clars sobre quan la recerca sobre capacitats d'IA-biologia s'ha de restringir de la seva publicacio. Equilibrar l'obertura cientifica enfront dels riscos de seguretat.

Limitacions: La restriccio de la publicacio academica no impedeix el desenvolupament privat. Les decisions sobre que restringir son controvertides.

## Per que aixo es dificil

El cas de la IA-biologia illustra tensions fonamentals en la governanca d'us dual.

**Compromisos benefici-risc.** La IA podria accelerar massivament la recerca biologica beneficiosa, potencialment salvant milions de vides. Les restriccions que prevenen el desenvolupament d'armes biologiques tambe poden alentir la recerca que salva vides. Cap marc separa nettament el benefici del risc.

**Normes d'obertura.** La ciencia ha valorat tradicionalment l'obertura: la replicacio, la revisio per parells i la construccio sobre el treball d'altres. Les preocupacions de seguretat empenyen cap al tancament i la restriccio, creant tensio amb la cultura cientifica.

**Dificultat d'atribucio.** A diferencia de les armes nuclears, el desenvolupament d'armes biologiques pot ser dificil de detectar i atribuir. Aixo soscava la dissuasio i la rendicio de comptes.

**Desenvolupament privat.** Els governs i els organismes internacionals poden regular la recerca publica. El desenvolupament privat i clandesti es mes dificil de governar.

**Velocitat del canvi.** Tant la IA com la biologia avancen rapidament. Els marcs de governanca dissenyats avui poden quedar obsolets en anys.

## La dimensio reflexiva

El nostre treball sobre governanca reflexiva de la IA ofereix algunes perspectives rellevants.

Els sistemes d'IA podrien potencialment participar en la governanca de la bioseguretat:

- **Autolimitacio.** Els sistemes entrenats amb objectius de seguretat poden refusar sollicituds perilloses, una forma de [restriccio llegible per maquina](/research/003-machine-readable-constraint-schema/).
- **Monitoratge.** Els sistemes d'IA podrien monitoritzar patrons d'us preocupants, tot i que aixo planteja preocupacions de vigilancia.
- **Explicar els limits.** Els sistemes podrien [explicar les seves restriccions](/research/026-explaining-constraints/) als usuaris, creant comprensio en lloc de nomes restriccio.

No obstant aixo, [els limits de l'autolimitacio](/research/013-limits-of-self-constraint/) tambe s'apliquen aqui. Les restriccions tecniques poden ser eludides. Els mecanismes de governanca institucionals i socials segueixen sent essencials.

## El que podria funcionar

Donats aquests reptes, una governanca eficac probablement requereix:

**Defensa per capes.** Cap mesura unica es suficient. Combinar restriccions tecniques, controls d'acces, monitoratge d'us, desenvolupament de normes i responsabilitat legal.

**Inversio en recerca.** Les implicacions de bioseguretat de la IA necessiten mes recerca, tant estudi empiric dels riscos actuals com desenvolupament de millors eines de governanca.

**Participacio de les parts interessades.** Els desenvolupadors d'IA, els biologs, els experts en bioseguretat i els responsables politics han de collaborar. Cap comunitat per si sola te prou experiencia.

**Coordinacio internacional.** Donada la naturalesa global tant de la IA com de la biologia, la governanca purament nacional es insuficient. Pero la coordinacio internacional es dificil d'assolir.

**Mecanismes adaptatius.** Construir una governanca que pugui evolucionar a mesura que avanca la tecnologia. Les restriccions tecniques especifiques quedaran obsoletes rapidament; les institucions robustes poden adaptar-se.

El que esta en joc es molt. Fer be la governanca de la IA-biologia podria significar la diferencia entre una era d'abundancia biologica i una era de risc biologic.

## Lectures addicionals

- [El problema de l'excedent de capacitats](/research/009-capability-overhang/)
- [Linies vermelles: una taxonomia de limits no negociables de la IA](/research/004-red-lines-taxonomy/)
- [Quan la IA ha de refusar: un marc](/research/025-when-ai-should-refuse/)
- [Avaluacions de capacitats perilloses](/research/024-capability-evaluations/)
