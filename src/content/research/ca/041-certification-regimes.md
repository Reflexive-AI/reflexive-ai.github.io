---
title: "Regims de certificació per a sistemes d'IA"
excerpt: "Podrien els sistemes d'IA certificar-se en matèria de seguretat com les aeronaus o els dispositius mèdics? Una anàlisi de com podria ser la certificació d'IA, els seus beneficis i els seus reptes significatius."
date: 2026-01-23
categories:
  - Governance Analysis
tags:
  - regulation
  - standards
  - safety
  - deployment
---

## La idea de la certificació

Moltes tecnologies d'alt risc requereixen certificació abans del seu desplegament. Les aeronaus han de certificar-se com a aptes per al vol. Els dispositius mèdics han de rebre aprovació regulatòria. Els productes elèctrics han de complir normes de seguretat. Aquests regims de certificació garanteixen un nivell mínim de seguretat abans que els productes arribin als usuaris.

Podrien funcionar regims similars per a la IA? Els seus defensors argumenten que la certificació podria proporcionar garantia de qualitat, claredat en matèria de responsabilitat civil i confiança pública. Els escèptics sostenen que les característiques distintives de la IA fan impracticables els enfocaments tradicionals de certificació.

Aquesta anàlisi examina com podria ser la certificació d'IA, tot extraient lliçons dels regims existents i reconeixent alhora els reptes específics de la IA.

## Com funciona la certificació en altres àmbits

Comprendre els regims de certificació existents il·lumina el que podria requerir la certificació d'IA.

### Aviació

La certificació aeronàutica és de les més rigoroses:

- **Certificació de tipus:** Els nous dissenys d'aeronaus se sotmeten a una avaluació exhaustiva d'acord amb les normes d'aeronavegabilitat
- **Certificació de fabricació:** Les instal·lacions de producció han d'estar certificades en qualitat
- **Certificació individual:** Cada aeronau s'inspecciona abans de la seva operació
- **Compliment continu:** L'aeronavegabilitat continuada requereix inspecció i manteniment regulars

Aquest règim és costós i lent, però ha aconseguit registres de seguretat notables. Vam explorar les lliçons de l'aviació per a la IA a [sistemes de notificació d'incidents](/research/021-aviation-lessons/).

### Dispositius mèdics

La certificació de dispositius mèdics varia segons el nivell de risc:

- **Dispositius de baix risc:** Autocertificació amb registre
- **Dispositius de risc moderat:** Avaluació de conformitat per tercers
- **Dispositius d'alt risc:** Aprovació regulatòria amb dades clíniques

El procés dura de mesos a anys i requereix proves substancials de seguretat i eficàcia.

### Seguretat de productes

Els productes de consum normalment requereixen:

- Conformitat amb normes publicades
- Assajos per laboratoris acreditats
- Marcatge (CE, UL, etc.) que indica conformitat

Això és menys rigorós que l'aviació o els dispositius mèdics, però proporciona una garantia bàsica de seguretat.

### Característiques comunes

En tots els àmbits, la certificació sol incloure:

- **Normes clares:** Requisits definits que els productes han de complir
- **Assajos:** Evidència que es compleixen els requisits
- **Verificació per tercers:** Avaluació independent, no només autocertificació
- **Documentació:** Registres que permeten la traçabilitat
- **Compliment continu:** Els requisits no acaben amb la certificació inicial
- **Aplicació:** Conseqüències per incompliment o fallada

## Com podria ser la certificació d'IA

A partir d'aquests models, la certificació d'IA podria incloure diversos elements.

### Avaluació prèvia al desplegament

Abans del desplegament, els sistemes d'IA podrien sotmetre's a una avaluació que cobrís:

- **Avaluació de capacitats:** Què pot fer el sistema? (en connexió amb la nostra anàlisi de les [avaluacions de capacitats perilloses](/research/024-capability-evaluations/))
- **Avaluació de riscos:** Quins danys podrien produir-se?
- **Assajos:** Com es comporta el sistema en condicions controlades?
- **Documentació:** Hi ha documentació adequada sobre l'entrenament, l'arquitectura i les limitacions?

### Aprovació del desplegament

Sobre la base de l'avaluació, les autoritats de certificació podrien:

- **Aprovar:** El sistema pot desplegar-se segons el que s'ha proposat
- **Aprovar amb condicions:** Desplegament permès amb restriccions
- **Requerir modificacions:** Calen canvis abans del desplegament
- **Rebutjar:** No es permet el desplegament

### Supervisió contínua

La certificació no acabaria amb el desplegament. Els requisits podrien incloure:

- **Supervisió del rendiment:** Seguiment del comportament del sistema en operació real
- **Notificació d'incidents:** Divulgació dels problemes que sorgeixin (com vam examinar a [lliçons de l'aviació](/research/021-aviation-lessons/))
- **Recertificació:** Reavaluació periòdica, especialment després de canvis significatius
- **Aprovació d'actualitzacions:** Els canvis en els sistemes desplegats requereixen revisió

### Enfocaments escalonats

No totes les aplicacions d'IA justifiquen el mateix rigor de certificació. Els enfocaments escalonats podrien ajustar el nivell d'escrutini al risc:

- **Aplicacions de baix risc:** Autocertificació amb registre
- **Aplicacions de risc moderat:** Avaluació per tercers
- **Aplicacions d'alt risc:** Aprovació regulatòria amb evidència exhaustiva

La Llei d'IA de la UE adopta aquest enfocament, amb requisits diferents segons els distints nivells de risc.

## Beneficis potencials

La certificació d'IA podria aportar beneficis significatius.

### Garantia de qualitat

La certificació establiria estàndards mínims. Els sistemes que la superessin haurien demostrat certes capacitats i propietats de seguretat. Els usuaris tindrien certa confiança en els sistemes certificats.

### Claredat en la responsabilitat civil

La certificació podria clarificar la responsabilitat civil. Els sistemes que fallen malgrat una certificació adequada podrien atribuir la responsabilitat de manera diferent als sistemes que no van ser certificats o que es van desplegar malgrat fallades en la certificació.

### Confiança pública

Els marcatges de certificació visibles —com el marcatge CE o l'aprovació de la FDA— podrien generar confiança pública en els sistemes d'IA. Els usuaris sabrien que els sistemes certificats han superat una revisió independent.

### Igualtat de condicions

Els requisits de certificació s'aplicarien per igual a tots els sistemes coberts. Els desenvolupadors responsables no patirien un desavantatge competitiu per complir estàndards més alts.

### Desenvolupament del mercat

Uns requisits de certificació clars podrien de fet accelerar l'adopció de la IA en proporcionar la garantia de la qual manquen els usuaris actualment reticents. Els sistemes sanitaris que no adoptarien IA sense certificar podrien adoptar sistemes certificats.

## Reptes significatius

Malgrat els beneficis potencials, la certificació d'IA afronta reptes significatius.

### Què es certificaria?

Definir què es certifica és difícil. Un model fundacional? Una versió ajustada? Un desplegament específic? Els sistemes d'IA sovint són altament configurables: el mateix model base pot adaptar-se a innombrables aplicacions.

Això difereix fonamentalment dels productes físics, on la certificació s'aplica a béns definits i fabricats.

### Segons quines normes?

La certificació requereix normes clares. Per a la IA, quines normes s'aplicarien?

- Les normes de seguretat per a IA són incipients
- Els llindars de capacitat són difícils de definir
- El rendiment "prou bo" depèn del context
- Les compensacions entre diferents propietats (precisió enfront d'explicabilitat enfront de privacitat) requereixen judici

Vam examinar els reptes normatius a [el paper dels organismes de normalització](/research/039-standards-bodies/).

### Com funcionarien els assajos?

Els assajos de certificació tradicionals impliquen proves definides segons especificacions. Per a la IA:

- Els sistemes poden comportar-se de manera diferent en el desplegament que en els assajos
- Les entrades adversàries poden causar fallades que els assajos estàndard no detecten
- Les situacions rares però importants són difícils de sotmetre a assaig
- Els assajos poden no revelar les capacitats que vam identificar en l'[excedent de capacitat](/research/009-capability-overhang/)

### Deriva posterior al desplegament

Els productes certificats normalment no canvien. Els sistemes d'IA poden derivar amb el temps en actualitzar-se, ajustar-se o exposar-se a dades canviants. El que es va certificar en el moment del desplegament pot no coincidir amb el que opera després.

### Requisits de recursos

La certificació rigorosa és costosa. La certificació aeronàutica costa milions; l'aprovació de dispositius mèdics dura anys. Podria la certificació d'IA aconseguir el rigor necessari sense imposar costos prohibitius, especialment als desenvolupadors més petits?

### Capacitat regulatòria

La certificació requereix certificadors competents. Els reguladors necessitarien experiència tècnica en IA de la qual molts manquen actualment. Els certificadors externs necessitarien una capacitat similar. Vam explorar reptes relacionats a [per què la regulació és difícil](/research/018-regulation-is-hard/).

### Riscos d'elusió

La certificació podria eludir-se:

- Desplegant fora de les jurisdiccions certificades
- Evitant el llindar per als requisits de certificació
- Modificant els sistemes després de la certificació
- Declarant falsament les capacitats del sistema

L'aplicació afrontaria reptes significatius.

## Enfocaments híbrids

Atesos aquests reptes, la certificació pura pot ser impracticable. Els enfocaments híbrids podrien ser més viables.

### Certificació de processos

En lloc de certificar sistemes específics, certificar processos:

- Segueix el desenvolupador pràctiques adequades de gestió del risc?
- Hi ha procediments d'assaig apropiats?
- Hi ha supervisió contínua?

Això s'assembla més a la certificació de sistemes de gestió ISO que a la certificació de productes.

### Avaluació de conformitat

En lloc d'una aprovació binària, l'avaluació de conformitat podria proporcionar informació graduada:

- A quins assajos es va sotmetre el sistema?
- Quins resultats es van obtenir?
- Quines limitacions es van identificar?

Els usuaris podrien prendre decisions informades basant-se en l'avaluació en lloc de dependre d'una certificació binària.

### Certificació contínua

En lloc d'una certificació puntual, la supervisió contínua podria mantenir el compliment permanent:

- Verificació automatitzada dels sistemes desplegats
- Supervisió contínua del rendiment
- Reavaluació activada quan apareixen anomalies

Això aborda les preocupacions sobre la deriva posterior al desplegament.

### Autocertificació amb rendició de comptes

Per a les aplicacions de menor risc, exigir autocertificació amb:

- Documentació publicada
- Divulgació obligatòria de limitacions
- Responsabilitat estricta per declaracions falses

Això proporciona certa garantia sense una infraestructura regulatòria pesant.

## La dimensió reflexiva

El nostre treball sobre governança reflexiva suggereix possibilitats addicionals.

Els sistemes d'IA podrien participar en la seva pròpia certificació:

- **Autonotificació:** Els sistemes informen de les seves capacitats i limitacions (com vam explorar a la [comunicació d'IA a regulador](/research/014-ai-regulator-protocol/))
- **Explicació de restriccions:** Els sistemes expliquen el que estan dissenyats per rebutjar (vegeu [explicar les restriccions](/research/026-explaining-constraints/))
- **Assistència en la supervisió:** Els sistemes ajuden a detectar els seus propis problemes

Això no substituiria la certificació externa, però podria complementar-la. No obstant això, com vam examinar a [els límits de l'autocontenció](/research/013-limits-of-self-constraint/), l'autonotificació té limitacions inherents.

## Recomanacions

Sobre la base d'aquesta anàlisi, la certificació d'IA hauria de:

**Començar per les aplicacions d'alt risc.** Centrar els requisits inicials de certificació en les aplicacions on els danys són més greus i els beneficis de la certificació estan més justificats.

**Emfatitzar els processos per sobre dels productes.** Atesa l'adaptabilitat de la IA, certificar els processos de desenvolupament i desplegament responsable en lloc de versions específiques de sistemes.

**Desenvolupar-se de forma incremental.** Desenvolupar la capacitat de certificació al llarg del temps en lloc d'intentar regims integrals de seguida.

**Invertir en capacitat regulatòria.** La certificació és tan bona com els certificadors. Es requereix una inversió significativa en experiència regulatòria.

**Combinar mecanismes.** La certificació per si sola no resoldrà la governança de la IA. Integrar amb responsabilitat civil, supervisió i altres mecanismes de governança.

**Mantenir l'adaptabilitat.** Qualsevol enfocament de certificació que sorgeixi ha de poder evolucionar a mesura que canvien les capacitats i la comprensió de la IA.

## Conclusió

La certificació d'IA ofereix beneficis potencials, però afronta reptes significatius. Els models de certificació purs d'altres àmbits no es tradueixen directament. Els enfocaments híbrids —que emfatitzin els processos, la supervisió contínua i l'avaluació graduada— poden ser més pràctics.

La certificació hauria de ser part de la governança de la IA, però no pot ser la seva totalitat. Construir una certificació eficaç requerirà inversió sostinguda, experimentació i adaptació.

## Lectures complementàries

- [Avaluacions de capacitats perilloses](/research/024-capability-evaluations/)
- [Sistemes de notificació d'incidents: lliçons de l'aviació](/research/021-aviation-lessons/)
- [El paper dels organismes de normalització en la governança de la IA](/research/039-standards-bodies/)
- [Autonotificació enfront d'auditoria externa: compensacions](/research/010-self-reporting-vs-audit/)
