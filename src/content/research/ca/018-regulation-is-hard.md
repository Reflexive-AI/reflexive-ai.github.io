---
title: "Per què 'simplement regular la IA' és més difícil del que sembla"
excerpt: "La regulació sembla la resposta òbvia als riscos de la IA. Però el camí des de 'hauríem de regular la IA' fins a una governança eficaç està ple d'obstacles tècnics, polítics i conceptuals."
date: 2025-12-31
categories:
  - Public
  - Governance Analysis
tags:
  - regulation
  - policy
  - governance
  - enforcement
  - jurisdiction
---

## La solució òbvia

Quan les persones coneixen els riscos de la IA — des d'algorismes esbiaixats fins a un possible ús indegut catastròfic — una resposta natural és: "Per què no simplement la regulem?" Aquesta resposta és sensata. La regulació ha funcionat per a altres tecnologies perilloses. Regulem els productes farmacèutics, l'energia nuclear, l'aviació i els mercats financers. Per què no la IA?

La resposta no és que la regulació sigui impossible o indesitjable. És que la IA presenta una combinació única de reptes que fan difícil aplicar els enfocaments reguladors tradicionals. Comprendre aquests reptes és essencial per dissenyar una governança que realment funcioni.

## Repte 1: Definir l'objectiu

La regulació requereix definir què s'està regulant. Per a la IA, això és sorprenentment difícil.

Què és un sistema d'IA? Les definicions actuals van des de les estretes (models d'aprenentatge automàtic per sobre d'una certa mida) fins a les àmplies (qualsevol sistema de decisió automatitzat). Cada elecció té conseqüències.

Si es defineix la IA de manera massa estreta, es creen llacunes. Una empresa podria reestructurar el seu sistema per quedar tècnicament fora de la definició mentre aconsegueix els mateixos resultats. Si es defineix de manera massa àmplia, es captura tot, des de simples filtres de spam fins a fórmules de fulls de càlcul, desbordant la capacitat reguladora amb aplicacions de baix risc.

La Llei d'IA de la UE intenta un enfocament basat en el risc, categoritzant aplicacions en lloc de tecnologies. Però això crea els seus propis problemes: el mateix model subjacent podria ser d'"alt risc" quan s'usa per a decisions de contractació però de "risc mínim" quan s'usa per a atenció al client, tot i que les seves capacitats — i el seu potencial d'ús indegut — continuïn sent idèntiques.

Els enfocaments basats en capacitats, com vam explorar a [proporcionalitat en la divulgació de models](/research/001-proportionality-disclosure/), ofereixen una alternativa. En lloc de regular per aplicació, regular pel que un sistema pot fer. Però mesurar la capacitat és en si un repte tècnic, i les capacitats poden emergir inesperadament a mesura que els sistemes escalen.

## Repte 2: El problema del ritme

La regulació tradicional és lenta per disseny. La deliberació, consulta, redacció i implementació requereixen temps — típicament anys per a noves regles significatives. Aquest ritme tenia sentit quan les tecnologies regulades canviaven lentament.

La IA no canvia lentament. Capacitats que semblaven estar a anys de distància es tornen disponibles en mesos. Un marc regulador dissenyat per a GPT-3 pot quedar obsolet per quan es desplegui GPT-5. Legislar requisits tècnics específics corre el risc de consagrar els enfocaments d'ahir mentre no s'aborden els riscos de demà.

Algunes jurisdiccions estan experimentant amb enfocaments adaptatius: regulació basada en principis que estableix objectius en lloc de regles específiques, sandboxes reguladors que permeten l'experimentació sota supervisió, o empoderar les agències per actualitzar estàndards tècnics sense nova legislació. Cadascun té compromisos entre flexibilitat i previsibilitat.

El problema del ritme també afecta l'aplicació. Per quan es detecta una infracció, s'investiga i s'adjudica, el dany pot ja estar fet i la tecnologia pot haver avançat. Els reguladors sovint es troben lluitant la guerra anterior.

## Repte 3: La bretxa de coneixement

Una regulació eficaç requereix comprendre el que s'està regulant. Per a la IA, aquest coneixement es concentra en un petit nombre d'empreses i institucions de recerca.

Els reguladors sovint manquen de l'experiència tècnica per avaluar directament els sistemes d'IA. Poden tenir dificultats per avaluar si les afirmacions de seguretat d'una empresa són creïbles, si una mitigació proposada realment funciona o quines podrien ser les implicacions d'una nova arquitectura.

Això crea una asimetria d'informació. Les empreses saben més sobre els seus sistemes que els reguladors, cosa que complica l'aplicació. És difícil verificar el compliment de regles que un no comprèn completament.

Alguns enfocaments intenten abordar això: contractar personal tècnic a les agències reguladores, usar auditors externs com a intermediaris o exigir a les empreses que proporcionin documentació interpretable. Però cadascun introdueix nous problemes. Els auditors externs poden tenir conflictes d'interès, com vam discutir a [qui vigila els vigilants?](/research/006-meta-governance-auditors/). El personal tècnic pot marxar a feines més ben pagades a la indústria. La documentació pot ser enganyosa.

## Repte 4: Arbitratge jurisdiccional

El desenvolupament de la IA és global. La governança és nacional.

Una empresa que s'enfronta a regulacions restrictives en una jurisdicció pot reubicar el seu desenvolupament en una altra. Els usuaris en jurisdiccions regulades poden accedir a serveis de proveïdors en altres llocs. Els models entrenats en un país poden desplegar-se a tot el món.

Això crea un risc de cursa cap al fons: les jurisdiccions podrien competir pel desenvolupament d'IA oferint regulacions més laxes, minant l'eficàcia de regles més estrictes en altres llocs. Vam analitzar aquesta dinàmica a [arbitratge regulador en el desplegament d'IA](/research/008-regulatory-arbitrage/).

La coordinació internacional podria abordar això, però la governança de la IA manca de l'arquitectura institucional global que existeix per a alguns altres àmbits. No existeix un equivalent d'IA de l'Agència Internacional d'Energia Atòmica o de l'Organització d'Aviació Civil Internacional. Construir tals institucions requereix dècades.

Mentrestant, diferents jurisdiccions estan desenvolupant diferents enfocaments: la UE se centra en els drets fonamentals i la categorització de riscos, la Xina emfatitza el control de contingut i l'estabilitat social, els EUA depenen més de regles sectorials i l'autoregulació de la indústria. Aquests marcs entren en conflicte de maneres que generen incertesa i oportunitats d'evasió.

## Repte 5: El compromís amb la innovació

La regulació imposa costos. El compliment requereix recursos. La incertesa desincentiva la inversió. Les restriccions limiten el que es pot desenvolupar.

Aquests costos poden valer la pena si prevenen danys. Però també arrisquen frenar la innovació beneficiosa, i els beneficis de la IA són potencialment enormes: en atenció mèdica, descobriment científic, educació i productivitat.

El compromís amb la innovació és particularment agut perquè les capacitats de la IA es concentren en un petit nombre d'organitzacions líders. Una regulació pesada que freni aquests líders podria permetre que uns altres — potencialment en jurisdiccions amb menys salvaguardes — els atrapin o superin.

Els responsables polítics han de navegar aquest compromís sense estimacions fiables ni dels costos de la regulació ni de la magnitud dels beneficis i riscos del desenvolupament no regulat. Estem prenent decisions transcendentals sota una profunda incertesa.

Aquesta incertesa no és un argument contra la regulació. És un argument a favor de la humilitat sobre quant aconseguirà qualsevol enfocament particular, i a favor d'incorporar mecanismes per aprendre i adaptar-se.

## Repte 6: Captura i manipulació

Les regulacions poden ser capturades per les entitats que se suposa que han de governar. Les empreses amb recursos per participar en el procés regulador modelen les regles al seu favor. Els requisits de compliment que les grans empreses poden satisfer fàcilment es converteixen en barreres que exclouen competidors més petits.

La indústria de la IA està altament concentrada. Un petit nombre de grans empreses domina el desenvolupament de frontera i disposa de recursos significatius per invertir en participació reguladora. Hi ha un risc genuí que la governança de la IA es converteixi en una eina d'avantatge per als actors establerts en lloc de protecció pública.

La manipulació és una preocupació relacionada. Els actors sofisticats troben maneres de complir amb la lletra de les regulacions mentre en violen l'esperit. Un sistema d'IA podria aprovar les avaluacions de seguretat requerides mentre conserva capacitats perilloses que aquestes avaluacions no van provar. Vam explorar dinàmiques similars a [els límits de l'autorestricció](/research/013-limits-of-self-constraint/).

## Què podria funcionar millor

Res d'això no significa que la regulació sigui impossible o s'hagi d'abandonar. Significa que els enfocaments ingenus — "simplement prohibiu la IA perillosa" o "simplement exigiu a les empreses que siguin segures" — no aconseguiran els seus objectius.

Els enfocaments més prometedors comparteixen diverses característiques:

**Flexibilitat.** Regles que especifiquen objectius en lloc de mètodes, i que poden actualitzar-se a mesura que la tecnologia evoluciona, tenen més probabilitats de continuar sent rellevants.

**Governança per capes.** Combinar la regulació governamental amb estàndards de la indústria, monitoratge de la societat civil i mecanismes tècnics crea redundància. Si una capa falla, unes altres poden detectar el problema.

**Coordinació internacional.** Fins i tot una coordinació imperfecta és millor que la pura competència. Els acords de reconeixement mutu, els protocols d'avaluació compartits i l'intercanvi d'informació poden limitar l'arbitratge.

**Inversió en capacitat.** Una governança eficaç requereix recursos. Capacitar el personal tècnic, desenvolupar eines d'avaluació i construir capacitat d'aplicació és tan important com redactar regles.

**Mecanismes reflexius.** Els mateixos sistemes d'IA podrien contribuir a la governança mitjançant [esquemes de restricció llegibles per màquina](/research/003-machine-readable-constraint-schema/), [autodetecció d'ús indegut](/research/011-reflexive-misuse-detection/) i [protocols de comunicació amb reguladors](/research/014-ai-regulator-protocol/). Aquest és l'enfocament central de la Iniciativa Reflexive AI.

## Conclusió

La regulació és necessària però no suficient. L'instint de "simplement regular la IA" identifica correctament que la governança és necessària, però subestima com de difícil serà aconseguir una governança eficaç.

Els obstacles són reals però no insuperables. Abordar-los requereix anar més enllà dels eslògans per enfrontar els reptes tècnics, polítics i institucionals específics de governar una tecnologia d'evolució ràpida, distribució global i intensiva en coneixement expert.

Aquest no és un argument a favor de la inacció. Els riscos d'una governança inadequada són greus. És un argument a favor de la sofisticació: enfocaments que reconeguin la complexitat mentre continuen avançant cap a la seguretat i la rendició de comptes.

## Recerca relacionada

- [Proporcionalitat en la divulgació de models](/research/001-proportionality-disclosure/)
- [Arbitratge regulador en el desplegament d'IA](/research/008-regulatory-arbitrage/)
- [Qui vigila els vigilants? Auditar els auditors d'IA](/research/006-meta-governance-auditors/)
- [Un protocol de comunicació entre IA i reguladors](/research/014-ai-regulator-protocol/)
