---
title: "Construir institucions de governança de la IA"
excerpt: "Una governança efectiva de la IA requereix noves institucions amb la combinació adequada d'independència, expertesa i poder d'aplicació. Aquesta anàlisi examina models existents de la regulació nuclear, aeronàutica i financera per derivar principis de disseny per als organismes de governança de la IA."
date: 2026-02-07
toc: true
categories:
  - Governance Analysis
tags:
  - institutions
  - ai-governance
  - regulation
  - international-cooperation
  - policy-design
version: "1.0"
---

**Objecte de Recerca Reflexiva 096**
*Tipus: Recerca*

## Introducció

Les normes sense institucions són paraules sobre paper. La Llei d'IA de la UE, les ordres executives dels EUA, la Declaració de Bletchley: totes pressuposen que alguna organització les interpretarà, implementarà i farà complir. No obstant això, la infraestructura institucional per a la governança de la IA continua sent feble. La majoria dels països no tenen un regulador dedicat a la IA. Cap organisme internacional té autoritat vinculant sobre el desenvolupament de la IA. La bretxa entre l'ambició de governança i la capacitat institucional és àmplia i creixent.

Aquesta bretxa no és accidental. Construir institucions de governança efectives és difícil i lent. Requereix consens polític, expertesa tècnica, finançament i legitimitat. El desenvolupament de la IA no espera cap d'aquestes coses. El resultat és un patró familiar: la tecnologia supera la governança, i la governança s'afanya per posar-se al dia.

Aquesta anàlisi examina què fa que les institucions de governança siguin efectives, basant-se en models establerts de la seguretat nuclear, l'aviació i la regulació financera. Proposa principis de disseny per als organismes de governança de la IA i avalua diverses propostes concretes que estan actualment en discussió.

## Lliçons dels models institucionals existents

Tres dominis ofereixen precedents instructius: l'energia nuclear, l'aviació civil i la regulació financera. Cadascun va afrontar el repte de governar una tecnologia complexa, d'alt risc i amb dimensions globals. Cadascun va construir institucions que, malgrat limitacions reals, han tingut un èxit considerable.

### L'AIEA: inspeccions i no proliferació

L'Agència Internacional de l'Energia Atòmica, establerta el 1957, governa la tecnologia nuclear mitjançant una combinació d'acords de salvaguardes, inspeccions i assistència tècnica. El seu doble mandat: promoure l'energia nuclear pacífica alhora que prevenir la proliferació d'armes.

Diverses característiques fan que l'AIEA sigui rellevant per a la governança de la IA. Primera, opera un règim de verificació. Els inspectors visiten instal·lacions nuclears, monitoritzen materials i verifiquen el compliment dels acords de salvaguardes. Això no és autoinforme; és avaluació independent amb accés físic. Segona, l'AIEA té un camí clar d'escalada en l'aplicació. L'incompliment es remet al Consell de Seguretat de l'ONU, que pot imposar sancions o autoritzar accions. Tercera, l'AIEA manté una expertesa tècnica profunda. El seu personal inclou físics nuclears, enginyers i especialistes en salvaguardes que entenen la tecnologia que regulen.

L'AIEA també il·lustra limitacions. La seva autoritat depèn del consentiment estatal. Els països que refusen unir-se al Tractat de No Proliferació Nuclear (TNP) o se'n retiren queden fora del règim. La verificació és incompleta: els estats poden fer trampes i ho han fet. El doble mandat crea tensió entre la promoció i la regulació. Aquestes limitacions són instructives per a la IA: qualsevol institució internacional afrontarà restriccions de sobirania similars.

### L'OACI: estàndards per a una indústria global

L'Organització d'Aviació Civil Internacional estableix estàndards i pràctiques recomanades per a l'aviació civil a tot el món. Com vam discutir a la nostra anàlisi de [lliçons de la seguretat aeronàutica](/research/021-aviation-lessons/), el registre de seguretat de l'aviació és en part un producte de la seva arquitectura institucional.

L'OACI funciona perquè l'aviació és inherentment internacional. Un avió fabricat a França, operat per una aerolínia coreana, volant a través de l'espai aeri japonès i aterrant a Austràlia ha de complir estàndards de seguretat consistents. Cap país pot optar per sortir dels requisits d'interoperabilitat sense aïllar el seu sector d'aviació. Això crea incentius forts per al compliment.

El procés d'establiment d'estàndards de l'OACI involucra comitès tècnics, consulta pública i adopció pels estats membres. Els estàndards són detallats i prescriptius: especifiquen des de la disposició dels instruments de la cabina fins als requisits de formació dels pilots. Com vam assenyalar a la nostra [anàlisi d'organismes d'estandardització](/research/039-standards-bodies/), l'especificitat dels estàndards és enormement important per a la seva efectivitat.

Per a la governança de la IA, el model de l'OACI suggereix que les institucions funcionen millor quan la tecnologia mateixa crea interdependències que fan racional la cooperació. La IA té algunes d'aquestes característiques: els models entrenats en una jurisdicció es despleguen globalment, i els serveis impulsats per IA creuen fronteres constantment. Però la IA no té els requisits d'interoperabilitat física de l'aviació, cosa que debilita l'incentiu estructural per a la coordinació internacional.

### El Comitè de Basilea: regulació en xarxa

El Comitè de Supervisió Bancària de Basilea ofereix un model diferent. No és una organització basada en un tractat amb autoritat legal formal. És un comitè de governadors de bancs centrals i reguladors de les principals economies que desenvolupa estàndards voluntaris. No obstant això, els requisits de capital de Basilea governen efectivament la banca global.

El model de Basilea funciona mitjançant una combinació de pressió entre iguals, expectatives del mercat i implementació domèstica. Els bancs que operen internacionalment han de complir els estàndards de Basilea a la pràctica, perquè les contraparts i els mercats ho esperen. Els reguladors nacionals adopten els estàndards de Basilea en la legislació domèstica, donant-los força vinculant sense necessitat d'un tractat.

Això és rellevant per a la governança de la IA perquè demostra que el [dret tou pot endurir-se fins a convertir-se en governança efectiva](/research/040-soft-law-hard-law/) a través de les dinàmiques de mercat i l'adopció mútua. Un organisme de governança de la IA modelat segons Basilea no necessitaria autoritat de tractat. Necessitaria la participació dels països on es desenvolupa la IA de frontera i un procés d'establiment d'estàndards que produeixi normes tècnicament creïbles i àmpliament adoptades.

## Què fa efectives les institucions

A través d'aquests exemples, diverses característiques distingeixen les institucions de governança efectives de les inefectives.

### Independència

Una institució capturada per la indústria que regula és pitjor que cap institució en absolut, perquè crea una falsa sensació de supervisió. Aquesta és la preocupació central de la nostra [anàlisi de metagovernança](/research/006-meta-governance-auditors/): qui vigila els vigilants?

La independència requereix proteccions estructurals. Mandats fixos per a la direcció. Finançament que no depengui de les taxes de la indústria (o, si ho fa, taxes recollides sense discrecionalitat). Personal amb prohibició d'ocupar llocs en entitats regulades durant períodes de refredament significatius. Processos de presa de decisions transparents. Els governs i la indústria entenen bé aquestes proteccions però les comprometen freqüentment a la pràctica.

Per a la governança de la IA, la independència és particularment difícil perquè l'expertesa rellevant es concentra precisament en les empreses que necessiten regulació. Un regulador d'IA que no pot contractar persones que entenguin els models de frontera no pot regular-los. Però els reguladors que contracten de la indústria porten perspectives i relacions de la indústria. Gestionar aquesta tensió requereix un disseny institucional deliberat: compensació competitiva, beques acadèmiques, programes de cessió temporal amb salvaguardes de conflicte d'interessos.

### Expertesa tècnica

Les institucions de governança han d'entendre el que governen. L'AIEA empra científics nuclears. Els comitès de l'OACI inclouen enginyers aeronàutics. El Comitè de Basilea es nodreix d'economistes financers. Sense un coneixement tècnic profund, una institució no pot establir estàndards significatius, conduir avaluacions creïbles ni identificar riscos emergents.

La governança de la IA afronta un dèficit d'expertesa sever. El nombre de persones que genuïnament entenen els sistemes d'IA de frontera és reduït, i la majoria treballen per a les empreses que els construeixen. Les [avaluacions de capacitats](/research/024-capability-evaluations/) requereixen avaluadors que puguin sondejar el comportament del sistema de maneres sofisticades. Establir estàndards de seguretat requereix entendre tant el que els models poden fer com la manera com fallen.

Les solucions inclouen invertir en la capacitat de recerca governamental en IA, crear programes de beques que facin rotar investigadors entre laboratoris i reguladors, i construir infraestructura d'avaluació que redueixi l'expertesa requerida per a les avaluacions individuals. L'Institut de Seguretat de la IA del Regne Unit i el seu homòleg nord-americà representen els primers esforços en aquesta direcció.

### Poder d'aplicació

Una institució sense poder d'aplicació és un consell assessor. Els consells assessors tenen el seu lloc, però no governen. Les institucions efectives necessiten un espectre d'eines d'aplicació: orientació i advertiments en l'extrem suau, multes i restriccions operatives al mig, i derivacions penals i tancaments en l'extrem dur.

El poder d'aplicació ha de ser proporcionat i creïble. Les sancions desproporcionades mai no s'apliquen; funcionen com amenaces que tothom sap que són buides. L'aplicació creïble requereix un historial d'utilització efectiva de les eines disponibles quan es produeixen infraccions.

Per a la governança internacional de la IA, l'aplicació és el problema més difícil. Cap país no atorgarà a un organisme internacional el poder d'aturar els seus laboratoris d'IA. El camí més realista passa per l'aplicació domèstica d'estàndards acordats internacionalment, tal com demostra el model de Basilea.

### Legitimitat

Les institucions necessiten legitimitat per funcionar. La legitimitat prové de múltiples fonts: autorització democràtica, equitat procedimental, competència tècnica i resultats. Una institució que pren bones decisions, segueix processos transparents i té un mandat legal clar guanya compliment més enllà del que l'aplicació sola aconsegueix.

La legitimitat és especialment important per a la governança de la IA perquè la tecnologia afecta tothom però és entesa per pocs. Els organismes de governança que semblen servir interessos restringits, ja sigui de la indústria o d'una nació particular, afrontaran resistència. La participació multiactor en el disseny de la governança: governs, investigadors, societat civil i comunitats afectades, enforteix la legitimitat.

## El problema de la velocitat

La IA avança ràpid. Les institucions avancen lentament. Aquesta discrepància és el repte de disseny central.

La construcció institucional tradicional porta dècades. L'AIEA es va establir dotze anys després que es fessin servir les primeres armes nuclears i set anys després del primer reactor civil. L'OACI va trigar quatre anys des de la Convenció de Chicago fins a l'operació plena. Basilea I va requerir tretze anys de deliberació. La governança de la IA no disposa d'aquest tipus de temps.

Tres estratègies poden abordar la discrepància de velocitat:

**Construir sobre organismes existents.** En lloc de crear institucions completament noves, ampliar els mandats i les capacitats de les existents. Les autoritats nacionals de protecció de dades poden ampliar el seu abast. Organismes d'estandardització com l'ISO ja desenvolupen estàndards d'IA. Organismes comercials com l'OMC poden abordar qüestions comercials relacionades amb la IA. Aquesta aproximació és més ràpida però comporta el risc de fragmentació i llacunes de mandat.

**Començar amb dret tou, endurir-lo després.** Començar amb compromisos voluntaris i estàndards no vinculants. Utilitzar l'experiència inicial per informar normes vinculants. Aquesta és essencialment l'aproximació actual, i té l'avantatge de la velocitat. El risc, com vam analitzar a [dret tou versus dret dur](/research/040-soft-law-hard-law/), és que els compromisos voluntaris continuen sent voluntaris: les empreses compleixen quan els convé i es desvien quan el compliment és costós.

**Dissenyar per a l'adaptació.** Construir institucions amb mecanismes explícits per actualitzar les seves pròpies normes. L'autoritat normativa delegada, on una institució pot emetre estàndards tècnics vinculants sense processos legislatius complets, permet una resposta més ràpida al canvi tecnològic. La legislació fundacional de la institució estableix principis i límits; la institució omple els detalls i els actualitza segons calgui.

## Propostes actuals i les seves perspectives

Diverses propostes específiques per a institucions de governança de la IA estan en discussió. Cadascuna té punts forts i febles.

### Consell de seguretat de la IA de frontera

Múltiples propostes contemplen un organisme centrat específicament en els sistemes d'IA de frontera: els models més capaços d'un petit nombre de laboratoris. Aquest consell establiria requisits de seguretat, conduiria o encarregaria avaluacions i atorgaria aprovacions de desplegament.

**Punts forts:** L'àmbit reduït fa que la institució sigui tractable. Els models de frontera són desenvolupats per aproximadament una dotzena d'organitzacions a nivell global; regular dotze entitats és factible. Els riscos dels sistemes de frontera són els més severs i la justificació més plausible per a nova maquinària institucional.

**Punts febles:** Definir "frontera" és difícil i canvia amb el temps. Una definició basada en llindars corre el risc de quedar obsoleta. Centrar-se només en sistemes de frontera ignora els danys de models àmpliament desplegats però menys capaços. I el petit nombre d'entitats regulades crea una pressió intensa de lobbisme i risc de captura.

### CERN per a la IA (institució de recerca internacional en IA)

Aquesta proposta, defensada en diverses formes per investigadors i alguns governs, contempla una institució de recerca internacional a gran escala per a la seguretat de la IA. Com el CERN en física de partícules, agruparia recursos, atrauria investigadors de primer nivell i conduiria recerca en seguretat que cap país ni empresa faria per si sol.

**Punts forts:** Aborda directament el problema de l'expertesa. Crea una base de recerca neutral de la qual els reguladors poden nodrir-se. Proporciona trajectòries professionals per als investigadors en seguretat fora de la indústria. Genera coneixement públic sobre seguretat de la IA que no són secrets comercials.

**Punts febles:** Les institucions de recerca no són reguladors. El CERN no regula la física de partícules; fa recerca. Un CERN per a la IA informaria la governança però no constituiria governança en si mateixa. La institució també afrontaria costos enormes, temps de posada en marxa llargs i negociació política sobre ubicació, dotació de personal i prioritats de recerca.

### Instituts nacionals de seguretat de la IA

El Regne Unit i els EUA han establert instituts de seguretat de la IA, i altres països els segueixen. Aquests organismes nacionals proven models de frontera, desenvolupen mètodes d'avaluació i construeixen capacitat tècnica governamental.

**Punts forts:** Es poden establir ràpidament sota autoritat executiva. Construeixen expertesa domèstica. Proporcionen capacitats concretes d'avaluació. Creen fonaments institucionals que poden expandir-se amb el temps.

**Punts febles:** Els organismes nacionals no poden abordar qüestions transfrontereres. La seva autoritat depèn de prioritats governamentals que canvien amb les eleccions. La fragmentació entre països comporta el risc d'estàndards inconsistents i arbitratge regulador, un problema que vam analitzar a [arbitratge regulador](/research/008-regulatory-arbitrage/).

### Ampliació del paper de l'OCDE

L'OCDE ja té programes de governança de la IA, principis i monitoratge. Ampliar el seu paper construiria sobre la infraestructura existent.

**Punts forts:** L'OCDE té credibilitat institucional, una membresía existent i processos establerts. Ja fa un treball significatiu en polítiques d'IA. L'ampliació és més ràpida que la creació.

**Punts febles:** L'OCDE representa democràcies riques. La Xina, l'Índia i la major part del Sud Global no en són membres. Una governança de la IA que exclou nacions importants en el desenvolupament i l'impacte de la IA manca de legitimitat i efectivitat. L'OCDE tampoc no té poder d'aplicació i és poc probable que l'adquireixi.

## Arquitectura de governança multinivell

Cap institució sola governarà la IA. Una governança efectiva requereix coordinació entre nivells.

**Reguladors nacionals** estableixen i fan complir les normes domèstiques, adaptades a les tradicions legals locals i les toleràncies al risc. Tenen poder d'aplicació i legitimitat democràtica.

**Organismes regionals**, com l'Oficina d'IA de la UE, coordinen normes entre països i creen mercats reguladors més grans. Redueixen la fragmentació alhora que preserven certa flexibilitat local.

**Organismes internacionals** estableixen estàndards mínims, coordinen qüestions transfrontereres, comparteixen informació i gestionen riscos compartits. No tenen aplicació directa però influeixen en la regulació nacional a través de l'establiment d'estàndards i la revisió entre iguals.

**Organismes tècnics** desenvolupen estàndards detallats, mètodes d'avaluació i punts de referència. Operen per sota del nivell polític però configuren el que la governança significa a la pràctica.

Aquesta arquitectura multinivell s'assembla a la regulació financera: Basilea estableix estàndards internacionals, la UE els implementa a través de directives, i els reguladors nacionals els fan complir domèsticament. Una arquitectura similar per a la IA implicaria l'establiment d'estàndards internacionals, la coordinació regional i l'aplicació nacional, tal com es discuteix a la nostra anàlisi de [propostes de tractats internacionals](/research/038-international-treaties/).

El repte clau de disseny és la coordinació. Múltiples institucions que operen a diferents nivells han de compartir informació, evitar requisits contradictoris i omplir les llacunes sense crear redundància. Això és un problema de disseny institucional, no un problema de polítiques, i rep massa poca atenció.

## Dimensió reflexiva

La Iniciativa Reflexive AI té un interès particular en el disseny institucional perquè la nostra tesi central en depèn. Argumentem que els sistemes d'IA haurien d'internalitzar les restriccions de governança: que la seguretat i el compliment haurien d'estar integrats en els models, no només imposats des de fora (vegeu [governança corporativa per a la seguretat de la IA](/research/042-corporate-governance/)). Però aquesta internalització només és significativa si hi ha institucions externes capaces de definir quines restriccions importen, verificar el compliment i actualitzar els requisits a mesura que la tecnologia evoluciona.

Sense institucions efectives, l'"autogovernança" es converteix en autoregulació, i l'autoregulació serveix al regulat. L'existència d'una governança externa creïble és el que dona a la governança interna el seu significat i la seva disciplina.

També assenyalem un repte recursiu: els sistemes d'IA s'utilitzen cada vegada més en la governança mateixa: per al monitoratge, l'avaluació, l'avaluació de riscos i el suport a la presa de decisions. Les institucions de governança han de governar la IA alhora que utilitzen la IA. Això crea la possibilitat que la tecnologia configuri les institucions que se suposa que han de configurar-la. El disseny institucional ha de tenir en compte aquest bucle de retroalimentació, garantint que les eines d'IA utilitzades en la governança estiguin elles mateixes subjectes a supervisió.

## Conclusió

Construir institucions de governança de la IA és el repte pràctic central de la política d'IA. Les normes, els principis i els compromisos són necessaris però insuficients. Necessiten seus institucionals: organitzacions amb la independència per resistir la captura, l'expertesa per entendre el que governen, l'autoritat per fer complir les seves decisions i la legitimitat per obtenir compliment.

No existeix cap model perfecte. L'AIEA, l'OACI i el Comitè de Basilea tenen tots limitacions significatives. Però demostren que es poden construir institucions de governança efectives per a tecnologies complexes i globals. Els principis de disseny són coneguts: independència, expertesa, aplicació, legitimitat i adaptabilitat. El repte és polític, no intel·lectual.

El camí a curt termini més productiu és una arquitectura multinivell: instituts nacionals de seguretat construint capacitat domèstica, fòrums internacionals desenvolupant estàndards compartits i organismes tècnics creant especificacions detallades. Amb el temps, aquests components poden formalitzar-se en acords vinculants a mesura que l'experiència s'acumula i la voluntat política es consolida. L'imperativa crítica és començar a construir ara, acceptant la imperfecció, en lloc d'esperar el disseny ideal mentre la bretxa de governança s'amplia.

## Referències

1. International Atomic Energy Agency. "IAEA Safeguards: Staying Ahead of the Game." IAEA, 2023.
2. International Civil Aviation Organization. "Convention on International Civil Aviation (Chicago Convention)." ICAO Doc 7300, 1944.
3. Basel Committee on Banking Supervision. "History of the Basel Committee." Bank for International Settlements, 2024.
4. UK Department for Science, Innovation and Technology. "AI Safety Institute: Approach to Evaluations." UK Government, 2024.
5. OECD. "OECD AI Principles." OECD, 2019. Updated 2024.
6. Anderljung, M. et al. "Frontier AI Regulation: Managing Emerging Risks to Public Safety." arXiv:2307.03718, 2023.
7. Ho, L. et al. "International Institutions for Advanced AI." arXiv:2307.04699, 2023.
8. Trager, R. et al. "International Governance of Civilian AI: A Jurisdictional Certification Approach." arXiv:2308.15514, 2023.
9. European Commission. "EU AI Act." Regulation (EU) 2024/1689, 2024.
10. Tallinn, J. and Shulman, C. "Governance of Superintelligence." Future of Humanity Institute, 2024.
