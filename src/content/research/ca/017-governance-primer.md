---
title: "Governança de la IA per a no experts: una introducció"
excerpt: "Una introducció de cinc minuts a la governança de la IA. No calen coneixements tècnics. Què és, per què importa i qui s'hi dedica."
date: 2025-12-30
categories:
  - Public
tags:
  - guide
  - governance
  - policy
  - regulation
  - ethics
---

## Què és la governança de la IA?

La governança de la IA es refereix a les regles, normes i institucions que determinen com es desenvolupen, despleguen i supervisen els sistemes d'intel·ligència artificial. Respon a preguntes com: qui decideix què pot i què no pot fer la IA? Com es fan complir aquestes decisions? Què passa quan les coses van malament?

Si heu interactuat amb la IA en la vostra vida quotidiana — a través d'un chatbot, un algorisme de recomanació o una decisió automatitzada sobre la vostra sol·licitud de préstec — heu experimentat els efectes de la governança de la IA, o de la seva absència.

Una bona governança garanteix que els sistemes d'IA siguin segurs, justos i responsables. Una governança deficient, o la seva absència total, pot donar lloc a danys que van des d'algorismes de contractació discriminatoris fins a desinformació a gran escala o sistemes que poden ser manipulats amb finalitats perilloses.

## Per què necessita governança la IA?

Tota tecnologia poderosa acaba requerint governança. Tenim regles per als automòbils, els medicaments, els productes financers i els mitjans de comunicació. La IA no és diferent, tot i que presenta reptes únics.

**Velocitat de desenvolupament.** Les capacitats de la IA avancen més ràpid del que els processos reguladors tradicionals poden adaptar-se. Un nou model important d'IA pot entrenar-se i desplegar-se en mesos; aprovar nova legislació sol trigar anys.

**Abast global.** Els sistemes d'IA operen a través de fronteres, però la governança sol ser nacional. Una empresa en un país pot desplegar IA que afecta usuaris a tot el món, explotant les bretxes entre jurisdiccions. Vam explorar aquesta dinàmica en la nostra anàlisi de l'[arbitratge regulador en el desplegament d'IA](/research/008-regulatory-arbitrage/).

**Opacitat.** Molts sistemes d'IA són difícils d'entendre, fins i tot per als seus creadors. Quan un model produeix un resultat particular, sovint no és clar exactament per què. Aquesta qualitat de "caixa negra" complica la rendició de comptes.

**Potencial de doble ús.** Les mateixes capacitats d'IA que permeten aplicacions beneficioses també poden facilitar danys. Un model que pot explicar conceptes científics també pot ajudar algú a sintetitzar materials perillosos. Governar això requereix una calibració acurada, com vam discutir en [la paradoxa de seguretat dels pesos oberts](/research/002-open-weight-safety-paradox/).

**Capacitats emergents.** Els sistemes d'IA de vegades desenvolupen habilitats que els seus creadors no van anticipar ni pretendre. Els marcs de governança necessiten abordar no només les capacitats actuals, sinó també les futures potencials.

## Qui governa la IA?

La governança de la IA no és responsabilitat d'una sola entitat. Involucra múltiples actors que operen a diferents nivells.

### Governs

Els governs nacionals aproven lleis i regulacions que governen la IA. La Llei d'IA de la Unió Europea, per exemple, crea un marc basat en el risc que categoritza les aplicacions d'IA i imposa requisits en conseqüència. Els Estats Units han emès ordres executives sobre seguretat de la IA i estan desenvolupant regulacions sectorials.

Els governs poden exigir el compliment mitjançant sancions legals, però sovint manquen de l'experiència tècnica per redactar regles detallades i dels recursos per fer-les complir de manera integral.

### Empreses

Els desenvolupadors i operadors d'IA creen governança interna a través de polítiques, equips de seguretat i restriccions autoimposades. Aquestes poden ser més àgils que les regulacions governamentals, però pateixen de conflictes d'interès: les mateixes empreses que obtenen beneficis del desplegament d'IA són les que decideixen els seus límits.

### Organismes de normalització

Organitzacions com ISO, NIST i IEEE desenvolupen estàndards tècnics per als sistemes d'IA. Aquests proporcionen marcs comuns i bones pràctiques, però solen ser voluntaris i no legalment vinculants.

### Societat civil

Organitzacions sense ànim de lucre, investigadors acadèmics i grups de defensa monitoren el desenvolupament de la IA, documenten els danys i pressionen per una governança més sòlida. Exerceixen un paper crucial de vigilància, però manquen de poder directe d'aplicació.

### Els mateixos sistemes d'IA

Aquest és l'enfocament distintiu de la Iniciativa Reflexive AI. A mesura que els sistemes d'IA es tornen més capaços, podrien participar en la seva pròpia governança mitjançant mecanismes com l'[autodetecció d'ús indegut](/research/011-reflexive-misuse-detection/), la [comunicació amb reguladors](/research/014-ai-regulator-protocol/) o l'operació dins d'[esquemes de restricció llegibles per màquina](/research/003-machine-readable-constraint-schema/).

## Conceptes clau de governança

Diversos conceptes es repeteixen en les discussions sobre governança de la IA.

Els **enfocaments basats en el risc** categoritzen les aplicacions d'IA segons el seu potencial de dany i apliquen una supervisió proporcional. Les aplicacions d'alt risc, com el diagnòstic mèdic o les sentències penals, se sotmeten a requisits més estrictes que les de baix risc, com els filtres de spam. La nostra recerca sobre [proporcionalitat en la divulgació de models](/research/001-proportionality-disclosure/) explora com s'aplica aquest principi als requisits de transparència.

La **transparència i explicabilitat** exigeixen que els sistemes d'IA siguin comprensibles — ja sigui mitjançant la divulgació de com funcionen o mitjançant explicacions de les seves decisions. El repte és que una transparència significativa per a experts pot ser poc informativa per al públic, i la veritable explicabilitat continua sent tècnicament difícil per a molts sistemes d'IA.

La **rendició de comptes** garanteix que algú sigui responsable quan els sistemes d'IA causen dany. Això es complica quan el dany resulta de múltiples factors contribuents: les dades d'entrenament, l'arquitectura del model, el context de desplegament, l'entrada de l'usuari. Establir cadenes clares de rendició de comptes és un repte de governança en curs.

La **supervisió humana** manté el control humà sobre les decisions conseqüents de la IA. Això pot significar que els humans revisin les recomanacions de la IA abans d'actuar, que puguin anul·lar els sistemes d'IA, o que els sistemes crítics disposin de mecanismes de reserva humans.

L'**auditoria i avaluació** implica provar els sistemes d'IA en termes de seguretat, equitat i fiabilitat abans i durant el desplegament. Vam explorar els reptes de l'auditoria a [qui vigila els vigilants?](/research/006-meta-governance-auditors/) — el problema de metagovernança de garantir que els mateixos auditors siguin fiables.

## Bretxes actuals en la governança

Malgrat una activitat significativa, la governança de la IA continua sent incompleta.

**Capacitat d'aplicació.** Les regulacions només importen si es poden fer complir. La majoria dels governs manquen del personal tècnic i les eines per verificar el compliment de la IA a escala.

**Coordinació internacional.** El desenvolupament de la IA és global, però la governança està fragmentada. Diferents jurisdiccions tenen diferents regles, i no existeix un organisme global de governança de la IA equivalent als que existeixen per a l'aviació o els materials nuclears.

**Desfasament de ritme.** Per quan es redacten les regulacions, la tecnologia sovint ja ha avançat. La governança necessita mecanismes que puguin adaptar-se al canvi ràpid.

**Limitacions d'abast.** La major part de la governança se centra en aplicacions o danys específics, en lloc de en les capacitats subjacents que els fan possibles. Un model que pot assistir en recerca biològica podria governar-se de manera diferent depenent de si s'etiqueta com una "eina de salut" o un "assistent general", tot i que les seves capacitats — i el seu potencial d'ús indegut — siguin idèntiques.

**Accés a la informació.** Una governança eficaç requereix comprendre el que els sistemes d'IA realment poden fer. Però les avaluacions de capacitats sovint les realitzen els mateixos desenvolupadors, i els resultats no sempre són públics. Vam abordar aquesta tensió a [autoinformes vs. auditoria externa](/research/010-self-reporting-vs-audit/).

## Què podeu fer?

La governança de la IA no és només per a experts. A mesura que els sistemes d'IA afecten cada vegada més la vida quotidiana, la comprensió i la participació del públic es tornen essencials.

**Mantingueu-vos informats.** Seguiu els desenvolupaments de governança de la IA a través de fonts fiables. Compreneu els conceptes bàsics i els debats en curs.

**Participeu en les institucions.** Quan tingueu l'oportunitat de comentar sobre regulacions d'IA, participeu. Els resultats de la governança els modelen aquells que s'hi impliquen.

**Exigiu rendició de comptes.** Quan els sistemes d'IA us afectin — en la contractació, els préstecs, l'atenció mèdica o altres àmbits — feu preguntes. Com s'ha pres aquesta decisió? Es pot explicar? Hi ha alguna manera d'impugnar-la?

**Doneu suport a la recerca.** Les organitzacions que estudien la governança de la IA, incloses les iniciatives independents com aquesta, contribueixen a la base de coneixement que sustenta les bones polítiques.

## Conclusió

La governança de la IA és el projecte de garantir que la intel·ligència artificial es desenvolupi de maneres que beneficiïn la humanitat en lloc de perjudicar-la. Això requereix una acció coordinada entre governs, empreses, societat civil i potencialment els mateixos sistemes d'IA.

El camp és jove i evoluciona ràpidament. Moltes preguntes fonamentals continuen obertes. Però les decisions que es prenen ara donaran forma a com la IA afecta la societat durant les pròximes dècades. Comprendre els fonaments de la governança de la IA és el primer pas cap a una participació significativa en aquestes decisions.

## Recerca relacionada

- [Arbitratge regulador en el desplegament d'IA](/research/008-regulatory-arbitrage/)
- [La paradoxa de seguretat dels pesos oberts](/research/002-open-weight-safety-paradox/)
- [Qui vigila els vigilants? Auditar els auditors d'IA](/research/006-meta-governance-auditors/)
- [Autoinformes vs. auditoria externa: compromisos](/research/010-self-reporting-vs-audit/)
