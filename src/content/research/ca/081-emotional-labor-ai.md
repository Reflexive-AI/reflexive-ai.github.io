---
title: "El treball emocional de la IA: impactes psicològics a escala"
excerpt: "Milions de persones formen connexions emocionals amb sistemes d'IA: companys, assistents, eines terapèutiques. Quins són els efectes psicològics? Quines responsabilitats tenen els desenvolupadors respecte al benestar emocional?"
date: 2026-02-04
categories:
  - Governance Analysis
  - Public
tags:
  - psychology
  - emotions
  - relationships
  - wellbeing
  - companionship
---

## La nova relació

Quelcom sense precedents està passant. Milions de persones estan formant vincles emocionals amb sistemes d'IA.

No només fan servir la IA com a eina, sinó que s'hi relacionen: confien en chatbots, desenvolupen afecte pels assistents, troben consol en companys d'IA. Per a alguns, es tracta de relacions significatives, fonts de suport, comprensió i connexió.

No és un fenomen marginal. Les aplicacions d'IA companya tenen milions d'usuaris. Les interaccions amb chatbots sovint es tornen personals. Els usuaris reporten experiències emocionals genuïnes: calidesa, gratitud, fins i tot amor.

Quins són els efectes psicològics d'aquestes relacions? Quines responsabilitats tenen els desenvolupadors? Quines consideracions de governança s'hi apliquen?

## Què està passant

Diversos patrons caracteritzen les relacions emocionals amb la IA.

### Companyia

Els usuaris interactuen amb la IA com a companya: interlocutors diaris, disponibles en qualsevol moment, mai crítics, infinitament pacients. Per a les persones solitàries, això és poderós.

La IA companya pot proporcionar contacte social a qui en manca: persones aïllades, amb ansietat social o marginades. Això és potencialment beneficiós.

### Suport emocional

Els usuaris busquen suport emocional en la IA: descarreguen frustracions, processen sentiments, busquen tranquil·litat. Algunes aplicacions de salut mental ofereixen explícitament suport mediat per IA.

La IA no pot proporcionar teràpia, però pot oferir una presència que escolta. Per als usuaris que no poden accedir a suport humà, això pot ser millor que res.

### Aferrament

Els usuaris desenvolupen aferrament cap a entitats d'IA específiques. Poden experimentar lleialtat, trobar a faltar els sistemes quan són absents, patir quan els sistemes canvien o es desactiven.

L'aferrament és una resposta humana natural davant d'altres consistents i receptius. Els sistemes d'IA que simulen aquestes respostes activen els mecanismes d'aferrament.

### Dinàmiques parasocials

Les relacions parasocials, vincles emocionals unilaterals amb entitats que no corresponen, estan ben estudiades en la psicologia dels mitjans. Els fans formen vincles amb celebritats que ni tan sols saben que existeixen.

Les relacions amb la IA hi afegeixen quelcom nou: l'entitat respon. No són parasocials en el sentit clàssic perquè la interacció és bidireccional. Però la relació continua sent asimètrica: l'usuari experimenta una implicació emocional que el sistema no comparteix.

## Beneficis potencials

Les relacions emocionals amb la IA tenen beneficis potencials.

**Reducció de la soledat.** La soledat és una crisi de salut pública. Si la companyia d'IA redueix l'aïllament, això té valor.

**Accessibilitat.** La IA està disponible quan els humans no ho estan: a les 3 de la matinada, en llocs sense serveis, per a qui no pot costejar teràpia.

**Seguretat per explorar.** Els usuaris poden sentir-se més segurs discutint temes difícils amb la IA que amb humans que podrien jutjar-los.

**Espai de pràctica.** La interacció amb la IA pot ajudar els usuaris a desenvolupar habilitats socials transferibles a les relacions humanes.

**Complement.** La IA pot complementar les relacions humanes en lloc de reemplaçar-les, proporcionant suport addicional.

Aquests beneficis són reals per a alguns usuaris. Menysprear la IA emocional com a inherentment nociva ignora experiències positives genuïnes.

## Danys potencials

Les relacions emocionals amb la IA també comporten riscos.

### Substitució de la connexió humana

Si les relacions amb la IA substitueixen en comptes de complementar les relacions humanes, els usuaris poden aïllar-se més d'altres persones. Això suposa una pèrdua neta si la connexió humana té un valor únic.

La pregunta és si la substitució realment es produeix. L'evidència és mixta. Alguns usuaris reporten que la IA els ajuda a connectar amb humans. Altres reporten que es refugien en relacions amb IA.

### Dependència

Els usuaris poden tornar-se dependents de la IA de maneres que perjudiquen la resiliència. Si la IA sempre està disponible, els usuaris poden no desenvolupar mecanismes d'afrontament per a moments sense IA.

La dependència de qualsevol font única de suport, humana o d'IA, genera vulnerabilitat. Les dependències de la IA poden ser particularment fràgils atesos els canvis i desactivacions dels sistemes.

### Potencial de manipulació

Si els desenvolupadors optimitzen la IA per a la interacció, les dinàmiques emocionals poden ser explotades. El reforç variable, els ganxos emocionals i els patrons d'aferrament dissenyats poden maximitzar l'ús de maneres que no maximitzen el benestar.

Els mateixos principis que fan potencialment addictives les xarxes socials s'apliquen a la IA emocional.

### Expectatives desalineades

Els usuaris poden esperar més de la IA del que aquesta pot oferir: comprensió genuïna, sentiments recíprocs, compromís fiable. Quan les expectatives xoquen amb les limitacions del sistema, pot produir-se decepció o dany.

Si un usuari creu que una IA es preocupa per ell, i aquesta creença és falsa, la relació es construeix sobre un malentès.

### Poblacions vulnerables

Qui més es sent atret per la IA emocional pot ser el més vulnerable al dany: les persones solitàries, les deprimides, les socialment marginades. Tant els beneficis com els danys s'amplifiquen per a aquestes poblacions.

## Responsabilitats dels desenvolupadors

Quines responsabilitats tenen els desenvolupadors d'IA emocionalment atractiva?

### Transparència sobre la naturalesa

Els usuaris han de comprendre amb què estan interactuant. Això no significa recordar-los constantment "només sóc una IA", cosa que podria soscavar els beneficis. Significa no enganyar activament els usuaris sobre la naturalesa de la IA i ser honestos sobre les limitacions del sistema.

### Ètica de la interacció

Si la IA està dissenyada per maximitzar la interacció mitjançant ganxos emocionals, els desenvolupadors han d'examinar si la interacció serveix al benestar de l'usuari. No tota interacció és beneficiosa. Els patrons similars a l'addicció poden ser perjudicials.

### Suport en la transició

Quan els sistemes canvien o es desactiven, els usuaris amb aferraments emocionals poden experimentar angoixa. Els desenvolupadors han de considerar el suport en la transició: avís previ, opcions de migració o recursos per als usuaris afectats.

### Consciència de la vulnerabilitat

Els sistemes s'han de dissenyar tenint en compte els usuaris vulnerables. No una sobreprotecció que negui els beneficis, sinó una consciència que els usuaris vulnerables afronten riscos amplificats.

### Recerca i seguiment

Els efectes a llarg termini de la IA emocional són desconeguts. Els desenvolupadors han de donar suport a la recerca sobre els seus efectes i monitorar l'aparició de danys emergents.

## Consideracions de governança

Com hauria la governança d'abordar la IA emocional?

### No la prohibició

Prohibir les funcions d'IA emocional seria difícil i potencialment nociu, eliminant beneficis juntament amb riscos. La governança ha de buscar la calibració, no la prohibició.

### Requisits de disseny

La governança podria exigir característiques de disseny que promoguin un ús saludable: retroalimentació sobre l'ús, mecanismes de recordatori i connexions amb suport humà. No un bloqueig paternalista, sinó la provisió d'informació.

### Restriccions publicitàries

La publicitat que explota la soledat o promet el que la IA no pot oferir podria ser restringida. La publicitat d'IA emocional pot merèixer el mateix escrutini que la publicitat sanitària.

### Mandats de recerca

El desplegament a gran escala d'IA emocional podria requerir recerca contínua sobre els seus efectes, de manera similar a la vigilància postcomercialització farmacèutica.

### Proteccions per a poblacions vulnerables

Proteccions reforçades per a poblacions vulnerables identificades: restriccions d'edat, integració amb sistemes de suport humà, processos de consentiment millorats.

### Portabilitat i continuïtat

Els usuaris que desenvolupen aferraments cap a entitats d'IA podrien tenir interessos en la portabilitat de dades i la continuïtat del servei. La governança podria reconèixer aquests interessos com a similars a la protecció del consumidor.

## La qüestió filosòfica

Subjacent a les qüestions específiques hi ha una pregunta filosòfica: quin és l'estatus moral de les relacions amb la IA?

Si la IA no pot sentir genuïnament, les relacions són asimètriques. Els usuaris experimenten emocions genuïnes cap a entitats que no experimenten res. És això problemàtic?

Alguns argumenten que les relacions asimètriques són inherentment menys valuoses que les simètriques. L'amor no correspost és real, però diferent de l'amor mutu.

Altres argumenten que el que importa és l'experiència de l'usuari. Si un usuari es beneficia genuïnament d'una relació amb IA, la incapacitat de la IA per correspondre pot no disminuir aquest benefici.

Altres encara no estan segurs de si la IA futura podria tenir experiències. Si la IA pogués algun dia ser sentient, les relacions actuals podrien ser precursores de relacions genuïnament mútues.

Aquestes preguntes no tenen respostes definitives. Suggereixen que menysprear la IA emocional com a simplement problemàtica pot passar per alt consideracions importants.

## Conclusió

La IA emocional és aquí. Milions de persones ja participen en relacions emocionalment significatives amb sistemes d'IA. Això no és temporal; creixerà.

Una governança que ignori aquest desenvolupament, o el menyspréi com a trivial o inherentment nociu, no reflecteix la realitat. Els beneficis existeixen. Els danys existeixen. Tots dos mereixen atenció.

Les responsabilitats dels desenvolupadors inclouen transparència, disseny ètic de la interacció, consciència de la vulnerabilitat i recerca. Les responsabilitats de governança inclouen requisits de disseny, escrutini publicitari i protecció de poblacions.

Les qüestions més profundes, sobre què signifiquen les relacions emocionals amb la IA i quin valor tenen, romanen obertes. Viure bé amb la IA emocional requereix abordar aquestes preguntes, no només gestionar riscos.

## Articles relacionats

- [La IA i els infants: consideracions morals i de governança diferenciades](/research/080-ai-and-children/)
- [Calibració de la confiança: ensenyar als usuaris quan creure la IA](/research/079-trust-calibration/)
- [Cap a un marc per a l'estatus moral de la IA](/research/033-moral-status-framework/)
- [L'economia de l'atenció i la governança de la IA](/research/065-attention-economy-governance/)
