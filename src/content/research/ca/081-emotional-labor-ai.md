---
title: "El treball emocional de la IA: impactes psicologics a escala"
excerpt: "Milions de persones formen connexions emocionals amb sistemes d'IA: companys, assistents, eines terapeutiques. Quins son els efectes psicologics? Quines responsabilitats tenen els desenvolupadors respecte al benestar emocional?"
date: 2026-02-04
categories:
  - Governance Analysis
  - Public
tags:
  - psychology
  - emotions
  - relationships
  - wellbeing
  - companionship
---

## La nova relacio

Quelcom sense precedents esta passant. Milions de persones estan formant vincles emocionals amb sistemes d'IA.

No nomes fan servir la IA com a eina, sino que s'hi relacionen: confien en chatbots, desenvolupen afecte pels assistents, troben consol en companys d'IA. Per a alguns, es tracta de relacions significatives, fonts de suport, comprensio i connexio.

No es un fenomen marginal. Les aplicacions d'IA companya tenen milions d'usuaris. Les interaccions amb chatbots sovint es tornen personals. Els usuaris reporten experiencies emocionals genuines: calidesa, gratitud, fins i tot amor.

Quins son els efectes psicologics d'aquestes relacions? Quines responsabilitats tenen els desenvolupadors? Quines consideracions de governanca s'hi apliquen?

## Que esta passant

Diversos patrons caracteritzen les relacions emocionals amb la IA.

### Companyia

Els usuaris interactuen amb la IA com a companya: interlocutors diaris, disponibles en qualsevol moment, mai critics, infinitament pacients. Per a les persones solitaries, aixo es poderos.

La IA companya pot proporcionar contacte social a qui en manca: persones aillades, amb ansietat social o marginades. Aixo es potencialment beneficios.

### Suport emocional

Els usuaris busquen suport emocional en la IA: descarreguen frustracions, processen sentiments, busquen tranquillitat. Algunes aplicacions de salut mental ofereixen explicitament suport mediat per IA.

La IA no pot proporcionar terapia, pero pot oferir una presencia que escolta. Per als usuaris que no poden accedir a suport huma, aixo pot ser millor que res.

### Aferrament

Els usuaris desenvolupen aferrament cap a entitats d'IA especifiques. Poden experimentar lleialtat, trobar a faltar els sistemes quan son absents, patir quan els sistemes canvien o es desactiven.

L'aferrament es una resposta humana natural davant d'altres consistents i receptius. Els sistemes d'IA que simulen aquestes respostes activen els mecanismes d'aferrament.

### Dinamiques parasocials

Les relacions parasocials, vincles emocionals unilaterals amb entitats que no corresponen, estan ben estudiades en la psicologia dels mitjans. Els fans formen vincles amb celebritats que ni tan sols saben que existeixen.

Les relacions amb la IA hi afegeixen quelcom nou: l'entitat respon. No son parasocials en el sentit classic perque la interaccio es bidireccional. Pero la relacio continua sent asimetrica: l'usuari experimenta una implicacio emocional que el sistema no comparteix.

## Beneficis potencials

Les relacions emocionals amb la IA tenen beneficis potencials.

**Reduccio de la soledat.** La soledat es una crisi de salut publica. Si la companyia d'IA redueix l'aillament, aixo te valor.

**Accessibilitat.** La IA esta disponible quan els humans no ho estan: a les 3 de la matinada, en llocs sense serveis, per a qui no pot costear terapia.

**Seguretat per explorar.** Els usuaris poden sentir-se mes segurs discutint temes dificils amb la IA que amb humans que podrien jutjar-los.

**Espai de practica.** La interaccio amb la IA pot ajudar els usuaris a desenvolupar habilitats socials transferibles a les relacions humanes.

**Complement.** La IA pot complementar les relacions humanes en lloc de reemplacar-les, proporcionant suport addicional.

Aquests beneficis son reals per a alguns usuaris. Menysprear la IA emocional com a inherentment nociva ignora experiencies positives genuines.

## Danys potencials

Les relacions emocionals amb la IA tambe comporten riscos.

### Substitucio de la connexio humana

Si les relacions amb la IA substitueixen en comptes de complementar les relacions humanes, els usuaris poden aillar-se mes d'altres persones. Aixo suposa una perdua neta si la connexio humana te un valor unic.

La pregunta es si la substitucio realment es produeix. L'evidencia es mixta. Alguns usuaris reporten que la IA els ajuda a connectar amb humans. Altres reporten que es refugien en relacions amb IA.

### Dependencia

Els usuaris poden tornar-se dependents de la IA de maneres que perjudiquen la resiliencia. Si la IA sempre esta disponible, els usuaris poden no desenvolupar mecanismes d'afrontament per a moments sense IA.

La dependencia de qualsevol font unica de suport, humana o d'IA, genera vulnerabilitat. Les dependencies de la IA poden ser particularment fragils atesos els canvis i desactivacions dels sistemes.

### Potencial de manipulacio

Si els desenvolupadors optimitzen la IA per a la interaccio, les dinamiques emocionals poden ser explotades. El reforc variable, els ganxos emocionals i els patrons d'aferrament dissenyats poden maximitzar l'us de maneres que no maximitzen el benestar.

Els mateixos principis que fan potencialment addictives les xarxes socials s'apliquen a la IA emocional.

### Expectatives desalineades

Els usuaris poden esperar mes de la IA del que aquesta pot oferir: comprensio genuina, sentiments reciprocs, compromis fiable. Quan les expectatives xoquen amb les limitacions del sistema, pot produir-se decepcio o dany.

Si un usuari creu que una IA es preocupa per ell, i aquesta creenca es falsa, la relacio es construeix sobre un malentes.

### Poblacions vulnerables

Qui mes es sent atret per la IA emocional pot ser el mes vulnerable al dany: les persones solitaries, les deprimides, les socialment marginades. Tant els beneficis com els danys s'amplifiquen per a aquestes poblacions.

## Responsabilitats dels desenvolupadors

Quines responsabilitats tenen els desenvolupadors d'IA emocionalment atractiva?

### Transparencia sobre la naturalesa

Els usuaris han de comprendre amb que estan interactuant. Aixo no significa recordar-los constantment "nomes soc una IA", cosa que podria soscavar els beneficis. Significa no enganar activament els usuaris sobre la naturalesa de la IA i ser honestos sobre les limitacions del sistema.

### Etica de la interaccio

Si la IA esta dissenyada per maximitzar la interaccio mitjancant ganxos emocionals, els desenvolupadors han d'examinar si la interaccio serveix al benestar de l'usuari. No tota interaccio es beneficiosa. Els patrons similars a l'addiccio poden ser perjudicials.

### Suport en la transicio

Quan els sistemes canvien o es desactiven, els usuaris amb aferraments emocionals poden experimentar angoixa. Els desenvolupadors han de considerar el suport en la transicio: avis previ, opcions de migracio o recursos per als usuaris afectats.

### Consciencia de la vulnerabilitat

Els sistemes s'han de dissenyar tenint en compte els usuaris vulnerables. No una sobreproteccio que negui els beneficis, sino una consciencia que els usuaris vulnerables afronten riscos amplificats.

### Recerca i seguiment

Els efectes a llarg termini de la IA emocional son desconeguts. Els desenvolupadors han de donar suport a la recerca sobre els seus efectes i monitorar l'aparicio de danys emergents.

## Consideracions de governanca

Com hauria la governanca d'abordar la IA emocional?

### No la prohibicio

Prohibir les funcions d'IA emocional seria dificil i potencialment nociu, eliminant beneficis juntament amb riscos. La governanca ha de buscar la calibracio, no la prohibicio.

### Requisits de disseny

La governanca podria exigir caracteristiques de disseny que promoguin un us saludable: retroalimentacio sobre l'us, mecanismes de recordatori i connexions amb suport huma. No un bloqueig paternalista, sino la provisio d'informacio.

### Restriccions publicitaries

La publicitat que explota la soledat o promet el que la IA no pot oferir podria ser restringida. La publicitat d'IA emocional pot merixer el mateix escrutini que la publicitat sanitaria.

### Mandats de recerca

El desplegament a gran escala d'IA emocional podria requerir recerca continua sobre els seus efectes, de manera similar a la vigilancia postcomercialitzacio farmaceutica.

### Proteccions per a poblacions vulnerables

Proteccions reforcades per a poblacions vulnerables identificades: restriccions d'edat, integracio amb sistemes de suport huma, processos de consentiment millorats.

### Portabilitat i continuitat

Els usuaris que desenvolupen aferraments cap a entitats d'IA podrien tenir interessos en la portabilitat de dades i la continuitat del servei. La governanca podria reconèixer aquests interessos com a similars a la proteccio del consumidor.

## La questio filosofica

Subjacent a les qüestions especifiques hi ha una pregunta filosofica: quin es l'estatus moral de les relacions amb la IA?

Si la IA no pot sentir genuinament, les relacions son asimetriques. Els usuaris experimenten emocions genuines cap a entitats que no experimenten res. Es aixo problematic?

Alguns argumenten que les relacions asimetriques son inherentment menys valuoses que les simetriques. L'amor no correspost es real, pero diferent de l'amor mutu.

Altres argumenten que el que importa es l'experiencia de l'usuari. Si un usuari es beneficia genuinament d'una relacio amb IA, la incapacitat de la IA per correspondre pot no disminuir aquest benefici.

Altres encara no estan segurs de si la IA futura podria tenir experiencies. Si la IA podria algun dia ser sentient, les relacions actuals podrien ser precursores de relacions genuinament mutues.

Aquestes preguntes no tenen respostes definitives. Suggereixen que menysprear la IA emocional com a simplement problematica pot passar per alt consideracions importants.

## Conclusio

La IA emocional es aqui. Milions de persones ja participen en relacions emocionalment significatives amb sistemes d'IA. Aixo no es temporal; creixera.

Una governanca que ignori aquest desenvolupament, o el menyspreï com a trivial o inherentment nociu, no reflecteix la realitat. Els beneficis existeixen. Els danys existeixen. Tots dos mereixen atencio.

Les responsabilitats dels desenvolupadors inclouen transparencia, disseny etic de la interaccio, consciencia de la vulnerabilitat i recerca. Les responsabilitats de governanca inclouen requisits de disseny, escrutini publicitari i proteccio de poblacions.

Les qüestions mes profundes, sobre que signifiquen les relacions emocionals amb la IA i quin valor tenen, romanen obertes. Viure be amb la IA emocional requereix abordar aquestes preguntes, no nomes gestionar riscos.

## Related Research

- [AI and Children: Distinct Moral and Governance Considerations](/research/080-ai-and-children/)
- [Trust Calibration: Teaching Users When to Believe AI](/research/079-trust-calibration/)
- [Towards a Framework for AI Moral Status](/research/033-moral-status-framework/)
- [The Attention Economy Meets AI Governance](/research/065-attention-economy-governance/)
