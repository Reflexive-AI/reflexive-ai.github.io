---
title: "La historia de la governanca de la IA en 2000 paraules"
excerpt: "De les Lleis d'Asimov a la Llei d'IA de la UE: com el pensament sobre la governanca de la intelligencia artificial ha evolucionat al llarg de vuit decades."
date: 2026-01-14
categories:
  - Public
  - Governance Analysis
tags:
  - governance
  - regulation
  - policy
  - guide
---

## La prehistoria: decades de 1940 a 1990

La governanca de la IA va comencar abans que la propia IA existis.

**1942: Les Tres Lleis d'Asimov.** L'escriptor de ciencia ficcio Isaac Asimov va introduir les seves famoses Tres Lleis de la Robotica. Tot i ser ficticies, van representar el primer intent serios de pensar en com les intelligencies artificials podrien ser restringides. Tambe van illustrar un problema fonamental: les regles formals poden tenir consequencies no desitjades i casos limit que soscaven la seva intencio. Aixo va presagiar els reptes amb els quals encara lluitem avui a [definir l'alineament](/research/016-what-alignment-means/).

**1956: Neix la IA.** La Conferencia de Dartmouth va llancar la IA com a camp d'estudi. L'optimisme inicial predeia una IA de nivell huma en decades. La governanca semblava prematura: la tecnologia amb prou feines existia.

**Decades de 1960 a 1980: L'era dels sistemes experts.** La recerca en IA es va centrar a codificar l'experiencia humana en sistemes basats en regles. Les discussions sobre governanca van ser limitades, centrant-se principalment en la responsabilitat per errors dels sistemes experts en contextos medics i legals.

**Decades de 1980 a 1990: El primer hivern de la IA.** Quan la IA no va complir les expectatives inflades, el financament es va assecar i l'interes va decaure. Les discussions sobre governanca van desapareixer juntament amb la tecnologia.

## La revolucio de l'aprenentatge: decades de 2000 a 2010

El ressorgiment de les xarxes neuronals ho va canviar tot.

**2006: Sorgeix l'aprenentatge profund.** Els investigadors van descobrir com entrenar xarxes neuronals amb moltes capes. Aquest avanc eventualment faria possible la IA moderna, tot i que les implicacions no van ser immediatament evidents.

**2010: Comenca la rendicio de comptes algoritmica.** Els academics van comencar a examinar com els sistemes de presa de decisions automatitzats afectaven la vida de les persones: puntuacions de credit, decisions de contractacio, elegibilitat per a prestacions socials. Encara no s'anomenava "governanca de la IA", pero les preocupacions eren fonamentals.

**2011: Watson guanya Jeopardy!** La victoria de Watson d'IBM sobre campions humans al concurs va despertar l'interes public en les capacitats de la IA. Les discussions es van mantenir enfocades en la disrupcio economica mes que en la seguretat.

**2012: L'avanc d'ImageNet.** Una xarxa neuronal va superar dramaticament els enfocaments tradicionals en reconeixement d'imatges. Aixo va marcar l'inici de l'aprenentatge profund modern i els rapids avancos en capacitats que eventualment requeririen atencio en materia de governanca.

**2014: El discurs del risc existencial.** "Superintelligence" de Nick Bostrom va portar les preocupacions sobre la seguretat de la IA a llarg termini a la discussio generalitzada. Tot i ser controvertit, va establir que la governanca de la IA necessitava considerar escenaris transformadors, no nomes millores incrementals.

## El despertar: 2015-2019

La governanca de la IA va emergir com un camp diferenciat.

**2015: Carta oberta sobre la seguretat de la IA.** Milers d'investigadors van signar una carta oberta demanant que la IA fos "robusta i beneficiosa". El Future of Life Institute va reunir experts. La seguretat de la IA va passar de ser una preocupacio marginal a una agenda de recerca legitima.

**2016: L'etica de la IA es generalitza.** L'IEEE va comencar a desenvolupar estandards per al disseny eticament alineat. Les empreses tecnologiques van crear comites d'etica i van publicar principis d'IA. La investigacio de ProPublica sobre COMPAS, un algorisme de prediccio de reincidencia, va demostrar el biaix algoritmic en decisions d'alt impacte.

**2017: Els Principis d'Asilomar.** Els investigadors es van reunir a Asilomar, seu de la famosa conferencia de biotecnologia de 1975, per desenvolupar 23 principis per a una IA beneficiosa. Aquests cobrien la cultura de recerca, l'etica i la seguretat a llarg termini. El parallelisme amb la governanca de la bioseguretat va ser intencional.

**2018: El RGPD inclou disposicions algoritmiques.** El Reglament General de Proteccio de Dades de la Unio Europea va incloure un "dret a l'explicacio" per a les decisions automatitzades. Tot i ser limitat i debatut, va representar la primera legislacio important que abordava explicitament la presa de decisions per IA.

**2019: L'auge de l'etica.** Totes les grans empreses tecnologiques van publicar principis d'etica de la IA. Governs de tot el mon van llancar estrategies d'IA. La UE va establir el seu Grup d'Experts d'Alt Nivell sobre IA, que va produir directrius etiques i recomanacions politiques. Pekin va publicar principis de governanca de la IA.

Aquest periode va establir conceptes clau: equitat, rendicio de comptes, transparencia i explicabilitat (sovint abreujats com FATE per les sigles en angles). Pero els critics van assenyalar que les directrius etiques eren sovint vagues, voluntaries i servien mes com a relacions publiques que com a restriccions genuines.

## El gir regulatori: 2020-2023

La pandemia de COVID-19 i els avancos en capacitats van transformar la governanca de la IA.

**2020: La pandemia accelera l'adopcio.** Els sistemes d'IA es van desplegar rapidament per al diagnostic medic, el desenvolupament de vacunes i el rastreig de contactes. Aquesta acceleracio sovint va superar la capacitat de governanca, plantejant preguntes sobre [la proporcionalitat en la divulgacio](/research/001-proportionality-disclosure/) i la supervisio.

**2021: Es proposa la Llei d'IA de la UE.** La Comissio Europea va proposar la primera regulacio integral d'IA del mon. El seu enfocament basat en riscos, que prohibia algunes aplicacions, regulava fortament d'altres i en deixava moltes sense regular, es va convertir en una plantilla per al pensament sobre governanca a nivell global.

**2022: Emergeixen els grans models de llenguatge.** El llancament public de ChatGPT al novembre de 2022 va portar les capacitats de la IA a l'experiencia publica directa per primera vegada. De sobte, milions de persones interactuaven amb sistemes capacos d'escriure, raonar i assistir amb tasques complexes. La governanca que havia semblat abstracta es va tornar urgent.

**2023: La crisi de capacitats.** Els rapids avancos van provocar respostes urgents de governanca:

- Cartes obertes demanant pauses en el desenvolupament de la IA
- Audiencies al Congres amb executius d'empreses d'IA
- La Cimera de Seguretat de la IA del Regne Unit a Bletchley Park
- Compromisos voluntaris de les principals empreses d'IA
- Ordres executives sobre seguretat de la IA de la Casa Blanca

Aquest periode va veure l'emergencia de "IA de frontera" com a categoria de governanca: sistemes les capacitats dels quals demanaven atencio especial. Hem explorat com aquests sistemes creen [reptes regulatoris](/research/018-regulation-is-hard/) i [problemes d'excedent de capacitats](/research/009-capability-overhang/).

## El repte de la implementacio: 2024-present

Ens trobem ara en un periode de desenvolupament institucional.

**2024: S'aprova la Llei d'IA de la UE.** La primera legislacio integral d'IA del mon es va convertir en llei. La seva implementacio trigaria anys, pero la plantilla existia. Altres jurisdiccions van comencar a adaptar o respondre a l'enfocament de la UE.

**Proliferen els Instituts de Seguretat de la IA.** El Regne Unit, els Estats Units, el Japo, Singapur i d'altres van establir instituts nacionals de seguretat de la IA. Aquests organismes pretenen construir capacitat tecnica dins del govern, un reconeixement que [la capacitat d'auditoria externa](/research/010-self-reporting-vs-audit/) es essencial per a una supervisio eficac.

**S'aprofundeixen els compromisos voluntaris.** Els principals laboratoris d'IA van assumir compromisos en materia de proves de capacitats perilloses, notificacio d'incidents i practiques de seguretat. La questio de si aquests compromisos son significatius sense mecanismes d'aplicacio segueix oberta, com discutim en la nostra analisi de [les limitacions de l'autonotificacio](/research/010-self-reporting-vs-audit/).

**Intents de coordinacio internacional.** L'ONU va convocar discussions sobre la governanca internacional de la IA. Es van explorar acords bilaterals entre les principals potencies en IA. No obstant aixo, el progres segueix sent limitat, reflectint els reptes fonamentals de governar una tecnologia on l'avantatge competitiu i els interessos de seguretat nacional son significatius.

**2025-2026: Reptes actuals.** En el moment d'escriure aixo, ens enfrontem a:

- La implementacio de la Llei d'IA de la UE i regulacions similars
- El debat sobre la governanca del comput i [les seves limitacions](/research/023-compute-governance/)
- Qestions sobre [la proteccio de denunciants](/research/022-whistleblower-protections/) als laboratoris d'IA
- Avancos continuats en capacitats que superen la governanca
- [Marcs de responsabilitat](/research/020-liability-frameworks/) encara en desenvolupament

## Llicons de la historia

Vuit decades de reflexio sobre la governanca de la IA ofereixen diverses llicons.

### Tecnologia i governanca coevolucionen

Les discussions sobre governanca estan modelades per la tecnologia, pero tambe modelen el desenvolupament tecnologic. Els conceptes desenvolupats en el discurs de la IA etica (equitat, transparencia, rendicio de comptes) han influit en com es construeixen els sistemes, no nomes en com es regulen.

### Les finestres s'obren i es tanquen

Els periodes de crisi i atencio creen oportunitats per a la innovacio en governanca. El moment actual es una d'aquestes finestres. Queda per veure si produira institucions duradores.

### Els principis son insuficients

Totes les grans empreses tecnologiques tenen principis d'etica de la IA. Moltes els violen regularment. Els principis importen, pero els mecanismes d'aplicacio, les estructures de rendicio de comptes i les restriccions genuines son el que fa real la governanca. Per aixo ens centrem en [restriccions llegibles per maquina](/research/003-machine-readable-constraint-schema/) i [rendicio de comptes operativa](/research/006-meta-governance-auditors/).

### Les solucions tecniques i socials s'han de combinar

La governanca de la IA no pot ser purament tecnica (construir sistemes mes segurs) ni purament social (regular el comportament). Requereix ambdues, integrades acuradament. Aquesta es la idea central de la governanca reflexiva: la idea que els sistemes poden participar en la seva propia supervisio, com s'explora al nostre [manifest](/research/030-manifesto/).

### La concentracio crea tant risc com oportunitat

Que el desenvolupament d'IA de frontera estigui concentrat en uns pocs actors es preocupant per a la distribucio del poder pero potencialment util per a la governanca. Menys actors poden significar una coordinacio mes manejable.

## Que ve despres

Som als primers capitols de la governanca de la IA, no als ultims.

Les properes decades probablement veuran:

- Marcs internacionals comparables als de la tecnologia nuclear o el clima
- Professionalitzacio dels rols de governanca de la IA
- Estandards tecnics que es tornen tan importants com les regulacions legals
- Tensio continuada entre innovacio i precaucio

El que fem ara, en aquesta finestra d'atencio i possibilitat, modelara la governanca de la IA durant decades. La Reflexive AI Initiative es una contribucio a aquesta feina. Et convidem a [unir-te a nosaltres](/contribute/).

## Lectures addicionals

- [Governanca de la IA per a no experts: una guia](/research/017-governance-primer/)
- [Per que "simplement regular la IA" es mes dificil del que sembla](/research/018-regulation-is-hard/)
- [La Llei d'IA de la UE: el que no contempla](/research/019-eu-ai-act-gaps/)
- [Dret tou enfront de dret dur en la regulacio de la IA](/research/040-soft-law-hard-law/) (proper)
