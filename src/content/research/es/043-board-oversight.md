---
title: "Supervisión de la IA a nivel de consejo de administración: mejores prácticas"
excerpt: "Los consejos de administración necesitan cada vez más supervisar la estrategia y los riesgos de la IA. Una guía práctica sobre cómo es una supervisión eficaz de la IA a nivel de consejo."
date: 2026-01-25
categories:
  - Governance Analysis
  - Public
tags:
  - governance
  - institutional-design
  - safety
  - transparency
---

## Por qué los consejos deben comprometerse

Los consejos de administración tienen deberes fiduciarios hacia los accionistas y, cada vez más, responsabilidades hacia otras partes interesadas. La IA plantea cuestiones de gobernanza que exigen la atención del consejo:

**Importancia estratégica.** La IA puede ser central para la estrategia corporativa. Los consejos deben comprender las oportunidades y riesgos de la IA para cumplir su función de supervisión estratégica.

**Riesgo material.** La IA puede generar riesgos materiales: regulatorios, reputacionales, operativos y legales. Los consejos son responsables de la supervisión del riesgo.

**Exposición a responsabilidad civil.** Los consejeros pueden enfrentar responsabilidad personal por daños relacionados con la IA si no ejercen una supervisión adecuada.

**Expectativas de las partes interesadas.** Los inversores, los reguladores y el público esperan cada vez más que el consejo se comprometa con la gobernanza de la IA.

Muchos consejos no están adecuadamente preparados para esta supervisión. Este análisis proporciona orientación práctica para los consejos que buscan mejorar la supervisión de la IA.

## Estado actual de la supervisión de la IA por los consejos

El compromiso del consejo con la IA varía ampliamente.

**Compromiso mínimo.** Muchos consejos tratan la IA como una cuestión técnica delegada a la dirección, recibiendo informes ocasionales pero sin ejercer una supervisión sustantiva.

**Enfoque en el riesgo.** Algunos consejos se involucran con la IA principalmente a través de comités de riesgos, centrándose en el cumplimiento normativo y la responsabilidad civil en lugar de una gobernanza más amplia.

**Enfoque estratégico.** Algunos consejos se relacionan con la IA como oportunidad estratégica, potencialmente infravalorando las consideraciones de riesgo.

**Supervisión integrada.** Una minoría de consejos ha desarrollado una supervisión integral de la IA que integra estrategia, riesgo, ética y operaciones.

La investigación sugiere que la mayoría de los consejos se encuentran en las dos primeras categorías: un compromiso insuficiente para la importancia que la IA tiene en sus organizaciones.

## La brecha de conocimiento

Un desafío fundamental es la brecha de conocimiento entre las capacidades de la IA y la experiencia del consejo.

**Complejidad técnica.** Los sistemas de IA son técnicamente complejos. La mayoría de los consejeros carecen de formación en aprendizaje automático, ciencia de datos o campos relacionados.

**Cambio rápido.** Las capacidades de la IA cambian más rápido de lo que los consejos pueden desarrollar experiencia. El conocimiento adquirido un año puede estar obsoleto al siguiente.

**Barreras de jerga.** El discurso sobre IA está lleno de jerga que oscurece en lugar de iluminar. Los consejos pueden no saber lo suficiente para hacer buenas preguntas.

**Asimetría de información.** La dirección controla el flujo de información hacia los consejos. Los consejeros que dependen de los informes de la dirección pueden no recibir información completa o equilibrada.

Abordar esta brecha de conocimiento es esencial para una supervisión eficaz.

## Desarrollar la capacidad del consejo

Varios enfoques pueden desarrollar la capacidad del consejo para la supervisión de la IA.

### Composición del consejo

**Experiencia en IA en el consejo.** Considerar la incorporación de consejeros con experiencia en IA: antiguos directores de tecnología, investigadores de IA o expertos en política tecnológica. La experiencia no tiene que ser técnica; el conocimiento de la gobernanza y el riesgo de la IA es valioso.

**Formación del consejo.** Proporcionar formación continua a todos los consejeros sobre los desarrollos, riesgos y gobernanza de la IA. Esta debe ser regular y sustantiva, no informes ocasionales.

**Asesores externos.** Contratar asesores externos para proporcionar una perspectiva independiente y compensar las lagunas de conocimiento del consejo.

### Estructura de comités

**Comité de IA.** Algunas organizaciones han establecido comités dedicados a la IA o la tecnología. Estos proporcionan atención focalizada, pero pueden aislar la supervisión de la IA de la gobernanza más amplia.

**Enfoque integrado.** Alternativamente, integrar la supervisión de la IA en los comités existentes: los comités de riesgos abordan el riesgo de la IA, los comités de auditoría abordan los controles de IA, los comités de compensación abordan las implicaciones de la IA en los incentivos.

**Compromiso del consejo pleno.** Dada la importancia de la IA, el compromiso del consejo pleno suele ser apropiado, con comités que se encargan del trabajo detallado.

### Flujo de información

**Acceso directo.** Asegurar que el consejo tenga acceso al liderazgo en IA y seguridad, no solo a la alta dirección. Esto es paralelo a los requisitos de acceso del comité de auditoría a la auditoría interna.

**Informes equilibrados.** Exigir informes que incluyan riesgos y fallos, no solo éxitos. Crear canales para que las preocupaciones lleguen al consejo.

**Perspectivas externas.** Incluir perspectivas externas en los materiales del consejo: evolución regulatoria, prácticas de competidores, evaluaciones de expertos.

**Indicadores clave.** Desarrollar indicadores que el consejo pueda supervisar: tasas de incidentes, inversión en seguridad, evaluaciones de capacidades, estado de cumplimiento normativo.

## Qué deben supervisar los consejos

La supervisión de la IA por el consejo debería abarcar varias áreas.

### Estrategia

**Alineación de la estrategia de IA.** ¿Se alinea la estrategia de IA con la estrategia corporativa general? ¿Está la empresa invirtiendo adecuadamente en IA?

**Posicionamiento competitivo.** ¿Cómo se compara la capacidad de IA de la empresa con la de los competidores? ¿Cuáles son las implicaciones estratégicas?

**Implicaciones a largo plazo.** ¿Cuáles son las implicaciones a largo plazo de las inversiones en IA? ¿Cómo podría la IA transformar el negocio?

### Riesgo

**Identificación de riesgos.** ¿Qué riesgos relacionados con la IA existen? ¿Regulatorios, reputacionales, operativos, legales, éticos?

**Evaluación de riesgos.** ¿Cuán significativos son estos riesgos? ¿Cuál es la magnitud y probabilidad potenciales?

**Mitigación de riesgos.** ¿Qué controles existen? ¿Son adecuados?

**Riesgos emergentes.** ¿Qué nuevos riesgos están surgiendo a medida que avanzan las capacidades de la IA?

Nuestro análisis del [excedente de capacidad](/research/009-capability-overhang/) es relevante: pueden existir riesgos que aún no son evidentes.

### Ética y seguridad

**Marco ético.** ¿Qué principios éticos guían el desarrollo y despliegue de la IA? ¿Son sustantivos y operativos?

**Prácticas de seguridad.** ¿Qué prácticas de seguridad existen? ¿Cómo se comparan con los estándares de la industria y los requisitos regulatorios?

**Gestión de incidentes.** ¿Cómo se identifican, evalúan y abordan los incidentes de IA? ¿Cuál es el historial?

**Impacto en las partes interesadas.** ¿Cómo afectan los sistemas de IA a clientes, empleados y comunidades? ¿Qué salvaguardas existen?

### Cumplimiento normativo

**Cumplimiento regulatorio.** ¿Cumple la empresa con las regulaciones de IA aplicables? ¿Cuál es la postura de cumplimiento ante regulaciones emergentes como la Ley de IA de la UE?

**Requisitos de divulgación.** ¿Son adecuadas las divulgaciones relacionadas con la IA? ¿Existen riesgos materiales de IA que deban divulgarse?

**Auditoría y aseguramiento.** ¿Existe una cobertura adecuada de auditoría interna de la IA? ¿Son apropiadas las evaluaciones de terceros?

### Estructura de gobernanza

**Responsabilidad organizativa.** ¿Quién es responsable de la gobernanza de la IA dentro de la dirección? ¿Es adecuada la estructura?

**Autoridad y rendición de cuentas.** ¿Tienen las funciones de seguridad y ética la autoridad adecuada? ¿Existe una rendición de cuentas clara?

**Cultura.** ¿Tiene la organización una cultura apropiada en torno a la seguridad de la IA? ¿Se plantean y abordan las preocupaciones?

Examinamos la gobernanza organizativa en [estructuras de gobernanza corporativa para la seguridad de la IA](/research/042-corporate-governance/).

## Prácticas de compromiso del consejo

Varias prácticas pueden mejorar el compromiso del consejo.

### Informes regulares

**Cadencia.** Los informes sobre IA deberían ser regulares: trimestrales como mínimo, con mayor frecuencia para las empresas donde la IA es central.

**Profundidad.** Los informes deberían proporcionar información sustantiva, no solo resúmenes optimistas. Incluir indicadores, incidentes y desafíos.

**Tiempo de discusión.** Asignar tiempo adecuado para la discusión, no solo para la presentación. Los consejeros deberían tener oportunidad de indagar.

### Visitas y demostraciones

**Inmersión técnica.** Las visitas del consejo a las operaciones de desarrollo de IA, con demostraciones de los sistemas y explicaciones de los procesos, pueden generar comprensión.

**Observación de la cultura.** Las visitas también permiten a los consejeros observar la cultura: cómo se discute la seguridad, si las preocupaciones se plantean abiertamente.

### Análisis de escenarios

**Escenarios de riesgo.** Recorrer escenarios de materialización de riesgos de IA. ¿Cómo respondería la empresa? ¿Son adecuadas las capacidades de respuesta?

**Escenarios estratégicos.** Considerar escenarios de avance de las capacidades de IA. ¿Qué oportunidades y amenazas podrían surgir?

### Relación con el exterior

**Relaciones con reguladores.** Los consejeros pueden relacionarse con los reguladores para comprender las expectativas y construir relaciones.

**Participación en la industria.** La participación en iniciativas de gobernanza del sector puede proporcionar perspectiva y desarrollar redes.

**Consulta a expertos.** La consulta periódica con expertos externos en seguridad y gobernanza de la IA proporciona una perspectiva independiente.

### Sesiones ejecutivas

**Discusión sin la dirección.** Las sesiones ejecutivas sin la dirección permiten a los consejeros discutir preocupaciones con franqueza y evaluar el desempeño de la dirección.

**Acceso al liderazgo en seguridad.** Considerar sesiones ejecutivas ocasionales con el liderazgo en seguridad de IA, sin la presencia de ejecutivos de producto.

## Señales de alerta

Ciertos indicios sugieren una supervisión inadecuada de la IA por parte del consejo:

- Ningún consejero con experiencia o conocimientos relevantes en IA
- Los informes sobre IA se limitan a oportunidades comerciales, sin abordar los riesgos
- No existen indicadores de seguridad o gobernanza de la IA
- El consejo desconoce los incidentes de IA que se han producido
- Las preocupaciones de seguridad no llegan al nivel del consejo
- La dirección controla todo el flujo de información sobre IA hacia el consejo
- No existe discusión sobre la IA en la supervisión de riesgos
- Los principios éticos existen pero nunca se discuten

## Expectativas crecientes

Las expectativas respecto a la supervisión de la IA por los consejos están aumentando:

**Presión regulatoria.** Los reguladores esperan cada vez más que el consejo se comprometa con la gobernanza de la IA. Los requisitos de gobernanza de la Ley de IA de la UE probablemente se extenderán al nivel del consejo.

**Expectativas de los inversores.** Los inversores institucionales preguntan cada vez más sobre la gobernanza de la IA. La supervisión del consejo se convertirá en una expectativa estándar.

**Riesgo de litigio.** La responsabilidad de los consejeros por fallos de IA puede aumentar, creando incentivos para una supervisión demostrable.

**Requisitos de divulgación.** Están surgiendo requisitos de divulgación sobre la gobernanza de la IA, que obligan a los consejos a articular sus prácticas de supervisión.

Los consejos que desarrollen una supervisión eficaz ahora estarán mejor posicionados a medida que las expectativas se formalicen.

## Conclusión

La supervisión de la IA a nivel de consejo de administración se está volviendo esencial. Los consejos necesitan experiencia, información y prácticas de compromiso que permitan una supervisión eficaz de la estrategia, el riesgo, la ética y la gobernanza de la IA.

Esto requiere una inversión deliberada: en la composición del consejo, la formación, el flujo de información y las prácticas de compromiso. Los consejos que tratan la IA como una cuestión puramente técnica delegada a la dirección están incumpliendo sus responsabilidades de supervisión.

Las consecuencias son importantes. Los fallos relacionados con la IA pueden causar daños materiales a las empresas y a las partes interesadas. Una supervisión eficaz del consejo es tanto un imperativo de gobernanza como una necesidad de gestión de riesgos.

## Lecturas complementarias

- [Estructuras de gobernanza corporativa para la seguridad de la IA](/research/042-corporate-governance/)
- [Marcos de responsabilidad civil por daños de la IA](/research/020-liability-frameworks/)
- [Protecciones para denunciantes en los laboratorios de IA](/research/022-whistleblower-protections/)
- [El problema del excedente de capacidad](/research/009-capability-overhang/)
