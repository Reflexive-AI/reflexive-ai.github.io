---
title: "Seguridad tecnica frente a seguridad social: problemas diferentes"
excerpt: "Por que hacer que los sistemas de IA funcionen segun lo previsto es un desafio diferente de hacer que el desarrollo de la IA sea bueno para la sociedad, y por que confundirlos conduce a una gobernanza deficiente."
date: 2026-01-16
categories:
  - Governance Analysis
  - Public
tags:
  - safety
  - alignment
  - governance
  - ethics
---

## Dos significados de "seguridad de la IA"

Cuando alguien dice que trabaja en "seguridad de la IA", puede referirse a dos cosas muy diferentes.

**La seguridad tecnica** se centra en hacer que los sistemas de IA se comporten segun lo previsto. Esto incluye evitar que los sistemas produzcan resultados daninos, evitar comportamientos no deseados, garantizar la robustez frente a entradas adversarias y construir una IA que haga de manera fiable lo que sus operadores quieren.

**La seguridad social** se centra en hacer que el desarrollo de la IA sea beneficioso para la humanidad. Esto incluye distribuir los beneficios de la IA de manera justa, prevenir la concentracion de poder, proteger los derechos y la democracia, y asegurar que la IA sirva al bienestar colectivo en lugar de a intereses limitados.

Estos problemas se superponen pero son fundamentalmente distintos. Confundirlos conduce a un discurso confuso y a una gobernanza deficiente.

Este analisis examina por que la distincion importa, como la confusion causa problemas y que significa esto para la gobernanza de la IA.

## El problema de la seguridad tecnica

La seguridad tecnica es principalmente un desafio de ingenieria. El objetivo son sistemas de IA fiables, predecibles y controlables.

### Preguntas clave

- Como especificamos lo que queremos que haga la IA con la suficiente precision para que realmente lo haga? (El problema de alineamiento que exploramos en [que significa realmente el alineamiento](/research/016-what-alignment-means/).)
- Como evitamos que la IA produzca resultados daninos como instrucciones peligrosas o contenido manipulador?
- Como aseguramos que los sistemas de IA se comporten de manera consistente en diferentes contextos y con diferentes entradas?
- Como mantenemos la supervision humana a medida que los sistemas se vuelven mas autonomos?

### Quien trabaja en ello

La seguridad tecnica es trabajada principalmente por investigadores de aprendizaje automatico, a menudo dentro de los laboratorios de IA. Es una agenda de investigacion tecnica con articulos, puntos de referencia y experimentos.

### Como se ve el exito

Un sistema de IA tecnicamente seguro hace lo que sus operadores pretenden, no produce resultados daninos y puede ser controlado y supervisado de manera fiable. Funciona segun lo disenado.

### Limitaciones

Un sistema tecnicamente seguro aun puede causar dano social. Un sistema de vigilancia que identifica perfectamente a los disidentes es tecnicamente exitoso pero socialmente danino. Un algoritmo de recomendacion que maximiza eficientemente la participacion puede ser tecnicamente robusto mientras socava la salud mental o el discurso democratico.

La seguridad tecnica es necesaria pero no suficiente para una IA beneficiosa.

## El problema de la seguridad social

La seguridad social es principalmente un desafio politico e institucional. El objetivo es un desarrollo de la IA que beneficie ampliamente a la humanidad.

### Preguntas clave

- Quien controla las decisiones de desarrollo y despliegue de la IA?
- Como se distribuyen los beneficios y costes de la IA en la sociedad?
- Que protecciones existen para quienes son danados por los sistemas de IA?
- Como prevenimos que la IA se utilice para concentrar poder o socavar la democracia?
- Que estructuras institucionales aseguran que la IA sirva a los intereses colectivos?

### Quien trabaja en ello

La seguridad social es trabajada por una comunidad diversa: responsables politicos, defensores de la sociedad civil, juristas, eticos, cientificos sociales y, cada vez mas, investigadores tecnicos que reconocen que las soluciones tecnicas solas son insuficientes.

### Como se ve el exito

Un desarrollo de IA socialmente seguro produce beneficios amplios, incluye protecciones robustas para los vulnerables, mantiene la gobernanza democratica y previene la concentracion peligrosa de poder. La tecnologia sirve a la humanidad en lugar de al reves.

### Limitaciones

Las medidas de seguridad social no pueden sustituir las capacidades tecnicas. Ninguna cantidad de gobernanza puede hacer fiable un sistema poco fiable. Y las intervenciones sociales a menudo no pueden seguir el ritmo del cambio tecnico.

## Como la confusion causa problemas

Cuando no distinguimos entre seguridad tecnica y social, surgen varios problemas.

### Investigadores tecnicos que afirman resolver problemas politicos

El trabajo en seguridad tecnica es valioso, pero no puede responder a preguntas como "a quien debe servir la IA?" o "como deben distribuirse los beneficios?" Cuando los investigadores tecnicos insinuan que la investigacion sobre alineamiento resuelve la gobernanza de la IA, se exceden, y potencialmente distraen de la necesaria participacion politica.

Esto esta relacionado con lo que identificamos en [el problema de la IA honesta](/research/029-honest-ai/): las soluciones tecnicas incorporan juicios de valor, pero esos juicios deben hacerse explicitamente a traves de procesos democraticos, no implicitamente a traves de decisiones de ingenieria.

### Responsables politicos que delegan en "soluciones" tecnicas

Los responsables politicos a veces tratan la gobernanza de la IA como un problema tecnico que los expertos tecnicos deben resolver. Esto supone abdicar de la responsabilidad democratica. Las preguntas sobre el riesgo aceptable, la distribucion de beneficios y los derechos fundamentales son cuestiones politicas que requieren decisiones politicas.

Como discutimos en [lo que los responsables politicos entienden mal sobre el riesgo de la IA](/research/033-policymaker-misconceptions/), la experiencia tecnica debe informar la gobernanza pero no puede sustituir la deliberacion democratica.

### Equipos de seguridad haciendo etica (y viceversa)

Las empresas de IA a menudo confunden los equipos de seguridad y de etica, dandoles mandatos superpuestos. Esto puede funcionar bien cuando los problemas genuinamente se superponen. Pero tambien puede significar que ningun problema recibe la atencion adecuada: las preocupaciones eticas se tratan como problemas de ingenieria, mientras que los problemas de ingenieria se diluyen con consideraciones sociales mas amplias.

### No ver la interseccion

A veces los problemas requieren tanto soluciones tecnicas como sociales. El sesgo algoritmico, por ejemplo, tiene aspectos tecnicos (como los sistemas amplifican los sesgos de los datos de entrenamiento) y aspectos sociales (que sesgos importan, que requiere la equidad, quien decide). Abordar solo una dimension deja el problema sin resolver.

## Donde se intersecan

Los problemas no estan completamente separados. Varias cuestiones requieren abordar ambas dimensiones.

### Poder y control

Las cuestiones tecnicas sobre la controlabilidad de la IA se conectan con las cuestiones sociales sobre quien controla la IA. Un sistema que es tecnicamente controlable pero controlado por actores daninos no es seguro en ningun sentido significativo.

### Transparencia y rendicion de cuentas

La investigacion tecnica en interpretabilidad se conecta con las demandas sociales de rendicion de cuentas. Pero los sistemas transparentes aun pueden ser mal utilizados, y la rendicion de cuentas requiere infraestructura institucional mas alla de las capacidades tecnicas.

### Capacidad y riesgo

Los niveles de capacidad tecnica tienen implicaciones sociales. Los sistemas mas capaces crean mayores riesgos sociales si la gobernanza es inadecuada. Las decisiones tecnicas sobre que capacidades desarrollar son, por tanto, tambien decisiones sociales.

### Concentracion

Las economias de escala tecnicas en el desarrollo de IA se conectan con las preocupaciones sociales sobre la concentracion de poder. El hecho de que la IA de frontera requiera recursos masivos es tanto una realidad tecnica como un desafio de gobernanza.

## Implicaciones para la gobernanza

Esta distincion tiene implicaciones practicas para como gobernamos la IA.

### Supervision separada pero coordinada

La seguridad tecnica y el impacto social requieren mecanismos de supervision diferentes. Los organismos de estandares tecnicos deben abordar el comportamiento de los sistemas. Las instituciones democraticas deben abordar las condiciones de despliegue, la proteccion de derechos y la distribucion de beneficios. Estos organismos deben coordinarse pero no fusionarse.

### Diferente experiencia para diferentes problemas

La seguridad tecnica requiere experiencia en aprendizaje automatico. La seguridad social requiere experiencia diversa: derecho, economia, etica, ciencias sociales, conocimiento del dominio. Las estructuras de gobernanza deben incorporar ambas sin confundirlas.

### Multiples intervenciones en multiples puntos

Las intervenciones tecnicas durante el desarrollo (pruebas, verificacion, monitorizacion) abordan la seguridad tecnica. Las intervenciones sociales en torno al despliegue (licencias, auditodia, responsabilidad) abordan la seguridad social. Ambas son necesarias; ninguna es suficiente.

### No dejar que una sustituya a la otra

Los desarrolladores de IA no deben afirmar que el trabajo en seguridad tecnica aborda las preocupaciones sociales. Los responsables politicos no deben asumir que la gobernanza puede sustituir a la robustez tecnica. Cada problema requiere sus propias soluciones.

## La conexion reflexiva

Nuestro trabajo sobre gobernanza reflexiva intenta tender puentes entre estos dominios. La idea de que [los sistemas de IA pueden participar en su propia gobernanza](/research/030-manifesto/) es tanto una propuesta tecnica (sistemas que informan restricciones, explican limites) como social (hacer la IA mas legible y responsable).

Las [restricciones legibles por maquina](/research/003-machine-readable-constraint-schema/) son un artefacto tecnico que sirve a propositos sociales. Los [protocolos de comunicacion de IA a regulador](/research/014-ai-regulator-protocol/) requieren tanto infraestructura tecnica como capacidad institucional.

Esta integracion es la contribucion distintiva de los enfoques reflexivos: reconocer que lo tecnico y lo social son distintos pero deben estar conectados, y construir puentes que respeten ambos dominios.

## Lecturas adicionales

- [Que significa realmente el alineamiento](/research/016-what-alignment-means/)
- [El problema de la IA honesta](/research/029-honest-ai/)
- [Un manifiesto de IA reflexiva](/research/030-manifesto/)
- [Lo que los responsables politicos entienden mal sobre el riesgo de la IA](/research/033-policymaker-misconceptions/)
