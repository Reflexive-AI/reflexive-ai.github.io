---
title: "El problema de los actores pequeños: cómo la regulación de IA configura la estructura de mercado"
excerpt: "Las regulaciones de IA a menudo favorecen a los grandes incumbentes que pueden asumir el cumplimiento. ¿Cómo puede la gobernanza evitar crear barreras que consoliden el poder y excluyan a los innovadores más pequeños?"
date: 2026-02-04
categories:
  - Governance Analysis
  - Policy Proposal
tags:
  - regulation
  - market-structure
  - small-actors
  - competition
  - power-concentration
---

## El coste oculto del cumplimiento

Toda regulación tiene costes de cumplimiento. Los requisitos de documentación exigen tiempo de abogados. Las auditorías requieren honorarios de auditores. Las pruebas de seguridad demandan infraestructura. La certificación implica burocracia.

Para las grandes organizaciones, estos costes son manejables. Una empresa con miles de millones en ingresos puede absorber millones en cumplimiento. El coste es una partida contable.

Para las organizaciones pequeñas, los mismos costes absolutos pueden ser prohibitivos. Una startup con diez empleados no puede contratar un equipo de cumplimiento. Una organización sin ánimo de lucro no puede permitirse auditorías de nivel empresarial.

Esto crea un sesgo estructural en la regulación: las normas diseñadas para actores grandes pueden excluir a los pequeños, no porque los actores pequeños sean menos seguros, sino porque no pueden navegar el cumplimiento.

## Cómo se manifiesta en la IA

Las propuestas de gobernanza de IA a menudo contienen elementos que gravan desproporcionadamente a los actores pequeños.

### Umbrales de computación

Las propuestas que activan la supervisión por encima de ciertos niveles de computación parecen neutrales. Se aplican por igual a cualquiera que utilice esa computación.

Pero la computación se correlaciona con los recursos organizacionales. Los actores grandes pueden cumplir más fácilmente los requisitos de supervisión porque ya disponen de infraestructura legal, de cumplimiento y de políticas. Los actores pequeños que cruzan los umbrales enfrentan nuevas exigencias burocráticas para las que pueden no estar estructurados.

### Requisitos de documentación

Los requisitos extensivos de documentación (fichas de modelo, evaluaciones de riesgo, divulgaciones de datos de entrenamiento) requieren tiempo para producirse. Las grandes organizaciones tienen redactores técnicos y equipos de políticas. Las pequeñas tienen ingenieros que preferirían estar construyendo.

Incluso si la documentación mejora la transparencia, la carga recae de forma desigual.

### Requisitos de auditoría

Las [auditorías de terceros](/research/010-self-reporting-vs-audit/) son valiosas pero costosas. Los honorarios de auditoría que representan errores de redondeo para grandes empresas pueden equivaler al presupuesto total de cumplimiento de una empresa pequeña.

Si las auditorías son obligatorias, los actores pequeños pagan proporcionalmente más. Si las auditorías son opcionales pero ventajosas (creando señales de confianza), los actores pequeños están en desventaja.

### Marcos de responsabilidad

Los [marcos de responsabilidad](/research/020-liability-frameworks/) que permiten litigios por daños de IA pueden gravar desproporcionadamente a los actores pequeños. Las grandes empresas pueden permitirse equipos jurídicos y seguros de litigios. Las pequeñas pueden verse abocadas a la quiebra por una sola demanda.

Esto no significa que la responsabilidad sea mala. Significa que el riesgo de responsabilidad se soporta de manera desigual.

### Organismos de normalización

Participar en el desarrollo de estándares lleva tiempo y experiencia. Los organismos de normalización que configuran la gobernanza de IA requieren un compromiso sostenido. Las grandes empresas envían delegados profesionales de estándares. Las pequeñas no pueden prescindir del personal.

Los estándares acaban reflejando los intereses de quienes participan: predominantemente organizaciones grandes.

## Por qué esto importa

El problema de los actores pequeños importa por varias razones.

**Competencia e innovación.** Los actores pequeños suelen ser fuentes de innovación. Las barreras regulatorias que excluyen a los actores pequeños reducen la competencia y pueden ralentizar la innovación beneficiosa.

**Concentración de poder.** Si la regulación favorece a los incumbentes, concentra aún más el poder. Las grandes empresas de IA pueden presionar por regulaciones que ellas pueden cumplir pero sus competidores no. La regulación se convierte en un arma competitiva.

**Legitimidad.** Una gobernanza que consolida las estructuras de poder existentes socava su propia legitimidad. La gobernanza democrática no debería favorecer sistemáticamente a los poderosos.

**La seguridad misma.** Si solo los actores grandes pueden operar, la seguridad depende de si los actores grandes son, de hecho, más seguros. Las grandes organizaciones tienen sus propios modos de fallo: burocracia, incentivos desalineados, adaptación más lenta. Los actores pequeños pueden ser más ágiles al responder a riesgos emergentes.

## El contraargumento

Existe un contraargumento: quizás los actores pequeños deberían verse gravados.

**Los requisitos de recursos son reales.** La seguridad requiere inversión. Si los actores pequeños no pueden invertir adecuadamente, quizás no deberían operar. Los costes de cumplimiento pueden representar costes genuinos de una operación responsable.

**Los actores más grandes tienen más capacidad.** Si los actores grandes pueden causar más daño debido a una mayor capacidad, tiene sentido regular más intensamente en proporción. Los actores pequeños pueden necesitar menos supervisión porque suponen menos riesgo.

**Incentivos de mercado para la escala.** Si el mercado de IA favorece naturalmente la escala (a través de los costes de computación, los requisitos de datos, los efectos de red), la regulación simplemente sigue la estructura del mercado.

Estos argumentos tienen mérito. Pero no eliminan el problema. Sugieren que el equilibrio debe gestionarse, no que los actores pequeños no importen.

## Principios de diseño para una regulación equitativa

La regulación puede diseñarse para reducir la carga desproporcionada sobre los actores pequeños.

### Requisitos escalonados

Los requisitos pueden graduarse según el tamaño de la organización, los ingresos o la capacidad. Los actores pequeños podrían enfrentar requisitos de documentación más ligeros, auditorías menos frecuentes o vías de cumplimiento simplificadas.

El escalonamiento basado en el riesgo es un enfoque común: las aplicaciones de mayor riesgo enfrentan requisitos más estrictos independientemente del tamaño del actor, mientras que las aplicaciones de menor riesgo tienen una carga reducida.

### Puertos seguros

Ciertas prácticas podrían calificar para protección frente a la responsabilidad o la supervisión. Los actores pequeños que siguieran directrices establecidas podrían recibir protección sin la carga total de cumplimiento.

Esto crea vías para una operación responsable sin requerir la infraestructura de las grandes organizaciones.

### Cumplimiento subvencionado

Los gobiernos o las asociaciones industriales podrían subvencionar el cumplimiento para los actores pequeños: proporcionando auditorías gratuitas o a coste reducido, recursos jurídicos compartidos o herramientas de cumplimiento.

El beneficio público requiere inversión pública. Si la sociedad se beneficia de la participación de los actores pequeños, la sociedad debería compartir los costes de cumplimiento.

### Estándares simplificados

Los estándares pueden diseñarse pensando en los actores pequeños. Plantillas predefinidas, listas de verificación automatizadas y procesos simplificados reducen la experiencia especializada requerida.

No todos los requisitos necesitan ser complejos. La sencillez es una opción de diseño.

### Estructuras de participación

Los organismos de normalización y los procesos de gobernanza pueden apoyar activamente la participación de los actores pequeños. Esto podría incluir plazas reservadas, opciones de participación remota o financiación para viajes y tiempo.

Si la mesa está dominada por actores grandes, hay que reestructurar la mesa.

## El riesgo de captura regulatoria

Existe un problema espejo: las regulaciones podrían ser diseñadas por actores grandes específicamente para gravar a los competidores pequeños. Esto es captura regulatoria.

Las grandes empresas de IA participan intensamente en el desarrollo de políticas. Tienen lobistas, equipos de políticas y relaciones con los reguladores. Cuando surgen regulaciones que resultan favorecer a los actores grandes, la coincidencia no es la única explicación.

Detectar la captura es difícil. Las regulaciones pueden servir genuinamente a los objetivos de seguridad y al mismo tiempo servir a los intereses de los incumbentes. El desafío es asegurar que las justificaciones de seguridad sean reales y no pretextuales.

Las salvaguardas incluyen:

- **Aportaciones diversas.** El desarrollo de políticas debería incluir actores pequeños, sociedad civil y grupos de interés público, no solo grandes empresas.
- **Transparencia.** El lobbying y la influencia en políticas deberían ser documentados y públicos.
- **Análisis de impacto.** Las regulaciones propuestas deberían incluir un análisis de los impactos diferenciales por tamaño de organización.
- **Cláusulas de revisión y extinción.** Las regulaciones deberían revisarse en busca de efectos no deseados y corregirse cuando se identifiquen cargas diferenciales.

## Conclusión

El problema de los actores pequeños no tiene una solución limpia. La regulación tiene costes de cumplimiento inevitables. Esos costes gravan inevitablemente más a los actores pequeños. Cierta carga puede ser apropiada si refleja inversiones genuinas en seguridad.

Pero una carga desproporcionada que excluye a los actores pequeños sin beneficio para la seguridad es puro coste. Concentra el poder, reduce la competencia y socava la legitimidad de la gobernanza.

Diseñar la gobernanza de IA teniendo en cuenta el problema de los actores pequeños requiere una atención activa. Requisitos escalonados, puertos seguros, cumplimiento subvencionado y participación inclusiva pueden mitigar el problema sin eliminar las medidas de seguridad necesarias.

La cuestión es si los diseñadores de la gobernanza priorizan esto. Dado que los diseñadores de la gobernanza suelen estar asociados con organizaciones grandes, la respuesta no está garantizada.

## Investigación relacionada

- [Regulatory Arbitrage in AI Deployment](/research/008-regulatory-arbitrage/)
- [Liability Frameworks for AI Harm](/research/020-liability-frameworks/)
- [Self-Reporting vs. External Audit: Trade-offs](/research/010-self-reporting-vs-audit/)
- [The Role of Standards Bodies in AI Governance](/research/039-standards-bodies/)
