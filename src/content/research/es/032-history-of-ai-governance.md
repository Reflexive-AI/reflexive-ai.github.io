---
title: "La historia de la gobernanza de la IA en 2000 palabras"
excerpt: "De las Leyes de Asimov a la Ley de IA de la UE: como el pensamiento sobre la gobernanza de la inteligencia artificial ha evolucionado a lo largo de ocho decadas."
date: 2026-01-14
categories:
  - Public
  - Governance Analysis
tags:
  - governance
  - regulation
  - policy
  - guide
---

## La prehistoria: decadas de 1940 a 1990

La gobernanza de la IA comenzo antes de que la propia IA existiera.

**1942: Las Tres Leyes de Asimov.** El escritor de ciencia ficcion Isaac Asimov introdujo sus famosas Tres Leyes de la Robotica. Aunque ficticias, representaron el primer intento serio de pensar en como las inteligencias artificiales podrian ser restringidas. Tambien ilustraron un problema fundamental: las reglas formales pueden tener consecuencias no deseadas y casos limite que socavan su intencion. Esto presagio los desafios con los que seguimos luchando hoy en [definir el alineamiento](/research/016-what-alignment-means/).

**1956: Nace la IA.** La Conferencia de Dartmouth lanzo la IA como campo de estudio. El optimismo inicial predecia una IA de nivel humano en decadas. La gobernanza parecia prematura: la tecnologia apenas existia.

**Decadas de 1960 a 1980: La era de los sistemas expertos.** La investigacion en IA se centro en codificar la experiencia humana en sistemas basados en reglas. Las discusiones sobre gobernanza fueron limitadas, centrandose principalmente en la responsabilidad por errores de los sistemas expertos en contextos medicos y legales.

**Decadas de 1980 a 1990: El primer invierno de la IA.** Cuando la IA no cumplio las expectativas infladas, la financiacion se seco y el interes decayo. Las discusiones sobre gobernanza desaparecieron junto con la tecnologia.

## La revolucion del aprendizaje: decadas de 2000 a 2010

El resurgimiento de las redes neuronales lo cambio todo.

**2006: Surge el aprendizaje profundo.** Los investigadores descubrieron como entrenar redes neuronales con muchas capas. Este avance eventualmente haria posible la IA moderna, aunque las implicaciones no fueron inmediatamente evidentes.

**2010: Comienza la rendicion de cuentas algoritmica.** Los academicos empezaron a examinar como los sistemas de toma de decisiones automatizados afectaban la vida de las personas: puntuaciones de credito, decisiones de contratacion, elegibilidad para prestaciones sociales. Aun no se llamaba "gobernanza de la IA", pero las preocupaciones eran fundamentales.

**2011: Watson gana Jeopardy!** La victoria de Watson de IBM sobre campeones humanos en el concurso desperto el interes publico en las capacidades de la IA. Las discusiones se mantuvieron enfocadas en la disrupcion economica mas que en la seguridad.

**2012: El avance de ImageNet.** Una red neuronal supero dramaticamente los enfoques tradicionales en reconocimiento de imagenes. Esto marco el comienzo del aprendizaje profundo moderno y los rapidos avances en capacidades que eventualmente requeririan atencion en materia de gobernanza.

**2014: El discurso del riesgo existencial.** "Superintelligence" de Nick Bostrom llevo las preocupaciones sobre la seguridad de la IA a largo plazo a la discusion generalizada. Aunque controvertido, establecio que la gobernanza de la IA necesitaba considerar escenarios transformadores, no solo mejoras incrementales.

## El despertar: 2015-2019

La gobernanza de la IA emergio como un campo diferenciado.

**2015: Carta abierta sobre la seguridad de la IA.** Miles de investigadores firmaron una carta abierta pidiendo que la IA fuera "robusta y beneficiosa". El Future of Life Institute reunio a expertos. La seguridad de la IA paso de ser una preocupacion marginal a una agenda de investigacion legitima.

**2016: La etica de la IA se generaliza.** El IEEE comenzo a desarrollar estandares para el diseno eticamente alineado. Las empresas tecnologicas crearon comites de etica y publicaron principios de IA. La investigacion de ProPublica sobre COMPAS, un algoritmo de prediccion de reincidencia, demostro el sesgo algoritmico en decisiones de alto impacto.

**2017: Los Principios de Asilomar.** Los investigadores se reunieron en Asilomar, sede de la famosa conferencia de biotecnologia de 1975, para desarrollar 23 principios para una IA beneficiosa. Estos cubrian la cultura de investigacion, la etica y la seguridad a largo plazo. El paralelo con la gobernanza de la bioseguridad fue intencional.

**2018: El RGPD incluye disposiciones algoritmicas.** El Reglamento General de Proteccion de Datos de la Union Europea incluyo un "derecho a la explicacion" para las decisiones automatizadas. Aunque limitado y debatido, represento la primera legislacion importante que abordaba explicitamente la toma de decisiones por IA.

**2019: El auge de la etica.** Todas las grandes empresas tecnologicas publicaron principios de etica de la IA. Gobiernos de todo el mundo lanzaron estrategias de IA. La UE establecio su Grupo de Expertos de Alto Nivel sobre IA, que produjo directrices eticas y recomendaciones politicas. Pekin publico principios de gobernanza de la IA.

Este periodo establecio conceptos clave: equidad, rendicion de cuentas, transparencia y explicabilidad (a menudo abreviados como FATE por sus siglas en ingles). Pero los criticos senalaron que las directrices eticas eran a menudo vagas, voluntarias y servian mas como relaciones publicas que como restricciones genuinas.

## El giro regulatorio: 2020-2023

La pandemia de COVID-19 y los avances en capacidades transformaron la gobernanza de la IA.

**2020: La pandemia acelera la adopcion.** Los sistemas de IA se desplegaron rapidamente para el diagnostico medico, el desarrollo de vacunas y el rastreo de contactos. Esta aceleracion a menudo supero la capacidad de gobernanza, planteando preguntas sobre [la proporcionalidad en la divulgacion](/research/001-proportionality-disclosure/) y la supervision.

**2021: Se propone la Ley de IA de la UE.** La Comision Europea propuso la primera regulacion integral de IA del mundo. Su enfoque basado en riesgos, que prohibia algunas aplicaciones, regulaba fuertemente otras y dejaba muchas sin regular, se convirtio en una plantilla para el pensamiento sobre gobernanza a nivel global.

**2022: Emergen los grandes modelos de lenguaje.** El lanzamiento publico de ChatGPT en noviembre de 2022 llevo las capacidades de la IA a la experiencia publica directa por primera vez. De repente, millones de personas interactuaban con sistemas capaces de escribir, razonar y asistir con tareas complejas. La gobernanza que habia parecido abstracta se volvio urgente.

**2023: La crisis de capacidades.** Los rapidos avances provocaron respuestas urgentes de gobernanza:

- Cartas abiertas pidiendo pausas en el desarrollo de la IA
- Audiencias en el Congreso con ejecutivos de empresas de IA
- La Cumbre de Seguridad de la IA del Reino Unido en Bletchley Park
- Compromisos voluntarios de las principales empresas de IA
- Ordenes ejecutivas sobre seguridad de la IA de la Casa Blanca

Este periodo vio la emergencia de "IA de frontera" como categoria de gobernanza: sistemas cuyas capacidades demandaban atencion especial. Hemos explorado como estos sistemas crean [desafios regulatorios](/research/018-regulation-is-hard/) y [problemas de excedente de capacidades](/research/009-capability-overhang/).

## El desafio de la implementacion: 2024-presente

Nos encontramos ahora en un periodo de desarrollo institucional.

**2024: Se aprueba la Ley de IA de la UE.** La primera legislacion integral de IA del mundo se convirtio en ley. Su implementacion llevaria anos, pero la plantilla existia. Otras jurisdicciones empezaron a adaptar o responder al enfoque de la UE.

**Proliferan los Institutos de Seguridad de la IA.** El Reino Unido, Estados Unidos, Japon, Singapur y otros establecieron institutos nacionales de seguridad de la IA. Estos organismos pretenden construir capacidad tecnica dentro del gobierno, un reconocimiento de que [la capacidad de auditoria externa](/research/010-self-reporting-vs-audit/) es esencial para una supervision eficaz.

**Se profundizan los compromisos voluntarios.** Los principales laboratorios de IA asumieron compromisos en materia de pruebas de capacidades peligrosas, notificacion de incidentes y practicas de seguridad. La cuestion de si estos compromisos son significativos sin mecanismos de aplicacion sigue abierta, como discutimos en nuestro analisis de [las limitaciones de la autonotificacion](/research/010-self-reporting-vs-audit/).

**Intentos de coordinacion internacional.** La ONU convoco discusiones sobre la gobernanza internacional de la IA. Se exploraron acuerdos bilaterales entre las principales potencias en IA. Sin embargo, el progreso sigue siendo limitado, reflejando los desafios fundamentales de gobernar una tecnologia donde la ventaja competitiva y los intereses de seguridad nacional son significativos.

**2025-2026: Desafios actuales.** En el momento de escribir esto, nos enfrentamos a:

- La implementacion de la Ley de IA de la UE y regulaciones similares
- El debate sobre la gobernanza del computo y [sus limitaciones](/research/023-compute-governance/)
- Cuestiones sobre [la proteccion de denunciantes](/research/022-whistleblower-protections/) en los laboratorios de IA
- Avances continuos en capacidades que superan a la gobernanza
- [Marcos de responsabilidad](/research/020-liability-frameworks/) aun en desarrollo

## Lecciones de la historia

Ocho decadas de reflexion sobre la gobernanza de la IA arrojan varias lecciones.

### Tecnologia y gobernanza coevolucionan

Las discusiones sobre gobernanza estan moldeadas por la tecnologia, pero tambien moldean el desarrollo tecnologico. Los conceptos desarrollados en el discurso de la IA etica (equidad, transparencia, rendicion de cuentas) han influido en como se construyen los sistemas, no solo en como se regulan.

### Las ventanas se abren y se cierran

Los periodos de crisis y atencion crean oportunidades para la innovacion en gobernanza. El momento actual es una de esas ventanas. Queda por ver si producira instituciones duraderas.

### Los principios son insuficientes

Todas las grandes empresas tecnologicas tienen principios de etica de la IA. Muchas los violan regularmente. Los principios importan, pero los mecanismos de aplicacion, las estructuras de rendicion de cuentas y las restricciones genuinas son lo que hace real la gobernanza. Por eso nos centramos en [restricciones legibles por maquina](/research/003-machine-readable-constraint-schema/) y [rendicion de cuentas operativa](/research/006-meta-governance-auditors/).

### Las soluciones tecnicas y sociales deben combinarse

La gobernanza de la IA no puede ser puramente tecnica (construir sistemas mas seguros) ni puramente social (regular el comportamiento). Requiere ambas, integradas cuidadosamente. Esta es la idea central de la gobernanza reflexiva: la idea de que los sistemas pueden participar en su propia supervision, como se explora en nuestro [manifiesto](/research/030-manifesto/).

### La concentracion crea tanto riesgo como oportunidad

Que el desarrollo de IA de frontera este concentrado en unos pocos actores es preocupante para la distribucion del poder pero potencialmente util para la gobernanza. Menos actores pueden significar una coordinacion mas manejable.

## Que viene despues

Estamos en los primeros capitulos de la gobernanza de la IA, no en los ultimos.

Las proximas decadas probablemente veran:

- Marcos internacionales comparables a los de la tecnologia nuclear o el clima
- Profesionalizacion de los roles de gobernanza de la IA
- Estandares tecnicos que se vuelven tan importantes como las regulaciones legales
- Tension continua entre innovacion y precaucion

Lo que hagamos ahora, en esta ventana de atencion y posibilidad, moldeara la gobernanza de la IA durante decadas. La Reflexive AI Initiative es una contribucion a ese trabajo. Te invitamos a [unirte a nosotros](/contribute/).

## Lecturas adicionales

- [Gobernanza de la IA para no expertos: una guia](/research/017-governance-primer/)
- [Por que "simplemente regular la IA" es mas dificil de lo que parece](/research/018-regulation-is-hard/)
- [La Ley de IA de la UE: lo que no contempla](/research/019-eu-ai-act-gaps/)
- [Derecho blando frente a derecho duro en la regulacion de la IA](/research/040-soft-law-hard-law/) (proximo)
