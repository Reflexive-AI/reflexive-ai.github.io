---
title: "El papel de la sociedad civil en la gobernanza de la IA"
excerpt: "Más allá de las empresas y los reguladores: cómo las organizaciones de la sociedad civil contribuyen a la gobernanza de la IA y cómo podría reforzarse su papel."
date: 2026-01-26
categories:
  - Public
tags:
  - governance
  - transparency
  - policy
  - ethics
---

## El tercer pilar

Las discusiones sobre gobernanza de la IA suelen centrarse en dos actores: las empresas que desarrollan IA y los gobiernos que la regulan. Pero un tercer actor desempeña un papel esencial: la sociedad civil.

La sociedad civil incluye organizaciones no gubernamentales, grupos de defensa de derechos, instituciones académicas, asociaciones profesionales, periodistas y movimientos ciudadanos organizados. Estos actores no desarrollan IA ni redactan leyes, pero configuran el entorno en el que ambas cosas suceden.

Este análisis examina cómo la sociedad civil contribuye a la gobernanza de la IA, qué facilita o limita estas contribuciones, y cómo podría reforzarse su papel.

## Qué hace la sociedad civil

La sociedad civil contribuye a la gobernanza de la IA a través de múltiples canales.

### Investigación y análisis

Las instituciones académicas y los centros de investigación producen análisis sobre las capacidades, riesgos y gobernanza de la IA:

- Investigación técnica sobre seguridad de la IA
- Análisis de políticas y propuestas
- Estudios empíricos sobre los impactos de la IA
- Investigación comparada en gobernanza

Esta investigación informa tanto la práctica empresarial como la política gubernamental. Gran parte de lo que los reguladores saben sobre IA proviene de la investigación de la sociedad civil.

### Defensa y presión

Las organizaciones de defensa presionan en favor de una gobernanza más fuerte:

- Campañas por regulaciones específicas
- Presión pública sobre las empresas
- Interacción con los medios para sensibilizar
- Litigios para hacer valer los derechos

Esta presión puede cambiar lo que las empresas y los gobiernos consideran políticamente viable o necesario.

### Funciones de vigilancia

La sociedad civil supervisa el desarrollo y despliegue de la IA:

- Auditoría de los sistemas de IA para detectar sesgos y daños
- Investigación de las prácticas empresariales
- Documentación de fallos y daños de la IA
- Seguimiento del cumplimiento normativo

Esta supervisión complementa la capacidad gubernamental limitada. Como discutimos en [quién vigila a los vigilantes](/research/006-meta-governance-auditors/), la supervisión independiente es esencial.

### Desarrollo de normas

La sociedad civil participa en el desarrollo de normas:

- Expertos académicos en comités de normalización
- Asociaciones profesionales que establecen directrices
- Iniciativas multiactor que desarrollan orientaciones

Los organismos de normalización, como examinamos en [su papel en la gobernanza](/research/039-standards-bodies/), suelen incluir participación de la sociedad civil.

### Desarrollo de capacidades

La sociedad civil desarrolla capacidades de gobernanza:

- Formación de responsables políticos sobre IA
- Educación de periodistas sobre temas técnicos
- Educación pública en alfabetización en IA
- Desarrollo de marcos de evaluación

Este desarrollo de capacidades permite una gobernanza más informada por parte de otros actores.

### Voz de las comunidades afectadas

La sociedad civil representa a quienes se ven afectados por la IA y pueden carecer de otra voz:

- Comunidades marginadas afectadas de forma desproporcionada por la IA
- Generaciones futuras afectadas por el desarrollo de la IA a largo plazo
- Público en general afectado por sistemas basados en IA

Esta representación contrarresta la influencia de la industria en los procesos de gobernanza.

## Ejemplos de impacto

La sociedad civil ha influido de manera demostrable en la gobernanza de la IA.

### Rendición de cuentas algorítmica

La investigación de ProPublica sobre COMPAS —un algoritmo de predicción de reincidencia— en 2016 introdujo el sesgo algorítmico en el debate público. Este ejercicio periodístico impulsó investigación académica, campañas de defensa y, finalmente, atención regulatoria. Las disposiciones de la Ley de IA de la UE sobre IA de alto riesgo en la justicia penal se remontan a las preocupaciones planteadas por la sociedad civil.

### Reconocimiento facial

Las campañas de la sociedad civil contra el reconocimiento facial —que incluyen investigación documentando sesgos, defensa de prohibiciones y organización ciudadana— han logrado restricciones significativas en múltiples jurisdicciones. Varias ciudades han prohibido el reconocimiento facial gubernamental. Empresas han pausado o limitado los productos de reconocimiento facial.

### Atención a la seguridad de la IA

La comunidad de investigación en seguridad de la IA —en gran parte académica y sin ánimo de lucro— ha llevado la seguridad de una preocupación marginal a una cuestión central de gobernanza. La investigación de instituciones como MIRI, FHI, CAIS y ahora Anthropic ha configurado cómo los responsables políticos y el público entienden el riesgo de la IA.

### Derechos de los trabajadores

Los sindicatos y los grupos de defensa de los trabajadores han presionado para que la voz de los trabajadores esté presente en el despliegue de la IA, especialmente en los sistemas de IA que afectan a las condiciones laborales, la contratación y la vigilancia. Esta defensa ha influido tanto en la legislación como en la práctica empresarial.

## Limitaciones de la sociedad civil

A pesar de estas contribuciones, la sociedad civil enfrenta limitaciones significativas.

### Asimetría de recursos

Las grandes empresas de IA disponen de muchos más recursos que las organizaciones de la sociedad civil. Las empresas pueden desplegar decenas de lobistas; los grupos de defensa pueden tener un puñado de empleados cubriendo todas las cuestiones tecnológicas. Esta asimetría afecta a la capacidad de investigación, defensa y participación.

### Experiencia técnica

La IA es técnicamente compleja. Las organizaciones de la sociedad civil pueden carecer de experiencia técnica para analizar eficazmente los sistemas de IA, participar en propuestas técnicas o intervenir en el desarrollo de normas. Esto está mejorando a medida que se desarrollan organizaciones de la sociedad civil especializadas en IA, pero persisten las brechas.

### Acceso a los sistemas

La sociedad civil no puede auditar lo que no puede acceder. La mayoría de los sistemas de IA son propietarios, con acceso externo limitado. Esto limita la evaluación independiente. Exploramos desafíos relacionados en [autonotificación frente a auditoría](/research/010-self-reporting-vs-audit/).

### Captura política

Algunas organizaciones de la sociedad civil son financiadas por empresas de IA, lo que crea un riesgo de captura. La investigación financiada por la industria puede estar sesgada hacia conclusiones favorables a la industria. La transparencia sobre la financiación ayuda, pero no elimina esta preocupación.

### Desafíos de coordinación

La sociedad civil está fragmentada: miles de organizaciones con distintas prioridades, enfoques e ideologías. La coordinación es difícil, lo que limita el impacto colectivo.

### Desfase temporal

El desarrollo de la IA avanza más rápido que la organización de la sociedad civil. Para cuando las campañas de defensa se desarrollan, los sistemas pueden estar ampliamente desplegados. La sociedad civil suele reaccionar en lugar de anticiparse.

## Reforzar el papel de la sociedad civil

Varios enfoques podrían reforzar la contribución de la sociedad civil a la gobernanza de la IA.

### Derechos de acceso

Los requisitos legales de acceso de los investigadores a los sistemas de IA —como los propuestos en la Ley de Servicios Digitales de la UE para las plataformas— podrían permitir la evaluación independiente. Del mismo modo, las protecciones para denunciantes (como examinamos en [nuestro análisis](/research/022-whistleblower-protections/)) ayudan a que la información fluya hacia la sociedad civil.

### Independencia de la financiación

Financiar a la sociedad civil a través de fuentes públicas, fundaciones filantrópicas sin vínculos con la industria o fondos de gobernanza específicos podría garantizar la independencia. La transparencia sobre las fuentes de financiación permite a las partes interesadas evaluar los posibles sesgos.

### Desarrollo de capacidades

La inversión en capacidades de la sociedad civil —formación técnica, programas de becas, desarrollo organizativo— podría abordar las brechas de experiencia. Esto podría provenir de fundaciones, gobiernos o asociaciones académicas.

### Inclusión formal

La inclusión formal de la sociedad civil en los procesos de gobernanza —órganos consultivos, desarrollo de normas, consultas regulatorias— garantiza una voz más allá del lobbismo. Esto requiere que la participación sea viable para organizaciones con recursos limitados.

### Derechos de información

Los requisitos legales de divulgación —de los sistemas de IA, de las prácticas de gobernanza, de los incidentes— crean información que la sociedad civil puede utilizar para la supervisión y la defensa de derechos.

### Construcción de coaliciones

Las organizaciones de la sociedad civil pueden amplificar su impacto mediante la construcción de coaliciones: coordinándose entre organizaciones, sectores y países. Las redes internacionales son particularmente importantes dada la naturaleza global de la IA.

## La dimensión reflexiva

Nuestro trabajo sobre gobernanza reflexiva sugiere funciones adicionales para la sociedad civil.

**Interpretar la autonotificación de la IA.** Si los sistemas de IA informan cada vez más de [sus restricciones](/research/014-ai-regulator-protocol/) y [explican sus limitaciones](/research/026-explaining-constraints/), la sociedad civil puede interpretar estos informes para la comprensión pública.

**Supervisar los mecanismos reflexivos.** La sociedad civil puede supervisar si los mecanismos de gobernanza reflexiva funcionan realmente: ¿son precisos los autoinformes de los sistemas de IA? ¿Funcionan las restricciones según lo declarado?

**Defender los enfoques reflexivos.** La sociedad civil puede presionar para que los sistemas de IA sean más transparentes sobre su funcionamiento, avanzando nuestro objetivo de una IA que participe en su propia gobernanza.

**Representar en los procesos reflexivos.** A medida que los sistemas de IA se vuelven más sofisticados, los procesos de gobernanza pueden necesitar incluir a la propia IA. La sociedad civil puede asegurar que los intereses humanos sigan siendo centrales en estos procesos.

## Cómo es una sociedad civil fuerte

Una contribución eficaz de la sociedad civil a la gobernanza de la IA incluiría:

**Instituciones de investigación independientes** que produzcan análisis rigurosos e imparciales sobre las capacidades, riesgos y opciones de gobernanza de la IA.

**Organizaciones de defensa bien dotadas** capaces de sostener campañas, abordar detalles técnicos y coordinarse entre temas y jurisdicciones.

**Periodistas de investigación** con capacidad técnica para indagar en el desarrollo y despliegue de la IA, y respaldo editorial para investigaciones a largo plazo.

**Organizaciones comunitarias** que representen a los más afectados por la IA, con capacidad para participar en los procesos de gobernanza.

**Asociaciones profesionales** que establezcan y hagan cumplir normas para el desarrollo de la IA, con credibilidad y capacidad de aplicación.

**Financiación diversa** procedente de fuentes que no generen captura por parte de la industria, permitiendo independencia y planificación a largo plazo.

**Mecanismos de coordinación eficaces** que permitan la acción colectiva respetando la diversidad organizativa.

## Conclusión

La sociedad civil es esencial para una gobernanza eficaz de la IA. Produce investigación, defiende la protección, supervisa el cumplimiento, representa a las comunidades afectadas y desarrolla capacidades de gobernanza. Sin la sociedad civil, la gobernanza estaría capturada por los intereses de la industria y limitada por la capacidad gubernamental.

Reforzar el papel de la sociedad civil requiere abordar sus limitaciones: asimetría de recursos, restricciones de acceso, brechas de experiencia y desafíos de coordinación. Invertir en la capacidad de la sociedad civil es invertir en la gobernanza de la IA.

La Reflexive AI Initiative aspira a contribuir a este ecosistema: produciendo investigación, proponiendo marcos de gobernanza y defendiendo una IA que participe de manera responsable en su propia gobernanza. Damos la bienvenida a la [colaboración](/contribute/) con otros que trabajan hacia estos objetivos.

## Lecturas complementarias

- [¿Quién vigila a los vigilantes? Auditar a los auditores de IA](/research/006-meta-governance-auditors/)
- [Protecciones para denunciantes en los laboratorios de IA](/research/022-whistleblower-protections/)
- [El papel de los organismos de normalización en la gobernanza de la IA](/research/039-standards-bodies/)
- [Autonotificación frente a auditoría externa: compensaciones](/research/010-self-reporting-vs-audit/)
