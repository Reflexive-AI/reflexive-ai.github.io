---
title: "Propuestas de tratados internacionales sobre IA: un análisis comparativo"
excerpt: "Desde la Declaración de Bletchley hasta las propuestas de tratados sobre IA: análisis de qué acuerdos internacionales sobre gobernanza de la IA se han propuesto, qué lograrían y cuáles son sus perspectivas."
date: 2026-01-20
categories:
  - Governance Analysis
  - Public
tags:
  - regulation
  - governance
  - policy
  - jurisdiction
---

## Los argumentos a favor de la gobernanza internacional de la IA

El desarrollo de la IA es global; una gobernanza eficaz posiblemente también deba serlo. Varias características de la IA sugieren que la gobernanza puramente nacional es insuficiente:

**Efectos transfronterizos.** Los sistemas de IA desarrollados en un país afectan a personas en todo el mundo. Un sistema de IA entrenado en California podría tomar decisiones sobre usuarios en Alemania, generar contenido consumido en Brasil y ejecutarse en servidores en Singapur.

**Dinámicas competitivas.** La regulación nacional genera presiones competitivas. Los países temen que normas internas estrictas lleven el desarrollo de IA a otros lugares. Esto puede crear carreras a la baja a menos que la coordinación internacional establezca estándares comunes.

**Riesgos compartidos.** Algunos riesgos de la IA —desalineación catastrófica, asistencia para armas biológicas, desinformación masiva— trascienden las fronteras nacionales. Ningún país por sí solo puede gestionar riesgos que podrían afectar a la humanidad colectivamente.

**Concentración.** El desarrollo de IA de frontera se concentra en un número reducido de países, principalmente Estados Unidos y China, con actividad significativa en el Reino Unido, Francia y otros. Los acuerdos entre pocos actores son más viables que entre muchos.

Este análisis examina qué acuerdos internacionales sobre IA se han propuesto o alcanzado, qué lograrían las diferentes propuestas y qué obstáculos enfrentan.

## Acuerdos internacionales actuales

Ya existen varios acuerdos internacionales de gobernanza de la IA, aunque ninguno constituye una gobernanza integral basada en tratados.

### Declaración de Bletchley (2023)

La Cumbre de Seguridad de la IA en Bletchley Park produjo una declaración firmada por 28 países, incluidos EE. UU. y China. Elementos clave:

- Reconocimiento de que la IA de frontera presenta riesgos de seguridad
- Reconocimiento de que los riesgos son de alcance internacional
- Compromiso de cooperación en seguridad de la IA
- Establecimiento de un diálogo internacional continuo

**Importancia:** La declaración estableció que la seguridad de la IA es un tema legítimo para la implicación internacional y logró una participación sorprendentemente amplia. Sin embargo, no es vinculante y no contiene compromisos específicos ni mecanismos de aplicación.

### Proceso de IA de Hiroshima del G7

El G7 desarrolló principios de gobernanza de IA y un código de conducta para desarrolladores de IA. Características clave:

- Compromisos voluntarios para desarrolladores avanzados de IA
- Enfoque en modelos fundacionales e IA generativa
- Principios que cubren seguridad, transparencia y desarrollo responsable

**Limitaciones:** Se aplica solo a los países del G7 y es voluntario. No aborda el desarrollo de IA fuera del G7, notablemente China.

### Principios de IA de la OCDE

La OCDE adoptó principios de IA en 2019, respaldados por más de 40 países:

- Valores centrados en el ser humano y equidad
- Transparencia y explicabilidad
- Robustez, seguridad y protección
- Rendición de cuentas

**Importancia:** Amplio respaldo internacional de principios. Sin embargo, los principios son de alto nivel y la implementación es nacional, creando una variación significativa en la práctica.

### Convenio del Consejo de Europa sobre IA

El Consejo de Europa desarrolló un convenio vinculante sobre IA y derechos humanos:

- Se aplica a los sistemas de IA en el sector público
- Requiere evaluaciones de impacto en derechos humanos
- Establece requisitos de rendición de cuentas
- Abierto a la firma de miembros no pertenecientes al Consejo de Europa

**Importancia:** El primer tratado internacional vinculante sobre IA. Sin embargo, el alcance se limita a las aplicaciones de derechos humanos y la aplicación depende de la implementación nacional.

### Acuerdos bilaterales

Diversas discusiones y acuerdos bilaterales abordan la IA:

- Discusiones del Consejo de Comercio y Tecnología UE-EE. UU. sobre estándares de IA
- Cooperación EE. UU.-Reino Unido en seguridad de la IA
- Diálogo limitado EE. UU.-China sobre riesgos de la IA

Estos acuerdos son importantes pero fragmentados y a menudo informales.

## Modelos de tratados propuestos

Se han propuesto varios modelos para acuerdos internacionales de IA más integrales.

### Analogía nuclear: un OIEA para la IA

Inspirándose en la gobernanza nuclear, algunos proponen una Agencia Internacional de IA inspirada en el OIEA:

- Verificación de las actividades de desarrollo de IA
- Estándares de seguridad e inspecciones
- Asistencia técnica para el desarrollo seguro de IA
- Intercambio de información sobre riesgos y capacidades

**Ventajas:** Modelo probado para gobernar tecnología peligrosa. Aborda los desafíos de verificación.

**Desafíos:** La IA difiere de la tecnología nuclear: es distribuida, de doble uso por defecto y desarrollada principalmente por actores privados. Los regímenes de inspección que funcionan para instalaciones nucleares se trasladan mal a los laboratorios de IA. Exploramos desafíos relacionados en [gobernanza del computo](/research/023-compute-governance/).

### Modelo de control de armamentos

Algunos proponen acuerdos de IA basados en tratados de control de armamentos:

- Límites al desarrollo de capacidades específicas de IA
- Medidas de transparencia y verificación
- Mecanismos de generación de confianza
- Canales de comunicación en crisis

**Ventajas:** Aborda las dinámicas competitivas entre grandes potencias. Plantilla probada para gestionar tecnologías peligrosas.

**Desafíos:** Las «capacidades» de la IA son más difíciles de definir y verificar que los sistemas de armas. La naturaleza de doble uso dificulta trazar líneas entre la IA civil y militar. A diferencia de las armas nucleares, el desarrollo de IA no requiere infraestructura física observable.

### Modelo de bioseguridad

La Convención sobre Armas Biológicas (CAB) ofrece otra analogía:

- Prohibición de aplicaciones específicas
- Medidas de fomento de la confianza
- Procesos de revisión por expertos
- Desarrollo de normas

**Ventajas:** Aborda la tecnología de doble uso con aplicaciones civiles y militares.

**Desafíos:** La debilidad de la CAB —la falta de verificación— probablemente se aplicaría a los acuerdos sobre IA. Como discutimos en [IA de doble uso en biología](/research/035-dual-use-biology/), la IA complica la bioseguridad en lugar de facilitarla.

### Modelo climático

La gobernanza climática ofrece perspectivas diferentes:

- Convenio marco que establece principios
- Conferencia de las partes para la negociación continua
- Contribuciones determinadas a nivel nacional
- Mecanismos de transparencia y revisión
- Mecanismos financieros para países en desarrollo

**Ventajas:** Acomoda diferentes circunstancias nacionales. Crea una implicación continua. Combina derecho duro y blando.

**Desafíos:** La gobernanza climática ha logrado reducciones limitadas de emisiones. La IA cambia más rápido de lo que los plazos de negociación climática permiten.

### Modelo de gobernanza de Internet

La gobernanza multisectorial de Internet ofrece otra plantilla:

- Participación de gobiernos, empresas, sociedad civil y comunidad técnica
- Estándares técnicos desarrollados por organismos expertos
- Normas desarrolladas a través de múltiples foros
- Estructura formal de tratados limitada

**Ventajas:** Flexibilidad y adaptabilidad. Incluye actores no estatales centrales en el desarrollo de IA.

**Desafíos:** La gobernanza de Internet tiene vacíos y conflictos significativos. Los enfoques multisectoriales pueden oscurecer la rendición de cuentas.

## Qué podrían cubrir los acuerdos

Diferentes aspectos de la gobernanza de la IA podrían beneficiarse de la coordinación internacional.

### Estándares de seguridad

Los estándares internacionales para las pruebas de seguridad, la evaluación y el despliegue de IA podrían reducir la fragmentación y las carreras a la baja. Esto conecta con nuestro análisis de las [evaluaciones de capacidades](/research/024-capability-evaluations/).

### Notificación de incidentes

Los mecanismos internacionales para la notificación y el intercambio de información sobre incidentes de IA podrían mejorar el aprendizaje colectivo. La OACI de la aviación ofrece un modelo, como discutimos en [lecciones de la notificación de incidentes en aviación](/research/021-aviation-lessons/).

### Aplicaciones prohibidas

El acuerdo sobre aplicaciones de IA que deberían estar universalmente prohibidas —quizá el desarrollo de armas NBQR, la vigilancia masiva o las armas autónomas— podría establecer normas globales. Nuestra [taxonomía de líneas rojas](/research/004-red-lines-taxonomy/) identifica candidatos.

### Transparencia

Los acuerdos sobre lo que los desarrolladores de IA deberían divulgar podrían abordar el [arbitraje regulatorio](/research/008-regulatory-arbitrage/) y apoyar una supervisión global consistente.

### Gobernanza del computo

Dado el papel del computo en el desarrollo de IA de frontera, la coordinación internacional sobre el acceso y el seguimiento del computo podría apoyar los objetivos de gobernanza. Véase nuestro [análisis de la gobernanza del computo](/research/023-compute-governance/).

### Cooperación en investigación

Los acuerdos podrían facilitar la cooperación internacional en investigación sobre seguridad de la IA, compartiendo conocimiento que beneficia la seguridad global en lugar de la nacional.

## Obstáculos para el acuerdo

Obstáculos significativos impiden la gobernanza internacional de la IA.

### Competencia entre grandes potencias

La relación EE. UU.-China actualmente prioriza la competencia sobre la cooperación. Ninguno de los dos países es probable que acepte acuerdos que restrinjan su desarrollo de IA mientras los competidores se benefician.

### Desafíos de verificación

A diferencia de las armas nucleares o los agentes químicos, las capacidades de IA son difíciles de observar y verificar. El software puede copiarse y ocultarse. Los entrenamientos ocurren en infraestructura distribuida. Las inspecciones tendrían dificultades para confirmar el cumplimiento.

### Dificultades de definición

¿Qué es «IA» a efectos de un tratado? ¿Qué capacidades merecen preocupación internacional? Trazar líneas que sean lo suficientemente específicas para ser significativas pero lo suficientemente flexibles para seguir siendo relevantes es extraordinariamente difícil.

### Papel del sector privado

A diferencia de la tecnología nuclear o militar, el desarrollo de IA está impulsado principalmente por empresas privadas. Los acuerdos internacionales entre estados no vinculan directamente a los actores corporativos.

### Velocidad de cambio

Las capacidades de la IA cambian más rápido que los procesos de negociación internacional. Un tratado negociado durante años podría ser obsoleto antes de su ratificación.

### Desalineación de incentivos

Los países que lideran en desarrollo de IA se benefician del statu quo y pueden resistirse a las restricciones. Los países rezagados pueden ver las restricciones como una consolidación de la desventaja.

## Perspectivas realistas a corto plazo

Dados estos obstáculos, ¿qué gobernanza internacional de IA podría emerger realmente?

### Desarrollo continuado de derecho blando

Los principios, directrices y compromisos voluntarios probablemente seguirán en expansión. Son más fáciles de lograr que los tratados vinculantes pero tienen una aplicación limitada.

### Acuerdos bilaterales y minilaterales

Los acuerdos a menor escala entre países afines son más factibles que los tratados globales. EE. UU., el Reino Unido y la UE podrían lograr una coordinación significativa incluso si China no participa.

### Coordinación de estándares técnicos

Los organismos internacionales de normalización (ISO, IEEE) pueden desarrollar estándares de IA que logren una aplicación internacional de facto a través de la adopción por el mercado, en lugar de por obligación de tratado.

### Acuerdos sobre temas específicos

Podrían alcanzarse acuerdos limitados sobre temas específicos —quizá armas autónomas, aplicaciones de armas biológicas o seguimiento del computo— incluso si la gobernanza integral no es posible.

### Progreso impulsado por crisis

Los incidentes graves relacionados con la IA podrían crear ventanas políticas para avances en gobernanza que actualmente no son posibles. Esto es desafortunado pero históricamente común en la gobernanza tecnológica.

## Conclusión

La gobernanza internacional de la IA es necesaria y extraordinariamente difícil a la vez. Los acuerdos actuales son fragmentados y en gran medida no vinculantes. La gobernanza integral basada en tratados enfrenta obstáculos significativos.

El camino realista hacia adelante probablemente implica:

- Desarrollo continuado de principios y normas
- Acuerdos bilaterales y minilaterales entre partes dispuestas
- Estándares técnicos con alcance internacional de facto
- Acuerdos sobre temas específicos donde exista alineación
- Construcción de capacidad institucional para una gobernanza futura más sólida

El objetivo debería ser establecer los cimientos para una gobernanza internacional más robusta cuando las condiciones políticas lo permitan, reconociendo que esas condiciones pueden requerir un trabajo diplomático constante o la urgencia impulsada por una crisis para materializarse.

## Lecturas complementarias

- [Why "Just Regulate AI" Is Harder Than It Sounds](/research/018-regulation-is-hard/)
- [Regulatory Arbitrage in AI Deployment](/research/008-regulatory-arbitrage/)
- [Compute Governance: Promises and Limits](/research/023-compute-governance/)
- [Incident Reporting Systems: Lessons from Aviation](/research/021-aviation-lessons/)
