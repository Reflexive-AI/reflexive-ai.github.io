---
title: "Lo que los responsables políticos entienden mal sobre el riesgo de la IA"
excerpt: "Concepciones erróneas comunes que conducen a políticas de IA ineficaces, y cómo pensar con mayor claridad sobre los riesgos reales que plantean los sistemas avanzados de IA."
date: 2026-01-15
categories:
  - Public
  - Policy Proposal
tags:
  - policy
  - risk-assessment
  - governance
  - regulation
---

## El problema con el discurso sobre el riesgo de la IA

Los responsables políticos enfrentan una tarea ingrata. Deben gobernar una tecnología que no crearon, que a menudo no comprenden completamente, y que cambia más rápido de lo que los procesos legislativos pueden acomodar. Bajo estas condiciones, las concepciones erróneas son inevitables.

Pero las concepciones erróneas conducen a políticas ineficaces. Los recursos se dirigen a los problemas equivocados. Los riesgos reales quedan sin abordar mientras los imaginarios consumen la atención. Este análisis identifica los errores más comunes y consecuentes en cómo los responsables políticos piensan sobre el riesgo de la IA, y sugiere correcciones.

Esto se basa en nuestro examen de [por qué la regulación de la IA es difícil](/research/018-regulation-is-hard/) y ofrece orientación concreta para un pensamiento político más eficaz.

## Concepción errónea 1: El riesgo de la IA es principalmente la pérdida de empleo

**El error.** Muchos responsables políticos enmarcan la IA principalmente como un problema de disrupción económica. Las audiencias se centran en los impactos sobre el empleo. Las políticas enfatizan programas de reconversión y redes de seguridad social.

**Por qué es incorrecto.** Aunque la disrupción económica es real y merece atención, enmarcar el riesgo de la IA principalmente a través de esta óptica deja fuera los desafíos de gobernanza más urgentes:

- Sistemas de IA tomando decisiones trascendentales sobre la vida de las personas
- Potencial de la IA para facilitar acciones dañinas a gran escala
- Erosión de la infraestructura epistémica a través de contenido generado por IA
- Concentración de poder en las organizaciones que controlan las capacidades de la IA

El desplazamiento laboral es un problema político, pero es uno conocido con herramientas de respuesta establecidas. Los desafíos novedosos de la IA requieren respuestas novedosas.

**Mejor enfoque.** La IA presenta múltiples categorías de riesgo que requieren diferentes respuestas políticas. La disrupción económica es una. Los riesgos para la seguridad, las implicaciones para los derechos y la concentración de poder son otras. Las políticas deben abordar todas ellas, no solo la más familiar políticamente.

## Concepción errónea 2: Necesitamos que los expertos en IA nos digan qué hacer

**El error.** Los responsables políticos a menudo delegan completamente en los expertos técnicos, tratando la gobernanza de la IA como una cuestión principalmente técnica que deben responder quienes construyen la tecnología.

**Por qué es incorrecto.** La experiencia técnica es necesaria pero insuficiente para la gobernanza. Las preguntas centrales no son técnicas:

- ¿Cuánto riesgo es aceptable a cambio de qué beneficios?
- ¿Quién debe asumir los costes del desarrollo de la IA?
- ¿Qué usos de la IA son compatibles con los derechos humanos y la dignidad?
- ¿Cómo debe distribuirse el poder sobre la IA?

Estas son preguntas políticas, éticas y sociales. Los expertos técnicos pueden informarlas pero no pueden responderlas. Como exploramos en [el problema de la IA honesta](/research/029-honest-ai/), incluso las cuestiones que parecen técnicas a menudo incorporan juicios de valor profundos.

**Mejor enfoque.** Utilizar la experiencia técnica para comprender las capacidades y las limitaciones. Utilizar los procesos democráticos para realizar juicios de valor. No confundir ambas cosas.

## Concepción errónea 3: La elección es innovación o seguridad

**El error.** Los debates sobre la gobernanza de la IA a menudo asumen un compromiso entre innovación (regulación mínima, desarrollo más rápido) y seguridad (más regulación, desarrollo más lento). Los responsables políticos se sienten obligados a elegir entre competitividad económica y protección.

**Por qué es incorrecto.** Este enfoque es a menudo erróneo y siempre incompleto.

Primero, algunas medidas de seguridad tienen un impacto mínimo en la velocidad de innovación. Los requisitos de transparencia, la notificación de incidentes y ciertos protocolos de prueba imponen costes modestos mientras mejoran significativamente la supervisión.

Segundo, una IA insegura crea su propio freno a la innovación. Si los sistemas de IA causan daños significativos, la reacción será peor que una regulación prudente. Las industrias a menudo prefieren una regulación predecible a una exposición incierta a la responsabilidad.

Tercero, el enfoque del compromiso ignora la distribución. Los beneficios de la innovación pueden recaer en algunos actores mientras los costes de seguridad recaen en otros. Las políticas deben abordar esta distribución, no solo el conjunto.

**Mejor enfoque.** Preguntar: ¿qué medidas de seguridad específicas se proponen? ¿Cuáles son sus costes y beneficios reales? ¿Quién asume cada uno? Este análisis granular es más productivo que los debates abstractos de innovación frente a seguridad.

## Concepción errónea 4: La IA está sobrevalorada o es una amenaza existencial

**El error.** Las discusiones sobre el riesgo de la IA tienden hacia los extremos. O bien la IA es "solo estadística" que no justifica atención especial, o es una amenaza existencial que exige acción de emergencia. Los responsables políticos a menudo eligen un extremo basándose en sus posiciones políticas previas.

**Por qué es incorrecto.** Ambos enfoques obstaculizan una política eficaz.

La visión desestimatoria conduce a una infrainversión en capacidad de gobernanza. Para cuando los riesgos se materializan, la capacidad institucional de respuesta es insuficiente. Esto ocurrió con la gobernanza de las redes sociales: el momento de construir capacidad de supervisión es antes de que los problemas se conviertan en crisis.

La visión de emergencia conduce a intervenciones precipitadas y mal diseñadas. También puede provocar una reacción adversa que dificulte la gobernanza. Y al centrarse en riesgos especulativos a largo plazo, puede distraer de los daños concretos a corto plazo.

**Mejor enfoque.** Tomar la IA en serio como desafío de gobernanza sin exigir certeza sobre escenarios extremos. Construir instituciones que puedan responder de manera flexible. Abordar los daños concretos ahora manteniendo la conciencia de los posibles desafíos futuros. Este es el enfoque que defendemos a lo largo de nuestra investigación sobre [proporcionalidad](/research/001-proportionality-disclosure/) y [evaluación de capacidades](/research/024-capability-evaluations/).

## Concepción errónea 5: Los compromisos voluntarios son suficientes

**El error.** Ante la complejidad legislativa y la presión de los grupos de interés, los responsables políticos a menudo aceptan los compromisos voluntarios de las empresas de IA como gobernanza adecuada.

**Por qué es incorrecto.** Los compromisos voluntarios presentan debilidades sistemáticas:

- Ningún mecanismo de aplicación cuando los compromisos entran en conflicto con los beneficios
- Participación selectiva: las empresas con peores prácticas no se ofrecen voluntariamente
- Objetivos móviles: los compromisos pueden debilitarse silenciosamente
- Opacidad: el cumplimiento es autoevaluado

Analizamos estas dinámicas en detalle en [autonotificación frente a auditoría externa](/research/010-self-reporting-vs-audit/). La historia sugiere que los compromisos voluntarios funcionan cuando están respaldados por una amenaza creíble de regulación, no como alternativas a ella.

**Mejor enfoque.** Los compromisos voluntarios pueden ser útiles para explorar enfoques de gobernanza y construir consenso. Pero deben preceder, no sustituir, los requisitos exigibles.

## Concepción errónea 6: El enfoque de China hace imposible la gobernanza

**El error.** Los responsables políticos a menudo argumentan que la gobernanza de la IA es imposible porque China (u otros competidores) no seguirá las reglas, por lo que cualquier restricción simplemente pone en desventaja a la industria nacional.

**Por qué es incorrecto.** Este razonamiento falla en múltiples niveles:

- No toda la gobernanza tiene que ver con la dinámica de la carrera. La seguridad doméstica de la IA, prevenir daños a los propios ciudadanos, importa independientemente de lo que hagan otros países.
- Los argumentos de competencia asumen que la gobernanza principalmente restringe. Pero la gobernanza también puede generar confianza que expanda la adopción de la IA.
- El argumento demuestra demasiado. Si la competencia internacional hiciera imposible la gobernanza, no podríamos regular nada.
- China, de hecho, ha implementado regulaciones de IA significativas, en algunas áreas más restrictivas que los enfoques occidentales.

**Mejor enfoque.** Algunas medidas de gobernanza tienen sentido unilateralmente; otras requieren coordinación internacional. Distinguir entre ambas. No usar la competencia internacional como excusa para evitar la gobernanza donde no es relevante.

## Concepción errónea 7: Debemos esperar hasta que se demuestren los daños

**El error.** Algunos responsables políticos argumentan que la gobernanza de la IA debe esperar hasta que se demuestren daños concretos, un enfoque de "innovación sin permisos".

**Por qué es incorrecto.** Este enfoque funciona mal para la IA por varias razones:

- Los daños de la IA pueden ser difíciles de demostrar. La discriminación algorítmica podría no detectarse nunca sin requisitos de auditoría.
- Algunos daños son irreversibles o catastróficos. Un enfoque de "esperar y ver" es apropiado para daños recuperables, no para catástrofes potenciales.
- Para cuando se demuestren los daños, la estructura industrial puede dificultar la intervención. La captura regulatoria es más fácil cuando las industrias están establecidas.

El [problema del excedente de capacidades](/research/009-capability-overhang/) significa que los riesgos pueden existir pero permanecer sin descubrir. Esperar a que se demuestre el daño puede significar esperar hasta que sea demasiado tarde.

**Mejor enfoque.** Utilizar la evaluación basada en riesgos. Donde los daños potenciales son graves e irreversibles, la precaución está justificada. Donde los daños son menores y reversibles, enfoques más ligeros tienen sentido. El enfoque escalonado de la Ley de IA de la UE, con todos sus defectos, acierta en esta estructura básica.

## Concepción errónea 8: Los estándares técnicos lo resolverán todo

**El error.** Los responsables políticos a veces esperan que los estándares técnicos, para pruebas de seguridad, fichas de modelo, evaluaciones de impacto, puedan sustituir a la supervisión institucional.

**Por qué es incorrecto.** Los estándares técnicos son herramientas, no soluciones. Necesitan:

- Gobernanza del propio proceso de elaboración de estándares (¿quién decide?)
- Mecanismos de aplicación (¿qué ocurre cuando se violan los estándares?)
- Procesos de adaptación (¿cómo se actualizan los estándares?)
- Autoridad de interpretación (¿quién resuelve la ambigüedad?)

Los estándares sin instituciones son como las leyes de tráfico sin policía de tráfico. Describen el comportamiento esperado pero no pueden asegurarlo. Por eso nos centramos en la [metagobernanza](/research/006-meta-governance-auditors/): gobernar los propios mecanismos de gobernanza.

**Mejor enfoque.** Los estándares técnicos deben estar integrados en marcos institucionales que aseguren que su desarrollo es legítimo, su aplicación es consistente y su cumplimiento es real.

## Hacia un mejor pensamiento político

Una buena política de IA requiere:

**Proporcionalidad.** Ajustar la intensidad de la gobernanza al riesgo real, no al revuelo o al miedo. Véase nuestro [marco de proporcionalidad](/research/001-proportionality-disclosure/).

**Capacidad institucional.** Construir la experiencia y la autoridad para gobernar la IA antes de que las crisis fuercen respuestas precipitadas.

**Inclusión de las partes interesadas.** Los expertos técnicos informan, pero los procesos democráticos deciden. Esto es central en nuestra visión de [gobernanza reflexiva](/research/030-manifesto/).

**Diseño adaptativo.** Crear mecanismos de gobernanza que puedan evolucionar a medida que cambian la tecnología y la comprensión.

**Orientación a la evidencia.** Exigir evidencia para las afirmaciones sobre costes y beneficios, tanto de los defensores de la industria como de los defensores de la seguridad.

Lo que está en juego es lo suficientemente importante como para justificar una atención política seria, y lo suficientemente importante como para justificar que las políticas sean correctas.

## Lecturas adicionales

- [Por qué "simplemente regular la IA" es más difícil de lo que parece](/research/018-regulation-is-hard/)
- [Marcos de responsabilidad por daños de la IA](/research/020-liability-frameworks/)
- [La Ley de IA de la UE: lo que no contempla](/research/019-eu-ai-act-gaps/)
- [Un manifiesto de IA reflexiva](/research/030-manifesto/)
