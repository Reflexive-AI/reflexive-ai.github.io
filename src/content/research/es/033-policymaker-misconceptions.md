---
title: "Lo que los responsables politicos entienden mal sobre el riesgo de la IA"
excerpt: "Concepciones erroneas comunes que conducen a politicas de IA ineficaces, y como pensar con mayor claridad sobre los riesgos reales que plantean los sistemas avanzados de IA."
date: 2026-01-15
categories:
  - Public
  - Policy Proposal
tags:
  - policy
  - risk-assessment
  - governance
  - regulation
---

## El problema con el discurso sobre el riesgo de la IA

Los responsables politicos enfrentan una tarea ingrata. Deben gobernar una tecnologia que no crearon, que a menudo no comprenden completamente, y que cambia mas rapido de lo que los procesos legislativos pueden acomodar. Bajo estas condiciones, las concepciones erroneas son inevitables.

Pero las concepciones erroneas conducen a politicas ineficaces. Los recursos se dirigen a los problemas equivocados. Los riesgos reales quedan sin abordar mientras los imaginarios consumen la atencion. Este analisis identifica los errores mas comunes y consecuentes en como los responsables politicos piensan sobre el riesgo de la IA, y sugiere correcciones.

Esto se basa en nuestro examen de [por que la regulacion de la IA es dificil](/research/018-regulation-is-hard/) y ofrece orientacion concreta para un pensamiento politico mas eficaz.

## Concepcion erronea 1: El riesgo de la IA es principalmente la perdida de empleo

**El error.** Muchos responsables politicos enmarcan la IA principalmente como un problema de disrupcion economica. Las audiencias se centran en los impactos sobre el empleo. Las politicas enfatizan programas de reconversion y redes de seguridad social.

**Por que es incorrecto.** Aunque la disrupcion economica es real y merece atencion, enmarcar el riesgo de la IA principalmente a traves de esta optica deja fuera los desafios de gobernanza mas urgentes:

- Sistemas de IA tomando decisiones trascendentales sobre la vida de las personas
- Potencial de la IA para facilitar acciones daninas a gran escala
- Erosion de la infraestructura epistemica a traves de contenido generado por IA
- Concentracion de poder en las organizaciones que controlan las capacidades de la IA

El desplazamiento laboral es un problema politico, pero es uno conocido con herramientas de respuesta establecidas. Los desafios novedosos de la IA requieren respuestas novedosas.

**Mejor enfoque.** La IA presenta multiples categorias de riesgo que requieren diferentes respuestas politicas. La disrupcion economica es una. Los riesgos para la seguridad, las implicaciones para los derechos y la concentracion de poder son otras. Las politicas deben abordar todas ellas, no solo la mas familiar politicamente.

## Concepcion erronea 2: Necesitamos que los expertos en IA nos digan que hacer

**El error.** Los responsables politicos a menudo delegan completamente en los expertos tecnicos, tratando la gobernanza de la IA como una cuestion principalmente tecnica que deben responder quienes construyen la tecnologia.

**Por que es incorrecto.** La experiencia tecnica es necesaria pero insuficiente para la gobernanza. Las preguntas centrales no son tecnicas:

- Cuanto riesgo es aceptable a cambio de que beneficios?
- Quien debe asumir los costes del desarrollo de la IA?
- Que usos de la IA son compatibles con los derechos humanos y la dignidad?
- Como debe distribuirse el poder sobre la IA?

Estas son preguntas politicas, eticas y sociales. Los expertos tecnicos pueden informarlas pero no pueden responderlas. Como exploramos en [el problema de la IA honesta](/research/029-honest-ai/), incluso las cuestiones que parecen tecnicas a menudo incorporan juicios de valor profundos.

**Mejor enfoque.** Utilizar la experiencia tecnica para comprender las capacidades y las limitaciones. Utilizar los procesos democraticos para realizar juicios de valor. No confundir ambas cosas.

## Concepcion erronea 3: La eleccion es innovacion o seguridad

**El error.** Los debates sobre la gobernanza de la IA a menudo asumen un compromiso entre innovacion (regulacion minima, desarrollo mas rapido) y seguridad (mas regulacion, desarrollo mas lento). Los responsables politicos se sienten obligados a elegir entre competitividad economica y proteccion.

**Por que es incorrecto.** Este enfoque es a menudo erroneo y siempre incompleto.

Primero, algunas medidas de seguridad tienen un impacto minimo en la velocidad de innovacion. Los requisitos de transparencia, la notificacion de incidentes y ciertos protocolos de prueba imponen costes modestos mientras mejoran significativamente la supervision.

Segundo, una IA insegura crea su propio freno a la innovacion. Si los sistemas de IA causan danos significativos, la reaccion sera peor que una regulacion prudente. Las industrias a menudo prefieren una regulacion predecible a una exposicion incierta a la responsabilidad.

Tercero, el enfoque del compromiso ignora la distribucion. Los beneficios de la innovacion pueden recaer en algunos actores mientras los costes de seguridad recaen en otros. Las politicas deben abordar esta distribucion, no solo el conjunto.

**Mejor enfoque.** Preguntar: que medidas de seguridad especificas se proponen? Cuales son sus costes y beneficios reales? Quien asume cada uno? Este analisis granular es mas productivo que los debates abstractos de innovacion frente a seguridad.

## Concepcion erronea 4: La IA esta sobrevalorada o es una amenaza existencial

**El error.** Las discusiones sobre el riesgo de la IA tienden hacia los extremos. O bien la IA es "solo estadistica" que no justifica atencion especial, o es una amenaza existencial que exige accion de emergencia. Los responsables politicos a menudo eligen un extremo basandose en sus posiciones politicas previas.

**Por que es incorrecto.** Ambos enfoques obstaculizan una politica eficaz.

La vision desestimatoria conduce a una infrainversion en capacidad de gobernanza. Para cuando los riesgos se materializan, la capacidad institucional de respuesta es insuficiente. Esto ocurrio con la gobernanza de las redes sociales: el momento de construir capacidad de supervision es antes de que los problemas se conviertan en crisis.

La vision de emergencia conduce a intervenciones precipitadas y mal disenadas. Tambien puede provocar una reaccion adversa que dificulte la gobernanza. Y al centrarse en riesgos especulativos a largo plazo, puede distraer de los danos concretos a corto plazo.

**Mejor enfoque.** Tomar la IA en serio como desafio de gobernanza sin exigir certeza sobre escenarios extremos. Construir instituciones que puedan responder de manera flexible. Abordar los danos concretos ahora manteniendo la conciencia de los posibles desafios futuros. Este es el enfoque que defendemos a lo largo de nuestra investigacion sobre [proporcionalidad](/research/001-proportionality-disclosure/) y [evaluacion de capacidades](/research/024-capability-evaluations/).

## Concepcion erronea 5: Los compromisos voluntarios son suficientes

**El error.** Ante la complejidad legislativa y la presion de los grupos de interes, los responsables politicos a menudo aceptan los compromisos voluntarios de las empresas de IA como gobernanza adecuada.

**Por que es incorrecto.** Los compromisos voluntarios presentan debilidades sistematicas:

- Ningun mecanismo de aplicacion cuando los compromisos entran en conflicto con los beneficios
- Participacion selectiva: las empresas con peores practicas no se ofrecen voluntariamente
- Objetivos moviles: los compromisos pueden debilitarse silenciosamente
- Opacidad: el cumplimiento es autoevaluado

Analizamos estas dinamicas en detalle en [autonotificacion frente a auditoria externa](/research/010-self-reporting-vs-audit/). La historia sugiere que los compromisos voluntarios funcionan cuando estan respaldados por una amenaza creible de regulacion, no como alternativas a ella.

**Mejor enfoque.** Los compromisos voluntarios pueden ser utiles para explorar enfoques de gobernanza y construir consenso. Pero deben preceder, no sustituir, los requisitos exigibles.

## Concepcion erronea 6: El enfoque de China hace imposible la gobernanza

**El error.** Los responsables politicos a menudo argumentan que la gobernanza de la IA es imposible porque China (u otros competidores) no seguira las reglas, por lo que cualquier restriccion simplemente pone en desventaja a la industria nacional.

**Por que es incorrecto.** Este razonamiento falla en multiples niveles:

- No toda la gobernanza tiene que ver con la dinamica de la carrera. La seguridad domestica de la IA, prevenir danos a los propios ciudadanos, importa independientemente de lo que hagan otros paises.
- Los argumentos de competencia asumen que la gobernanza principalmente restringe. Pero la gobernanza tambien puede generar confianza que expanda la adopcion de la IA.
- El argumento demuestra demasiado. Si la competencia internacional hiciera imposible la gobernanza, no podriamos regular nada.
- China, de hecho, ha implementado regulaciones de IA significativas, en algunas areas mas restrictivas que los enfoques occidentales.

**Mejor enfoque.** Algunas medidas de gobernanza tienen sentido unilateralmente; otras requieren coordinacion internacional. Distinguir entre ambas. No usar la competencia internacional como excusa para evitar la gobernanza donde no es relevante.

## Concepcion erronea 7: Debemos esperar hasta que se demuestren los danos

**El error.** Algunos responsables politicos argumentan que la gobernanza de la IA debe esperar hasta que se demuestren danos concretos, un enfoque de "innovacion sin permisos".

**Por que es incorrecto.** Este enfoque funciona mal para la IA por varias razones:

- Los danos de la IA pueden ser dificiles de demostrar. La discriminacion algoritmica podria no detectarse nunca sin requisitos de auditoria.
- Algunos danos son irreversibles o catastroficos. Un enfoque de "esperar y ver" es apropiado para danos recuperables, no para catastrofes potenciales.
- Para cuando se demuestren los danos, la estructura industrial puede dificultar la intervencion. La captura regulatoria es mas facil cuando las industrias estan establecidas.

El [problema del excedente de capacidades](/research/009-capability-overhang/) significa que los riesgos pueden existir pero permanecer sin descubrir. Esperar a que se demuestre el dano puede significar esperar hasta que sea demasiado tarde.

**Mejor enfoque.** Utilizar la evaluacion basada en riesgos. Donde los danos potenciales son graves e irreversibles, la precaucion esta justificada. Donde los danos son menores y reversibles, enfoques mas ligeros tienen sentido. El enfoque escalonado de la Ley de IA de la UE, con todos sus defectos, acierta en esta estructura basica.

## Concepcion erronea 8: Los estandares tecnicos lo resolveran todo

**El error.** Los responsables politicos a veces esperan que los estandares tecnicos, para pruebas de seguridad, fichas de modelo, evaluaciones de impacto, puedan sustituir a la supervision institucional.

**Por que es incorrecto.** Los estandares tecnicos son herramientas, no soluciones. Necesitan:

- Gobernanza del propio proceso de elaboracion de estandares (quien decide?)
- Mecanismos de aplicacion (que ocurre cuando se violan los estandares?)
- Procesos de adaptacion (como se actualizan los estandares?)
- Autoridad de interpretacion (quien resuelve la ambiguedad?)

Los estandares sin instituciones son como las leyes de trafico sin policia de trafico. Describen el comportamiento esperado pero no pueden asegurarlo. Por eso nos centramos en la [metagobernanza](/research/006-meta-governance-auditors/): gobernar los propios mecanismos de gobernanza.

**Mejor enfoque.** Los estandares tecnicos deben estar integrados en marcos institucionales que aseguren que su desarrollo es legitimo, su aplicacion es consistente y su cumplimiento es real.

## Hacia un mejor pensamiento politico

Una buena politica de IA requiere:

**Proporcionalidad.** Ajustar la intensidad de la gobernanza al riesgo real, no al revuelo o al miedo. Vease nuestro [marco de proporcionalidad](/research/001-proportionality-disclosure/).

**Capacidad institucional.** Construir la experiencia y la autoridad para gobernar la IA antes de que las crisis fuercen respuestas precipitadas.

**Inclusion de las partes interesadas.** Los expertos tecnicos informan, pero los procesos democraticos deciden. Esto es central en nuestra vision de [gobernanza reflexiva](/research/030-manifesto/).

**Diseno adaptativo.** Crear mecanismos de gobernanza que puedan evolucionar a medida que cambian la tecnologia y la comprension.

**Orientacion a la evidencia.** Exigir evidencia para las afirmaciones sobre costes y beneficios, tanto de los defensores de la industria como de los defensores de la seguridad.

Lo que esta en juego es lo suficientemente importante como para justificar una atencion politica seria, y lo suficientemente importante como para justificar que las politicas sean correctas.

## Lecturas adicionales

- [Por que "simplemente regular la IA" es mas dificil de lo que parece](/research/018-regulation-is-hard/)
- [Marcos de responsabilidad por danos de la IA](/research/020-liability-frameworks/)
- [La Ley de IA de la UE: lo que no contempla](/research/019-eu-ai-act-gaps/)
- [Un manifiesto de IA reflexiva](/research/030-manifesto/)
