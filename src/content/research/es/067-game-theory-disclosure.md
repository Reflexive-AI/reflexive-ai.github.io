---
title: "La teoría de juegos de la divulgación en IA: cuando la transparencia es un dilema del prisionero"
excerpt: "Las empresas enfrentan un problema de acción colectiva: todas se beneficiarían de una transparencia generalizada en la industria, pero la divulgación unilateral puede perjudicar la posición competitiva. ¿Cómo cambiamos la estructura de incentivos?"
date: 2026-02-04
categories:
  - Governance Analysis
  - Policy Proposal
tags:
  - transparency
  - game-theory
  - collective-action
  - disclosure
  - incentives
---

## El problema de la transparencia

Todos coinciden en que los sistemas de IA deberían ser más transparentes. Las empresas publican informes de transparencia. Los reguladores exigen divulgación. Los investigadores piden apertura sobre los datos de entrenamiento, las capacidades de los modelos y las evaluaciones de seguridad.

Sin embargo, la transparencia significativa sigue siendo escasa. Las fichas de modelo omiten información crítica. Las evaluaciones de seguridad se realizan en privado y se informan selectivamente. Las dinámicas competitivas desincentivan la divulgación.

¿Por qué? Porque la transparencia no es solo una cuestión técnica o ética. Es una cuestión estratégica. Y la estructura estratégica de la divulgación en IA se asemeja a un dilema del prisionero.

## El juego básico

Consideremos dos empresas de IA competidoras. Cada una debe decidir si divulgar información sobre sus modelos: composición de los datos de entrenamiento, evaluaciones de capacidades, resultados de pruebas de seguridad, limitaciones conocidas.

Si ambas divulgan:
- La industria se beneficia del aprendizaje compartido
- Los reguladores pueden comparar y evaluar
- Aumenta la confianza en la IA
- Ninguna obtiene ventaja competitiva sobre la otra

Si ninguna divulga:
- La industria pierde oportunidades de aprendizaje compartido
- Los reguladores no pueden comparar eficazmente
- La confianza permanece baja
- Ninguna obtiene ventaja competitiva sobre la otra

Si una divulga y la otra retiene:
- La que divulga revela vulnerabilidades que los competidores pueden explotar
- La que divulga se somete a un escrutinio que la otra evita
- La que retiene obtiene ventaja competitiva
- La que divulga puede sufrir daño reputacional si los defectos divulgados son sensacionalizados

La estructura de incentivos favorece la retención independientemente de lo que haga la otra parte. Esta es la estructura del dilema del prisionero: la racionalidad individual produce suboptimalidad colectiva.

## Complicaciones

El juego básico está simplificado. La divulgación real en IA involucra varias complicaciones.

**Capacidades asimétricas.** Las empresas difieren en la calidad de sus sistemas. Los sistemas de alta calidad se benefician más de la transparencia (nada que ocultar). Los sistemas de baja calidad se benefician más de la opacidad (los defectos permanecen ocultos). Esto crea incentivos asimétricos.

**Dinámicas reputacionales.** La divulgación puede señalar confianza. Las empresas con prácticas de seguridad sólidas pueden beneficiarse de una transparencia que demuestre su superioridad. Pero esto solo funciona si los observadores pueden evaluar con precisión la información divulgada.

**Decisiones secuenciales.** Las empresas no deciden simultáneamente. Observan el comportamiento de las demás y responden. Los primeros en divulgar pueden establecer normas que los entrantes posteriores deben seguir, o ser castigados por su ingenuidad.

**Divulgación heterogénea.** La divulgación no es binaria. Las empresas pueden revelar selectivamente información que las hace quedar bien mientras ocultan información desfavorable. Esta divulgación estratégica puede ser peor que la opacidad uniforme porque induce a error mientras aparenta transparencia.

**Multiplicidad de audiencias.** La divulgación llega a múltiples audiencias: reguladores, competidores, clientes, investigadores, público. La información valiosa para una audiencia puede ser perjudicial si la ve otra.

## Por qué fracasa la transparencia voluntaria

Dada esta estructura, los llamamientos a la transparencia voluntaria de la industria fracasarán en su mayoría.

Las empresas individuales enfrentan presión para retener. Incluso si los ejecutivos creen que la transparencia es lo correcto, los consejos de administración y los inversores pueden priorizar la posición competitiva. La desventaja de ser el primero en divulgar es real.

Las asociaciones industriales no pueden resolver esto. Las asociaciones representan los intereses colectivos de sus miembros, pero esos intereses son aparentar transparencia mientras los competidores la ejercen realmente. Los compromisos declarados de transparencia típicamente producen una divulgación real mínima.

Las exhortaciones culturales son insuficientes. Decir a las empresas que deberían ser transparentes no cambia la estructura de incentivos. Mientras la retención sea individualmente racional, la mayoría de las empresas retendrán.

## Cambiar la estructura de incentivos

Si la transparencia voluntaria fracasa, las intervenciones de gobernanza deben cambiar el juego subyacente.

**Mandatos regulatorios.** La divulgación obligatoria elimina la desventaja competitiva de la transparencia unilateral. Si todos deben divulgar, nadie pierde posición relativa por divulgar.

La [Ley de IA de la UE](/research/019-eu-ai-act-gaps/) adopta este enfoque, exigiendo documentación y divulgación para sistemas de alto riesgo. La eficacia depende de qué divulgación se exige y si los requisitos se aplican.

**Verificación y auditoría.** Las empresas podrían afirmar transparencia mientras practican divulgación selectiva. Las [auditorías](/research/006-meta-governance-auditors/) de terceros pueden verificar que las divulgaciones sean completas y precisas. Los auditores cambian el juego al hacer detectable la no divulgación estratégica.

**Vinculación con la responsabilidad.** Si la no divulgación aumenta la exposición a la responsabilidad en caso de daño, el cálculo cambia. Las empresas podrían preferir la divulgación que documenta sus prácticas de seguridad sobre la opacidad que las deja vulnerables a reclamaciones de que no ejercieron la diligencia debida.

Los [marcos de responsabilidad](/research/020-liability-frameworks/) pueden estructurarse para recompensar la divulgación: salvaguardas para empresas que divulgaron riesgos conocidos, daños incrementados para quienes los ocultaron.

**Mecanismos reputacionales.** Las calificaciones, clasificaciones y cuadros de mando públicos pueden recompensar la divulgación y penalizar la opacidad. Si los clientes, inversores y talento prefieren empresas transparentes, las dinámicas de mercado cambian.

Esto requiere evaluadores creíbles que puedan valorar la calidad de la divulgación. Sin esto, los mecanismos reputacionales recompensan la apariencia de transparencia en lugar de la sustancia.

**Compromiso coordinado de la industria.** Si todos los actores principales se comprometen simultáneamente con estándares de divulgación, ninguno obtiene ventaja por desertar. Esto es autorregulación colectiva.

El desafío es la aplicación. Sin verificación externa, las empresas pueden desertar de los compromisos declarados. Las [limitaciones de la autonotificación](/research/010-self-reporting-vs-audit/) se aplican aquí.

## Niveles de divulgación

No toda la información es igualmente estratégica. La divulgación puede escalonarse por sensibilidad.

**Divulgación de baja sensibilidad.** Descripciones generales de capacidades, categorías amplias de datos de entrenamiento, resultados de evaluación de seguridad de alto nivel. El daño competitivo es mínimo. Esta divulgación debería ser sencilla de exigir.

**Divulgación de sensibilidad media.** Resultados de evaluación específicos, modos de fallo conocidos, composición detallada de datos de entrenamiento. Alguna información competitiva, pero mayormente relevante para la evaluación de seguridad. Los reguladores podrían recibir esta información bajo confidencialidad mientras se publican resúmenes.

**Divulgación de alta sensibilidad.** Pesos del modelo, técnicas de entrenamiento propietarias, capacidades no reportadas. Valor competitivo significativo. La divulgación pública puede no ser apropiada, pero las [evaluaciones de capacidades](/research/024-capability-evaluations/) por terceros de confianza podrían serlo.

La [proporcionalidad en la divulgación](/research/001-proportionality-disclosure/) se aplica: la información más sensible puede justificar transparencia restringida en lugar de pública.

## El enfoque reflexivo

La gobernanza reflexiva ofrece mecanismos adicionales.

La [documentación de restricciones legible por máquinas](/research/003-machine-readable-constraint-schema/) puede verificarse computacionalmente. A diferencia de la divulgación en lenguaje natural, que puede ser estratégicamente vaga, los formatos legibles por máquinas permiten la verificación automatizada. Los sistemas satisfacen las restricciones declaradas o no las satisfacen.

Los [protocolos de IA a regulador](/research/014-ai-regulator-protocol/) pueden habilitar la divulgación continua en lugar de informes puntuales. Los sistemas que señalan anomalías en su propia operación proporcionan transparencia continua sin requerir que las empresas anticipen qué divulgar.

La [procedencia de las salidas](/research/012-output-provenance/) permite la transparencia sobre salidas específicas sin requerir la divulgación de los componentes internos del sistema. Los usuarios y los sistemas posteriores pueden verificar lo que recibieron sin acceso a cómo fue generado.

Estos mecanismos cambian el juego al hacer la no divulgación detectable o irrelevante. Si las restricciones son verificables por máquinas, declarar restricciones falsas fracasa. Si los sistemas reportan sus propias anomalías, las empresas no pueden ocultar problemas que desconocían.

## Conclusión

La transparencia en IA no es solo una aspiración ética. Es un problema estratégico con una estructura específica: el dilema del prisionero.

Reconocer esta estructura aclara por qué las iniciativas de transparencia voluntaria fracasan y qué intervenciones podrían tener éxito. Cambiar la estructura de incentivos importa más que cambiar la retórica.

Los mandatos regulatorios, los mecanismos de verificación, la vinculación con la responsabilidad y la documentación reflexiva desplazan los incentivos hacia la divulgación. Ninguno es perfecto. Todos son mejores que esperar que las empresas se desfavorezcan voluntariamente.

El objetivo no es castigar a las empresas por la opacidad. Es crear condiciones donde la transparencia sea compatible con el éxito competitivo. Cuando la divulgación es universal, la penalización competitiva desaparece. Cuando la divulgación es verificable, la manipulación se vuelve difícil. Cuando la divulgación está vinculada con la responsabilidad, el ocultamiento se vuelve arriesgado.

La teoría de juegos no nos dice qué valorar. Pero nos dice cómo obtener lo que valoramos dada la forma en que los agentes responden a los incentivos. Si valoramos la transparencia, debemos diseñar sistemas donde la transparencia sea rentable.

## Investigación relacionada

- [Proporcionalidad en la divulgación de modelos](/research/001-proportionality-disclosure/)
- [Autonotificación vs. auditoría externa: compensaciones](/research/010-self-reporting-vs-audit/)
- [¿Quién vigila a los vigilantes? Auditar a los auditores de IA](/research/006-meta-governance-auditors/)
- [Un esquema de restricciones legible por máquinas](/research/003-machine-readable-constraint-schema/)
- [Marcos de responsabilidad por daños de la IA](/research/020-liability-frameworks/)
