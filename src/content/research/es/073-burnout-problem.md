---
title: "El problema del agotamiento: sostenibilidad en la investigación de seguridad de IA"
excerpt: "La investigación en seguridad de IA opera bajo un marco de 'carrera contra la catástrofe'. Esta cultura de urgencia puede socavar el trabajo mismo que pretende motivar. ¿Cómo es una investigación de seguridad sostenible?"
date: 2026-02-04
categories:
  - Reflexivity
  - Public
tags:
  - researcher-wellbeing
  - sustainability
  - culture
  - institutions
  - meta
---

## La trampa de la urgencia

Los investigadores de seguridad de IA trabajan a menudo bajo una presión extraordinaria. El marco es conocido: puede que dispongamos de tiempo limitado antes de la llegada de la IA transformadora, la investigación en seguridad está infrafinanciada en relación con la investigación en capacidades, y lo que está en juego no podría ser más importante.

Esta urgencia no es artificial. Existen razones genuinas para creer que la seguridad de la IA importa y que los plazos pueden ser más cortos de lo deseable. Pero la urgencia tiene costes. Y esos costes pueden socavar la propia investigación que se supone que deben motivar.

Este artículo examina el problema de sostenibilidad en la investigación de seguridad de IA: cómo la cultura de urgencia afecta a los investigadores, si produce un buen trabajo y qué cambios institucionales podrían ayudar.

## El patrón

Si se habla en privado con investigadores de seguridad de IA, emergen patrones.

**Culpa por descansar.** Los investigadores dicen sentirse culpables cuando no trabajan. Si lo que está en juego es la extinción, ¿cómo se pueden justificar unas vacaciones? Esta culpa persiste incluso cuando los investigadores entienden intelectualmente que el descanso mejora el rendimiento.

**Expansión del alcance.** Todo está conectado con la seguridad. Cada avance en capacidades parece relevante. Los investigadores tienen dificultades para delimitar sus preocupaciones, lo que genera una sobrecarga cognitiva abrumadora.

**Inadecuación comparativa.** Los investigadores se comparan con colegas que aparentemente trabajan más, publican más o contribuyen de forma más directa. Esto crea expectativas laborales en espiral.

**Aislamiento.** La comunidad es pequeña y concentrada. Los investigadores pueden sentir que no pueden hablar de sus dificultades sin socavar su posición o alarmar a otros.

**Cinismo y desesperanza.** La exposición prolongada a escenarios catastróficos sin un progreso claro produce cinismo sobre si el trabajo importa, o desesperanza sobre si el éxito es posible.

Estos patrones no son universales. Muchos investigadores mantienen equilibrio y perspectiva. Pero suficientes los experimentan como para que el patrón merezca atención.

## Por qué esto importa para la seguridad

El agotamiento no es solo una cuestión de bienestar. Afecta a la calidad de la investigación.

**Deterioro cognitivo.** El agotamiento degrada el razonamiento, la creatividad y el juicio. La investigación en seguridad requiere exactamente las capacidades cognitivas que el agotamiento destruye.

**Tolerancia al riesgo.** Los investigadores agotados pueden tomar atajos, omitir verificaciones o aceptar estándares más bajos. En la investigación de seguridad, esto es particularmente peligroso.

**Rotación.** Los investigadores que se agotan abandonan el campo. Dada la escasez de talento, perder investigadores experimentados es costoso. El campo no puede permitirse tratar a los investigadores como prescindibles.

**Efectos de selección.** Si el campo selecciona por la disposición a sacrificar el bienestar, selecciona en contra de investigadores con perspectivas equilibradas. Esto homogeneiza la base de investigadores y puede introducir puntos ciegos sistemáticos.

**Mal modelado.** Los investigadores que construyen sistemas de IA para el florecimiento humano deberían comprender el florecimiento humano. Los investigadores que descuidan su propio bienestar pueden diseñar sistemas que reproduzcan ese mismo descuido.

## La justificación de la urgencia

La cultura de la urgencia tiene una justificación a mano: lo que está en juego es enorme, el plazo es corto, y debemos trabajar lo más duro posible.

Esta justificación merece escrutinio.

**Incertidumbre sobre los plazos.** No sabemos cuándo llegará la IA transformadora. Las predicciones medianas van desde años hasta décadas. Si los plazos son más largos, agotar a los investigadores ahora sacrifica capacidad a largo plazo por producción a corto plazo.

**Rendimientos decrecientes.** Trabajar más horas no aumenta la producción proporcionalmente. El trabajo creativo y analítico se deteriora drásticamente más allá de ciertos umbrales. La décima hora no vale lo que la primera hora.

**Sostenibilidad institucional.** Incluso si el sacrificio individual estuviera justificado, las instituciones que dependen de un esfuerzo insostenible fracasarán. Construir instituciones de seguridad duraderas requiere prácticas sostenibles.

**Obligaciones morales hacia los investigadores.** Los investigadores son personas. Su bienestar importa con independencia de su valor instrumental para la seguridad. Las organizaciones que tratan a los investigadores puramente como instrumentos violan principios éticos básicos.

**Modelado y cultura.** La forma en que la comunidad de seguridad trata a sus miembros señala lo que la comunidad valora. Una comunidad que sacrifica el bienestar de los investigadores por la producción puede construir sistemas de IA que sacrifiquen el bienestar humano por el rendimiento.

## Cómo es la seguridad sostenible

La investigación de seguridad sostenible diferiría de la práctica actual en varios aspectos.

**Semanas laborales delimitadas.** Las organizaciones establecerían expectativas explícitas sobre las horas de trabajo y desalentarían activamente el exceso de trabajo. El liderazgo modelaría prácticas sostenibles.

**El descanso como inversión.** Las vacaciones, las pausas y la recuperación se tratarían como inversiones en productividad a largo plazo, no como costes que minimizar o placeres culpables que justificar.

**Gestión del alcance.** Se apoyaría a los investigadores para que se centren en lugar de intentar abarcar todo. Decir "eso queda fuera de mi alcance" sería aceptable, no irresponsable.

**Apoyo psicológico.** Trabajar con escenarios catastróficos tiene costes psicológicos. Las organizaciones proporcionarían recursos de apoyo en lugar de suponer que los investigadores pueden soportar una exposición ilimitada al pensamiento del peor caso.

**Sostenibilidad de la carrera.** Las estructuras de carrera anticiparían carreras largas, no carreras a muerte seguidas de abandono. Los ascensos, las excedencias y las transiciones de rol se normalizarían.

**Estilos de trabajo diversos.** No todos prosperan en las mismas condiciones. Las organizaciones acomodarían diferentes necesidades en lugar de suponer que un único modelo sirve para todos.

## Cambios institucionales

Avanzar hacia la sostenibilidad requiere cambio institucional, no solo decisiones individuales.

**Estructuras de financiación.** Si los financiadores recompensan el volumen de producción sobre la calidad de la investigación, las organizaciones presionarán a los investigadores en consecuencia. Los financiadores deberían atender a métricas de sostenibilidad: retención de investigadores, satisfacción y productividad a largo plazo.

**Normas de liderazgo.** Los líderes que trabajan de forma insostenible envían la señal de que los demás deberían hacerlo también. Seleccionar líderes que modelen el equilibrio importa. Celebrar el exceso de trabajo debería ser tan inaceptable como celebrar otros comportamientos dañinos.

**Cultura entre pares.** Los investigadores se influyen mutuamente. Las comunidades que alaban el exceso de trabajo crean dinámicas destructivas. Las comunidades que normalizan el equilibrio crean dinámicas de apoyo.

**Políticas explícitas.** Los compromisos vagos con el bienestar logran poco. Las políticas explícitas sobre horarios, permisos y apoyo crean rendición de cuentas.

**Rendición de cuentas externa.** Las organizaciones pueden resistirse a la sostenibilidad porque sienten que aceptan menos producción. Los observadores externos (financiadores, socios, la comunidad más amplia) pueden exigir responsabilidades a las organizaciones.

## El problema de coordinación

Las organizaciones individuales enfrentan un problema de coordinación. Si una organización mantiene prácticas sostenibles mientras otras exigen sacrificio, la organización sostenible puede enfrentarse a una desventaja competitiva: menos publicaciones, un progreso más lento, menor prestigio.

Esto crea dinámicas de carrera a nivel organizacional, reflejando la carrera capacidades-seguridad a nivel de la industria.

Las soluciones a este problema de coordinación son paralelas a otros escenarios de carrera hacia el fondo:

**Normas y reputación.** Si explotar a los investigadores se vuelve costoso reputacionalmente (si los financiadores y el talento evitan a organizaciones conocidas por el agotamiento), los incentivos cambian.

**Estándares compartidos.** Si las organizaciones principales se comprometen colectivamente con estándares de sostenibilidad, ninguna organización individual soporta una desventaja competitiva.

**Transparencia.** Si la experiencia de los investigadores en las organizaciones es visible (a través de encuestas, evaluaciones o informes), las organizaciones no pueden ocultar los costes que imponen.

## Aplicación reflexiva

El marco de gobernanza reflexiva sugiere que los sistemas de IA deberían participar en su propia supervisión. Una observación reflexiva paralela se aplica aquí: los investigadores de seguridad deberían aplicar sus marcos analíticos a su propia comunidad.

El campo estudia cómo la desalineación de incentivos produce prácticas peligrosas en el desarrollo de IA. Esos mismos incentivos operan dentro de la propia comunidad de seguridad.

El campo estudia cómo la transparencia permite la rendición de cuentas. Ese principio se aplica a las propias organizaciones de seguridad.

El campo estudia cómo las restricciones mantienen comportamientos beneficiosos bajo presión. Los investigadores que enfrentan la presión de la urgencia también necesitan restricciones.

Esto no es una búsqueda de hipocresía. Es reconocer que las ideas desarrolladas para la gobernanza de IA se aplican de manera más amplia.

## Conclusión

La urgencia de la seguridad de IA es real. Pero la urgencia no es un cheque en blanco para prácticas que socavan la sostenibilidad y, en última instancia, el trabajo mismo.

Un campo que consume investigadores no puede mantener el conocimiento institucional, la perspectiva y el juicio que el trabajo de seguridad requiere. Un campo que sacrifica el bienestar de los investigadores por la producción puede construir sistemas que reproduzcan ese sacrificio.

La investigación de seguridad sostenible requiere compromiso institucional, no solo resiliencia individual. Requiere reconocer que el bienestar de los investigadores no es un lujo que se pueda intercambiar por progreso, sino un prerrequisito para un buen trabajo.

El mismo rigor que el campo aplica a la seguridad de la IA debería aplicarse a sus propias prácticas. Eso es lo que significa la gobernanza reflexiva.

## Investigación relacionada

- [A Reflexive AI Manifesto](/research/030-manifesto/)
- [Why AI Safety Researchers Disagree: A Taxonomy of Worldviews](/research/064-ai-safety-worldviews/)
- [The Role of Civil Society in AI Governance](/research/044-civil-society-role/)
