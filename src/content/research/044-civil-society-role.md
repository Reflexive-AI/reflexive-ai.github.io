---
title: "The Role of Civil Society in AI Governance"
excerpt: "Beyond companies and regulators: how civil society organizations contribute to AI governance, and how their role could be strengthened."
date: 2026-01-26
categories:
  - Public
tags:
  - governance
  - transparency
  - policy
  - ethics
---

## The Third Pillar

AI governance discussions often focus on two actors: companies that develop AI and governments that regulate it. But a third actor plays an essential role: civil society.

Civil society includes non-governmental organizations, advocacy groups, academic institutions, professional associations, journalists, and organized citizen movements. These actors don't develop AI or write laws, but they shape the environment in which both happen.

This analysis examines how civil society contributes to AI governance, what enables or constrains these contributions, and how civil society's role could be strengthened.

## What Civil Society Does

Civil society contributes to AI governance through multiple channels.

### Research and Analysis

Academic institutions and think tanks produce research on AI capabilities, risks, and governance:

- Technical AI safety research
- Policy analysis and proposals
- Empirical studies of AI impacts
- Comparative governance research

This research informs both industry practice and government policy. Much of what regulators know about AI comes from civil society research.

### Advocacy and Pressure

Advocacy organizations push for stronger governance:

- Campaigns for specific regulations
- Public pressure on companies
- Media engagement to raise awareness
- Litigation to enforce rights

This pressure can shift what companies and governments consider politically feasible or necessary.

### Watchdog Functions

Civil society monitors AI development and deployment:

- Auditing AI systems for bias and harm
- Investigating company practices
- Documenting AI failures and harms
- Tracking regulatory compliance

This oversight supplements limited government capacity. As we discussed in [who watches the watchers](/research/006-meta-governance-auditors/), independent oversight is essential.

### Standards Development

Civil society participates in standards development:

- Academic experts on standards committees
- Professional associations setting norms
- Multi-stakeholder initiatives developing guidelines

Standards bodies, as we examined in [their governance role](/research/039-standards-bodies/), often include civil society participation.

### Capacity Building

Civil society builds governance capacity:

- Training policymakers on AI
- Educating journalists on technical topics
- Public education on AI literacy
- Developing assessment frameworks

This capacity building enables more informed governance by other actors.

### Voice for Affected Communities

Civil society represents those affected by AI who may lack other voice:

- Marginalized communities disproportionately affected by AI
- Future generations affected by long-term AI development
- General public affected by AI-enabled systems

This representation counterbalances industry influence in governance processes.

## Examples of Impact

Civil society has demonstrably influenced AI governance.

### Algorithmic Accountability

ProPublica's investigation of COMPAS—a recidivism prediction algorithm—in 2016 brought algorithmic bias into public discourse. This journalism spurred academic research, advocacy campaigns, and eventually regulatory attention. The EU AI Act's provisions on high-risk AI in criminal justice trace back to concerns raised by civil society.

### Facial Recognition

Civil society campaigns against facial recognition—including research documenting bias, advocacy for bans, and grassroots organizing—have achieved meaningful restrictions in multiple jurisdictions. Several cities have banned government facial recognition. Companies have paused or limited facial recognition products.

### AI Safety Attention

The AI safety research community—largely academic and nonprofit—has moved safety from fringe concern to central governance issue. Research from institutions like MIRI, FHI, CAIS, and now Anthropic has shaped how policymakers and the public understand AI risk.

### Workers' Rights

Labor unions and worker advocacy groups have pushed for worker voice in AI deployment—particularly AI systems that affect working conditions, hiring, and surveillance. This advocacy has influenced both legislation and corporate practice.

## Constraints on Civil Society

Despite these contributions, civil society faces significant constraints.

### Resource Asymmetry

Major AI companies have vastly more resources than civil society organizations. Companies can field dozens of lobbyists; advocacy groups may have a handful of staff covering all technology issues. This asymmetry affects capacity for research, advocacy, and engagement.

### Technical Expertise

AI is technically complex. Civil society organizations may lack technical expertise to effectively analyze AI systems, engage with technical proposals, or participate in standards development. This is improving as AI-focused civil society organizations develop, but gaps remain.

### Access to Systems

Civil society cannot audit what it cannot access. Most AI systems are proprietary, with limited external access. This constrains independent assessment. We explored related challenges in [self-reporting versus audit](/research/010-self-reporting-vs-audit/).

### Political Capture

Some civil society organizations are funded by AI companies, creating potential capture. Industry-funded research may be biased toward industry-friendly conclusions. Transparency about funding helps but doesn't eliminate this concern.

### Coordination Challenges

Civil society is fragmented—thousands of organizations with different priorities, approaches, and ideologies. Coordination is difficult, limiting collective impact.

### Speed Mismatch

AI development moves faster than civil society organizing. By the time advocacy campaigns develop, systems may be widely deployed. Civil society often reacts rather than anticipates.

## Strengthening Civil Society's Role

Several approaches could strengthen civil society's contribution to AI governance.

### Access Rights

Legal requirements for researcher access to AI systems—as proposed in the EU Digital Services Act for platforms—could enable independent assessment. Similarly, whistleblower protections (as we examined in [our analysis](/research/022-whistleblower-protections/)) help information flow to civil society.

### Funding Independence

Funding civil society through public sources, philanthropic foundations without industry ties, or dedicated governance funds could ensure independence. Transparency about funding sources enables stakeholders to assess potential bias.

### Capacity Building

Investment in civil society capacity—technical training, fellowship programs, organizational development—could address expertise gaps. This might come from foundations, governments, or academic partnerships.

### Formal Inclusion

Formal inclusion of civil society in governance processes—advisory bodies, standards development, regulatory consultation—ensures voice beyond lobbying. This requires making participation feasible for resource-constrained organizations.

### Information Rights

Legal requirements for disclosure—of AI systems, of governance practices, of incidents—create information that civil society can use for oversight and advocacy.

### Coalition Building

Civil society organizations can amplify impact through coalition building—coordinating across organizations, sectors, and countries. International networks are particularly important given AI's global nature.

## The Reflexive Dimension

Our work on reflexive governance suggests additional roles for civil society.

**Interpreting AI self-reporting.** If AI systems increasingly [report their constraints](/research/014-ai-regulator-protocol/) and [explain their limitations](/research/026-explaining-constraints/), civil society can interpret these reports for public understanding.

**Monitoring reflexive mechanisms.** Civil society can monitor whether reflexive governance mechanisms actually work—are AI systems' self-reports accurate? Do constraints function as claimed?

**Advocating for reflexive approaches.** Civil society can push for AI systems to be more transparent about their operation, advancing our goal of AI that participates in its own governance.

**Representing in reflexive processes.** As AI systems become more sophisticated, processes for governance may need to include AI itself. Civil society can ensure that human interests remain central in these processes.

## What Strong Civil Society Looks Like

Effective civil society contribution to AI governance would include:

**Independent research institutions** producing rigorous, unbiased analysis of AI capabilities, risks, and governance options.

**Well-resourced advocacy organizations** able to sustain campaigns, engage with technical detail, and coordinate across issues and jurisdictions.

**Investigative journalists** with technical capacity to probe AI development and deployment, and editorial support for long-term investigation.

**Community organizations** representing those most affected by AI, with capacity to participate in governance processes.

**Professional associations** setting and enforcing norms for AI development, with credibility and enforcement capacity.

**Diverse funding** from sources that don't create industry capture, enabling independence and long-term planning.

**Effective coordination** mechanisms that enable collective action while respecting organizational diversity.

## Conclusion

Civil society is essential to effective AI governance. It produces research, advocates for protection, monitors compliance, represents affected communities, and builds governance capacity. Without civil society, governance would be captured by industry interests and limited by government capacity.

Strengthening civil society's role requires addressing constraints: resource asymmetry, access limitations, expertise gaps, and coordination challenges. Investment in civil society capacity is investment in AI governance.

The Reflexive AI Initiative aims to contribute to this ecosystem—producing research, proposing governance frameworks, and advocating for AI that participates responsibly in its own governance. We welcome [collaboration](/contribute/) with others working toward these goals.

## Further Reading

- [Who Watches the Watchers? Auditing AI Auditors](/research/006-meta-governance-auditors/)
- [Whistleblower Protections in AI Labs](/research/022-whistleblower-protections/)
- [The Role of Standards Bodies in AI Governance](/research/039-standards-bodies/)
- [Self-Reporting vs. External Audit: Trade-offs](/research/010-self-reporting-vs-audit/)
