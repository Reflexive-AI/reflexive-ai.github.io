---
title: "Career Paths in AI Governance"
excerpt: "A practical guide to careers in AI governance. Roles, required skills, where the jobs are, and how to break into a field where demand far outstrips supply."
date: 2026-02-07
toc: true
categories:
  - Public Interest
tags:
  - careers
  - ai-governance
  - workforce
  - policy
  - education
version: "1.0"
---

**Reflexive Research Object 098**
*Type: Research*

## Introduction

AI governance is no longer an academic curiosity. It is a growing professional field with real jobs, real salaries, and a serious shortage of qualified people. Governments, companies, international organizations, and civil society groups are all hiring. Most of them are struggling to find candidates.

If you care about how AI shapes society, this is a field you can work in. This article maps the landscape: what roles exist, what they require, where to find them, and how to get started. Whether you are a student choosing a direction, a mid-career professional considering a pivot, or a technologist who wants to work on governance, this guide is for you.

For background on what AI governance actually is, see our [AI Governance Primer](/research/017-governance-primer/). For how we got here, see [The History of AI Governance](/research/032-history-of-ai-governance/).

## The Roles

AI governance is not a single job. It spans a range of distinct roles, each with different daily realities and skill requirements.

### Policy Analyst

Policy analysts research AI issues and write recommendations for legislators, regulators, or government agencies. They translate technical developments into language policymakers can act on. A policy analyst at NIST writes frameworks for AI risk management. A policy analyst at a congressional office drafts questions for hearings on frontier AI.

**Skills needed:** Strong writing, research methodology, ability to read technical papers and extract policy implications. Familiarity with legislative and regulatory processes.

**Where to find these jobs:** Government agencies (NIST, OSTP, NTIA in the US; DSIT in the UK; DG CNECT in the EU), think tanks (Brookings, RAND, Ada Lovelace Institute, Centre for AI Safety Policy), legislative offices.

### Technical Safety Researcher

Technical safety researchers work on the engineering side of governance. They design evaluations for dangerous capabilities, build tools to detect misuse, develop alignment techniques, and test model behavior under adversarial conditions. This is the most technically demanding governance role.

**Skills needed:** Machine learning expertise, programming (Python, PyTorch/JAX), experimental design, knowledge of AI safety research. A PhD is common but not always required.

**Where to find these jobs:** AI labs (Anthropic, OpenAI, Google DeepMind, Meta FAIR), government labs (AISI in the UK, USAISI in the US), academic research groups (MIRI, CHAI at UC Berkeley, Centre for AI Safety).

### AI Ethicist

AI ethicists analyze the moral and social dimensions of AI systems. They assess fairness in automated decisions, evaluate the social impact of deployment choices, and advise organizations on responsible AI practices. The title varies: some organizations call this role "responsible AI lead" or "AI ethics researcher."

**Skills needed:** Background in philosophy, social science, science and technology studies (STS), or law. Ability to apply ethical frameworks to concrete technical systems. Strong communication skills for conveying complex ideas to engineers and executives.

**Where to find these jobs:** Technology companies (responsible AI teams), universities, civil society organizations (AI Now Institute, Data & Society), consultancies.

### Compliance Officer

As AI regulation expands, compliance officers ensure their organizations meet legal requirements. Under the EU AI Act, companies deploying high-risk AI systems need staff who understand both the regulation and the technology. This role is growing fast.

**Skills needed:** Legal knowledge (especially technology regulation), project management, risk assessment, ability to interpret technical documentation. A law degree or compliance certification helps.

**Where to find these jobs:** Technology companies, financial institutions using AI, healthcare organizations, legal and consulting firms (Deloitte, PwC, EY).

### Red Teamer

Red teamers probe AI systems for vulnerabilities, biases, and dangerous capabilities. They try to make models produce harmful outputs, find ways to bypass safety measures, and document failure modes. This work directly informs both safety engineering and governance decisions.

**Skills needed:** Creative thinking, adversarial mindset, familiarity with prompt engineering and model behavior, knowledge of threat modeling. Some roles require domain expertise (biosecurity, cybersecurity, CBRN).

**Where to find these jobs:** AI labs, government AI safety institutes, security consultancies, bug bounty programs run by AI companies.

### Standards Developer

Standards developers create the technical specifications and best practices that define how AI governance works in practice. They write documents like ISO/IEC 42001 (AI management systems) or NIST AI 600-1 (AI risk management). This work is slow and detail-oriented, but it shapes how governance operates across entire industries.

**Skills needed:** Deep knowledge of standards processes, technical writing, consensus-building, specific domain expertise (security, quality management, or AI). Patience.

**Where to find these jobs:** Standards bodies (ISO, IEEE, NIST, CEN-CENELEC), industry consortia (Partnership on AI, Frontier Model Forum), national standards organizations.

### Auditor

AI auditors independently assess whether AI systems meet governance requirements. They test for bias, verify safety claims, evaluate documentation, and produce reports for regulators or the public. This role is expanding as audit requirements increase under new regulations. We explored the complexities of this role in our article on [meta-governance for auditors](/research/006-meta-governance-auditors/).

**Skills needed:** Quantitative analysis, statistical testing, domain knowledge in fairness and safety metrics, understanding of regulatory requirements. Experience in traditional auditing (financial, IT) transfers well.

**Where to find these jobs:** Specialized AI audit firms (Holistic AI, ORCAA, Credo AI), accounting firms expanding into AI audit, government agencies, independent consultancies.

### Civil Society Advocate

Civil society advocates represent public interests in AI governance. They investigate harms, publish research, campaign for stronger protections, organize affected communities, and participate in regulatory processes. This work shapes the political environment in which governance decisions happen.

**Skills needed:** Research and communication, community organizing, media engagement, understanding of policy processes. Domain expertise in areas affected by AI (criminal justice, immigration, labor).

**Where to find these jobs:** Non-profit organizations (Electronic Frontier Foundation, Access Now, Algorithm Watch, Center for Democracy & Technology), investigative journalism outlets, community organizations, academic centers.

## The Talent Gap

Demand for AI governance professionals far exceeds supply. A 2024 survey by the International Association of Privacy Professionals found that 68% of organizations expected to hire AI governance staff within two years, but over half reported difficulty finding qualified candidates. Government agencies face an even sharper gap: they compete with private-sector salaries while needing the same expertise.

The gap is especially severe in three areas:

**People who understand both the technology and the policy.** Most governance professionals come from either a technical or a policy background. Few are fluent in both. Organizations prize candidates who can read a machine learning paper and draft a regulatory comment with equal confidence.

**Auditors with AI-specific expertise.** As audit mandates expand under the EU AI Act and emerging US state laws, the number of people qualified to audit AI systems remains small. Traditional audit firms are retraining staff, but building genuine AI expertise takes time.

**International and multilateral governance specialists.** Bodies like the OECD, the Global Partnership on AI, and the UN's Advisory Body on AI need staff who combine AI knowledge with experience in international negotiations. This combination is rare.

## Educational Pathways and Entry Points

There is no single degree that prepares you for AI governance. The field draws from law, computer science, public policy, philosophy, political science, and more. What matters is combining knowledge from at least two of these areas.

### Degree Programs

Several universities now offer programs specifically designed for AI governance:

- **Stanford HAI Policy Program** offers courses bridging AI technology and policy.
- **Georgetown's Center for Security and Emerging Technology (CSET)** trains analysts for government and policy roles.
- **University of Oxford's Institute for Ethics in AI** runs graduate programs in AI ethics and governance.
- **Carnegie Mellon's AI Engineering program** includes governance and policy tracks.
- **MIT's Technology and Policy Program** combines engineering with policy training.
- **University of Toronto's Schwartz Reisman Institute** offers interdisciplinary AI governance research opportunities.

A master's degree in public policy, law, or computer science with governance-focused coursework positions you well. A PhD helps for research-heavy roles but is not necessary for most positions.

### Fellowships and Training Programs

Fellowships offer structured entry into the field, often with stipends and placement in governance organizations:

- **AAAS Science & Technology Policy Fellowships** place scientists and engineers in US government agencies.
- **Horizon Fellowship** (run by the Federation of American Scientists) trains emerging tech policy leaders.
- **GovAI Fellowship** at Oxford focuses specifically on AI governance research.
- **Open Philanthropy's AI Governance Fellowship** supports graduate students working on AI policy.
- **Mozilla Foundation's Responsible Computer Science Challenge** funds curriculum development at the intersection of ethics and computing.
- **AI Safety Camp** provides structured project-based training in technical AI safety.

### Other Entry Points

You do not need to start from scratch. Many paths lead into AI governance:

**From law:** Technology law, data protection, and intellectual property practices all connect to AI governance. Lawyers who develop AI-specific expertise are in high demand.

**From engineering:** Software engineers and ML practitioners who develop interest in safety and policy bring irreplaceable technical credibility. Many AI labs actively recruit engineers for governance-adjacent roles.

**From social science:** Researchers studying technology's social impacts already have relevant analytical skills. The transition involves learning AI-specific technical vocabulary and policy mechanisms.

**From government service:** Civil servants experienced in technology regulation (telecommunications, pharmaceuticals, financial services) find that their regulatory knowledge transfers directly.

**From journalism:** Investigative reporters covering AI often develop the expertise and networks to transition into policy or advocacy roles.

**Practical first steps:** Write about AI governance (a blog, policy memos, or public comments on proposed regulations). Attend conferences (AAAI, ACM FAccT, AI Policy Forum). Volunteer with civil society organizations. Build a portfolio that demonstrates both understanding and engagement.

## Where the Jobs Are

AI governance jobs exist across five sectors, each with distinct cultures and trade-offs.

**Government agencies** offer the chance to shape binding regulation but pay less than the private sector. In the US, look at NIST, NTIA, FTC, and the new USAISI. In the EU, the AI Office is hiring. The UK's DSIT and AISI have expanded rapidly.

**AI laboratories** pay well and offer proximity to cutting-edge technology. Governance teams at Anthropic, OpenAI, Google DeepMind, and Meta shape internal policies and engage with external regulators. The tension: you are governing the product your employer sells.

**Consultancies and professional services firms** advise clients on AI compliance and risk management. Deloitte, McKinsey, BCG, and specialized boutique firms have built AI governance practices. The work is varied but can be implementation-heavy.

**Non-profits and civil society organizations** do the advocacy, research, and watchdog work that keeps other actors accountable. Salaries are typically lower, but the work is mission-driven and influential. The Algorithmic Justice League, AI Now Institute, and Center for AI Safety are examples.

**International organizations** operate at the highest level of governance coordination. The OECD, UN, World Economic Forum, and ISO set global norms. These roles require patience for multilateral processes and comfort with ambiguity.

## Reflexive Dimension

The question of who governs AI is itself an AI governance question. If the field is staffed primarily by people from wealthy countries with elite educations, it will encode those perspectives into global rules. Diversity in the AI governance workforce is not a nice-to-have; it is a condition for governance that actually represents the people affected by AI.

AI systems can contribute to career accessibility in this field. They can translate technical AI research into plain language, helping policy professionals build technical literacy. They can identify patterns in job postings, fellowship opportunities, and skill requirements. They can help aspiring governance professionals draft policy memos and practice analyzing regulations.

But AI systems should also be transparent about the limits of their own analysis. A model advising someone on AI governance careers should disclose that its training data is unlikely to reflect the most current job market. This kind of reflexive honesty, acknowledging what it does and does not know, is central to the principles of [reflexive AI governance](/research/030-manifesto/).

## Conclusion

AI governance is a field where the work matters, the demand is real, and the barriers to entry are lower than many people assume. You do not need a PhD in machine learning. You do not need a law degree. You need curiosity about how AI affects society, the willingness to learn across disciplines, and the initiative to start contributing.

The talent gap is an opportunity. Organizations are looking for people who bring diverse perspectives, not just conventional credentials. If you can combine technical literacy with policy thinking, ethical reasoning with practical judgment, or domain expertise with governance interest, there is a role for you.

The decisions that governments, companies, and civil society organizations make now about AI governance will shape how this technology affects billions of lives. The people making those decisions should reflect the full range of people those decisions affect. This field needs your voice.

## References

1. OECD AI Policy Observatory. "National AI Policies and Strategies." [https://oecd.ai](https://oecd.ai)
2. International Association of Privacy Professionals. "AI Governance in Practice: 2024 Survey." IAPP, 2024.
3. Georgetown CSET. "The AI Workforce: Government Needs Assessment." Center for Security and Emerging Technology, 2023.
4. NIST. "AI Risk Management Framework (AI RMF 1.0)." National Institute of Standards and Technology, 2023.
5. European Parliament. "Regulation (EU) 2024/1689: The EU Artificial Intelligence Act." 2024.
6. IEEE. "Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems." IEEE, 2019.
7. Dafoe, Allan. "AI Governance: A Research Agenda." Centre for the Governance of AI, University of Oxford, 2018.
8. Anderljung, Markus et al. "Frontier AI Regulation: Managing Emerging Risks to Public Safety." arXiv:2307.03718, 2023.

## Related Research

- [AI Governance for Non-Experts: A Primer](/research/017-governance-primer/)
- [The History of AI Governance in 2000 Words](/research/032-history-of-ai-governance/)
- [Who Watches the Watchers? Auditing AI Auditors](/research/006-meta-governance-auditors/)
- [A Reflexive AI Manifesto](/research/030-manifesto/)
