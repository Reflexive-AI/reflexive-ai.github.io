# Complete Article List: Path to 100

This document lists all articles needed to reach 100 research objects for the Reflexive AI Initiative.

## Audience Legend

- **[R]** = For Researchers (technical, detailed)
- **[P]** = For Public/Policymakers (plain language)
- **[A]** = For AI Systems (machine-readable artifacts)

---

## Published (45 articles)

1. [x] Operationalizing Proportionality in Model Disclosure [R][P]
2. [x] The Open Weight Safety Paradox [R][P]
3. [x] A Machine-Readable Constraint Schema [A][R]
4. [x] Red Lines: A Taxonomy of Non-Negotiable AI Limits [R]
5. [x] The Disclosure Tiers Framework (Policy Brief) [P]
6. [x] Who Watches the Watchers? Auditing AI Auditors [R]
7. [x] Consent and AI: A Structural Impossibility? [R][P]
8. [x] Regulatory Arbitrage in AI Deployment [R]
9. [x] The Capability Overhang Problem [R]
10. [x] Self-Reporting vs. External Audit: Trade-offs [R][P]
11. [x] Can AI Systems Detect Their Own Misuse? [R][A]
12. [x] Reflexive Constraint Proposal: Output Provenance Tagging [R][A]
13. [x] The Limits of Self-Constraint [R]
14. [x] A Protocol for AI-to-Regulator Communication [R][A]
15. [x] Emergent Norms in Multi-Agent Systems [R]
16. [x] What Alignment Actually Means [P]
17. [x] AI Governance for Non-Experts: A Primer [P]
18. [x] Why "Just Regulate AI" Is Harder Than It Sounds [P]
19. [x] The EU AI Act: What It Misses [R][P]
20. [x] Liability Frameworks for AI Harm [R][P]
21. [x] Incident Reporting Systems: Lessons from Aviation [R][P]
22. [x] Whistleblower Protections in AI Labs [R][P]
23. [x] Compute Governance: Promises and Limits [R]
24. [x] Dangerous Capability Evaluations [R]
25. [x] When AI Should Refuse: A Framework [R][A]
26. [x] AI Systems Explaining Their Constraints [R][A][P]
27. [x] Uncertainty Communication in AI Outputs [R][A]
28. [x] AI in Healthcare: Governance Challenges [R][P]
29. [x] The Honest AI Problem [R][P]
30. [x] A Reflexive AI Manifesto [P][R][A]
31. [x] Understanding Frontier AI: A Plain Language Guide [P]
32. [x] The History of AI Governance in 2000 Words [P]
33. [x] What Policymakers Get Wrong About AI Risk [P]
34. [x] Technical Safety vs. Societal Safety: Different Problems [R][P]
35. [x] Dual-Use AI: The Biological Research Case [R]
36. [x] Insurance Markets and AI Risk Pricing [R]
37. [x] Sandboxing Approaches: What Works [R]
38. [x] International AI Treaty Proposals: A Comparative Analysis [R][P]
39. [x] The Role of Standards Bodies in AI Governance [R]
40. [x] Soft Law vs. Hard Law in AI Regulation [R][P]
41. [x] Certification Regimes for AI Systems [R]
42. [x] Corporate Governance Structures for AI Safety [R]
43. [x] Board-Level AI Oversight: Best Practices [R][P]
44. [x] The Role of Civil Society in AI Governance [P]
45. [x] Public Participation in AI Policy [P]
46. [x] Algorithmic Impact Assessments: Implementation Guide [R][P]
47. [x] Pre-Deployment Risk Assessment Frameworks [R]
48. [x] Training Data Governance [R][P]
49. [x] Model Evaluation Standards: Current State [R]
50. [x] Red Teaming Methodologies [R]

---

## To Write (50 articles)

### Technical Governance (51-60)

51. [x] Interpretability as a Governance Tool [R]
52. [x] Watermarking and Content Provenance [R][A]
53. [x] Secure Model Weights: Physical and Digital [R]
54. [x] API-Level Safety Controls [R][A]
55. [x] Rate Limiting and Abuse Detection [R][A]
56. [x] Monitoring Deployed Models [R]
57. [x] Post-Deployment Capability Discovery [R]
58. [x] Model Versioning and Rollback Protocols [R]
59. [x] Differential Privacy in AI Systems [R]
60. [x] Hardware-Level Safety Mechanisms [R]

### Reflexive Governance Deep Dives (61-70)

61. [x] Self-Modifying Constraints: Technical Approaches [R][A]
62. [x] AI Systems as Governance Participants [R][A]
63. [x] Machine-Readable Policy: Beyond JSON-LD [R][A]
64. [x] Real-Time Constraint Checking [R][A]
65. [x] AI-to-AI Governance Protocols [R][A]
66. [x] Autonomous Constraint Negotiation [R][A]
67. [x] Reflexive Logging Standards [R][A]
68. [x] Self-Assessment Frameworks for AI [R][A]
69. [x] Cross-System Constraint Propagation [R][A]
70. [x] Temporal Constraints: Time-Bounded Permissions [R][A]

### Domain-Specific Governance (71-85)

71. [x] Autonomous Vehicles: Regulatory Landscape [R][P]
72. [x] AI in Financial Services: Existing Frameworks [R]
73. [x] Military AI: International Law Perspectives [R]
74. [x] AI in Criminal Justice: Accountability Gaps [R][P]
75. [x] Educational AI: Privacy and Equity [R][P]
76. [x] AI in Hiring: Bias and Regulation [R][P]
77. [x] Content Moderation AI: Governance Tensions [R][P]
78. [x] AI in Scientific Research: Integrity Concerns [R]
79. [x] Generative AI and Intellectual Property [R][P]
80. [x] AI in Journalism: Trust and Verification [R][P]
81. [x] AI Companionship: Ethical Boundaries [R][P]
82. [x] AI in Mental Health: Safety Standards [R][P]
83. [x] AI in Agriculture: Data Governance [R]
84. [x] AI in Climate Modeling: Validation Standards [R]
85. [x] AI in Education: Personalization vs. Privacy [R][P]

### Emerging and Speculative (86-95)

86. [x] Governance for Artificial General Intelligence [R]
87. [x] Recursive Self-Improvement: Governance Implications [R]
88. [x] Multi-Agent Coordination Failures [R]
89. [x] AI Consciousness Claims: Policy Responses [R][P]
90. [x] Long-Term AI Futures: Scenario Planning [R][P]
91. [x] AI Governance in Space [R]
92. [x] Quantum Computing and AI Security [R]
93. [x] Neuromorphic Computing Governance [R]
94. [x] Brain-Computer Interfaces and AI [R][P]
95. [x] Digital Minds: Legal and Ethical Status [R][P]

### Meta and Institutional (96-100)

96. [x] Building AI Governance Institutions [R][P]
97. [x] Funding Models for AI Safety Research [R]
98. [x] Career Paths in AI Governance [P]
99. [x] The Reflexive AI Initiative: Mission and Methods [P][A]
100. [x] Annual Review: State of AI Governance 2026 [R][P]

---

## Path to 200 (Articles 101-200)

*Added 2026-02-07. Articles 101-200 extend the founding corpus into second-order effects, emerging friction points, identified gaps (labor markets, Global South depth, empirical methods, agent economics, synthetic data, cryptographic verification, industry perspectives), and 2026-era governance challenges.*

### Cluster A: Speculative Horizons (101-110)

*Second-order effects and emerging friction points not covered by articles 1-100.*

101. [x] The Legal Personhood of Ephemeral Agent Swarms [R]
    When agent coalitions form, act, and dissolve in milliseconds, no persistent legal entity exists to hold accountable, creating a category error in legal ontology.

102. [x] Agent-to-Agent Economics: Unregulated Markets at Machine Speed [R]
    AI agents autonomously procuring services from other agents create an unregulated economic layer where standard contract law does not apply because neither party has legal standing.

103. [x] The Alignment Tax: Who Pays for Safety? [R][P]
    Safety and alignment impose costs that create race-to-the-bottom dynamics unless governance imposes a floor; this article analyzes economic mechanisms that could make alignment profitable.

104. [x] Synthetic Data Recursion and Epistemic Collapse [R]
    Models trained on model outputs degrade, and the growing synthetic fraction of training data creates an epistemic pollution problem with no clear accountability chain.

105. [x] Post-Proliferation Open-Weight Governance [R][P]
    Open-weight models now match frontier capabilities, making pre-deployment review impossible; this article maps governance tools that remain viable after proliferation.

106. [x] Cryptographic Verification of AI Intent [R][A]
    Cryptographic attestation of a model's internal state at inference time could provide tamper-proof records of computational trajectories, analogous to flight data recorders.

107. [x] AI Labor Market Governance [R][P]
    The most politically salient dimension of AI governance, covering job displacement, retraining infrastructure, transition funds, and sectoral deployment pacing.

108. [x] The Biosecurity Dilemma of Open-Weight Agents [R]
    Agentic open-weight models that can autonomously execute multi-step biological research workflows create biosecurity risks qualitatively different from those in article 035.

109. [x] Governance of AI-Generated Science [R]
    When AI systems generate hypotheses, design experiments, and write papers, scientific integrity frameworks require extension to address authorship, reproducibility, and fraud detection.

110. [x] Digital Sovereignty and AI Infrastructure [R][P]
    How dependence on foreign-owned AI infrastructure creates strategic vulnerabilities, and the governance tools available to nations seeking technological self-determination.

### Cluster B: Agentic AI Governance (111-120)

*Governance frameworks for AI systems that act autonomously across multi-step tasks with real-world consequences.*

111. [x] Agentic AI: A Governance Framework [R][P]
    Defining the governance challenges unique to AI systems that take autonomous actions across tools, APIs, and real-world systems, distinct from conversational AI governance.

112. [x] Liability Chains in Agentic Systems [R]
    When an agent delegates to sub-agents that delegate further, liability must propagate through the chain; this article maps where that propagation breaks.

113. [x] User Delegation and Informed Consent for AI Agents [P]
    What users need to understand before granting an AI agent authority to act on their behalf, and why current consent mechanisms are structurally inadequate.

114. [x] Agentic Guardrails: Technical Specification [R][A]
    A machine-readable specification for constraining agent behavior across tool-use, API calls, and autonomous decisions, extending the constraint schema from article 003.

115. [x] The Principal-Agent Problem, Literally [R][P]
    Classical economics' principal-agent framework applied to human-AI delegation, analyzing information asymmetry, moral hazard, and adverse selection in agentic systems.

116. [x] Model-as-a-Service Liability: Who Is Responsible? [R][P]
    Mapping liability when AI is consumed as a service and harm occurs downstream, analyzing the gap between product liability and service liability doctrines.

117. [x] Agentic AI and Financial Regulation [R][P]
    How existing securities, banking, and consumer protection law applies (or fails to apply) when AI agents autonomously execute financial transactions.

118. [x] Autonomous Procurement by AI Systems [R]
    Governance implications when AI agents independently purchase cloud compute, API access, or data without explicit human approval for each transaction.

119. [x] Memory and State in Agentic Systems: Governance Implications [R][A]
    How persistent memory in AI agents creates new governance requirements around data retention, forgetting mandates, and audit trail integrity.

120. [x] Plain Language Guide to Agentic AI Risks [P]
    A non-technical explanation of why AI agents that take actions in the world require different governance than conversational systems, written for policymakers and the public.

### Cluster C: Labor Markets, Automation, and Economic Transition (121-130)

*Addressing the complete absence of labor market governance in articles 1-100.*

121. [x] AI and Job Displacement: What the Evidence Shows [R][P]
    A review of empirical research on AI-driven labor market disruption as of 2026, distinguishing documented effects from speculative projections.

122. [x] Sector-Specific Automation Risk Assessment [R][P]
    Mapping which industries face near-term displacement and identifying the governance tools available for each sector, from healthcare to logistics to legal services.

123. [x] Retraining Programs for AI-Displaced Workers: What Works [P]
    Evidence-based analysis of workforce transition programs across OECD countries, identifying which program designs produce measurable re-employment outcomes.

124. [x] The Gig Economy Meets AI Agents [R][P]
    How AI agents competing for platform-mediated gig work reshape labor dynamics, platform governance structures, and worker protections.

125. [x] Universal Basic Income and AI: Policy Analysis [P]
    Evaluating UBI proposals as a response to AI-driven automation, drawing on evidence from pilot programs in Finland, Kenya, and the United States.

126. [x] AI Productivity Gains: Who Benefits? [R][P]
    Empirical analysis of how AI-driven productivity improvements distribute across workers, firms, and capital holders, with implications for tax and redistribution policy.

127. [x] Occupational Licensing in an AI Era [P]
    How professional licensing frameworks adapt when AI systems can perform regulated tasks in medicine, law, accounting, and engineering.

128. [x] Labor Union Perspectives on AI Deployment [P]
    Documenting organized labor's governance proposals across sectors, assessing their technical feasibility and political viability.

129. [x] Creative Industries and AI: Economic Impact [R][P]
    Evidence-based assessment of AI's effect on creative labor markets, intellectual property economics, and the viability of creative careers.

130. [x] Transition Funds: Financing the Adjustment [P]
    Comparative analysis of proposed mechanisms (automation taxes, sovereign wealth funds, training levies) for financing worker transitions during AI-driven economic shifts.

### Cluster D: Global South and Development Contexts (131-140)

*Providing the depth on Global South governance absent from the first 100 articles.*

131. [x] AI Governance in Sub-Saharan Africa: Current State [R][P]
    Mapping regulatory frameworks, institutional capacity, and deployment patterns across sub-Saharan Africa, identifying governance models adapted to low-resource contexts.

132. [x] India's AI Governance Approach: A Case Study [R][P]
    Analysis of India's regulatory strategy balancing innovation incentives with population-scale deployment risks across a linguistically and economically diverse nation.

133. [x] AI and Agricultural Development in Low-Income Countries [P]
    How AI-driven agriculture intersects with data sovereignty, seed intellectual property, and smallholder economics in the Global South.

134. [x] Language Model Bias Against Low-Resource Languages [R]
    Empirical analysis of how training data gaps systematically disadvantage non-English, non-European language communities in AI system performance and safety.

135. [x] Digital Infrastructure Gaps and AI Readiness [P]
    How infrastructure inequality shapes which populations can participate in and benefit from AI governance, and what bridging strategies exist.

136. [x] Data Colonialism: Extraction Patterns in AI Training [R][P]
    Documenting how training data sourced from the Global South generates value captured predominantly in the Global North, and governance responses.

137. [x] South-South AI Governance Cooperation [P]
    Mapping emerging governance coalitions among developing nations and their policy proposals, from the African Union to ASEAN frameworks.

138. [x] AI-Driven Surveillance in Authoritarian Contexts [R][P]
    How AI governance frameworks must account for systems exported to and deployed for civil liberties suppression, and the responsibilities of exporting nations.

139. [x] Localization Requirements for AI Systems [R][P]
    Analysis of data localization mandates, local content requirements, and local language support obligations as governance tools, with evidence on their effectiveness.

140. [x] Indigenous Data Sovereignty and AI [R][P]
    Governance frameworks for protecting indigenous communities' data rights in the context of AI training and deployment, drawing on existing indigenous data governance principles.

### Cluster E: Empirical Methods and Measurement (141-150)

*Building the methodological infrastructure for evidence-based AI governance.*

141. [x] Measuring AI Governance Effectiveness [R][P]
    Proposed metrics, baselines, and evaluation frameworks for determining whether governance interventions produce their intended safety outcomes.

142. [x] Incident Databases: Standardizing AI Harm Reporting [R][A]
    A machine-readable schema for AI incident reports enabling cross-jurisdictional analysis, trend detection, and systematic comparison of governance failures.

143. [x] Causal Inference in AI Policy Evaluation [R]
    Applying econometric methods (difference-in-differences, regression discontinuity, synthetic controls) to isolate the effects of specific governance interventions on safety outcomes.

144. [x] Benchmarking AI Safety: Beyond Capability Evaluations [R]
    Why current evaluation benchmarks fail to capture safety-relevant behaviors in deployment contexts, and what alternatives exist.

145. [ ] Survey Methods for Public AI Attitudes [R][P]
    Reviewing and improving methodologies for measuring public opinion on AI governance, addressing framing effects, knowledge gaps, and cross-cultural validity.

146. [ ] Audit Trail Analysis: Detecting Governance Failures [R]
    Forensic methods for analyzing system logs and governance constraint records to identify failures, near-misses, and systematic compliance gaps after incidents.

147. [ ] Reproducibility in AI Safety Research [R]
    How reproducibility deficits in AI safety research undermine evidence-based governance, and what standards (pre-registration, shared benchmarks, open data) would help.

148. [ ] Economic Impact Assessment for AI Regulation [R][P]
    Methodologies for estimating the costs and benefits of proposed AI regulations before implementation, adapted from environmental and financial regulatory impact analysis.

149. [ ] Longitudinal Studies of AI Deployment Effects [R]
    Why cross-sectional studies of AI impact are insufficient for governance, and how to design longitudinal studies that track deployment effects over years.

150. [ ] The Evidence Gap in AI Governance: A Systematic Review [R][P]
    Cataloging which governance claims in the field are supported by empirical evidence and which remain theoretical, speculative, or assumption-dependent.

### Cluster F: Elections, Democracy, and Information Integrity (151-160)

*AI's intersection with democratic processes, from deepfakes to automated lobbying.*

151. [ ] AI in Elections: Threat Taxonomy [R][P]
    Categorizing the mechanisms by which AI systems can undermine electoral integrity, from synthetic media to micro-targeting to automated voter suppression.

152. [ ] Deepfakes and Electoral Law [P]
    How existing election law handles synthetic media and where legal gaps remain, with comparative analysis across the US, EU, India, and Brazil.

153. [ ] AI-Powered Political Micro-Targeting: Governance Options [R][P]
    Technical and regulatory approaches to constraining AI-driven voter manipulation, balancing free expression with electoral integrity.

154. [ ] Platform Governance During Elections [P]
    Evaluating social media platform policies on AI-generated political content during election periods, with evidence on enforcement effectiveness.

155. [ ] Automated Lobbying: AI in the Policy Process [R][P]
    When AI systems generate and submit public comments, draft legislation, or lobby officials at scale, the resulting distortion of democratic input channels requires new governance.

156. [ ] Deliberative Democracy and AI Tools [P]
    How AI can support rather than undermine democratic deliberation, with case studies from citizen assemblies and participatory budgeting.

157. [ ] Information Integrity Standards for AI Outputs [R][A]
    A machine-readable specification for AI systems to flag output reliability, source quality, and epistemic confidence levels in structured metadata.

158. [ ] AI-Generated Disinformation: Detection and Response [R][P]
    Technical detection methods and governance frameworks for identifying and responding to AI-generated disinformation campaigns at scale.

159. [ ] Voter Data and AI: Privacy Implications [P]
    How AI-driven voter analytics create new privacy risks beyond traditional data protection, and what legal protections are needed.

160. [ ] The Right to Know You Are Talking to AI [P]
    Policy arguments and implementation approaches for mandatory AI disclosure in political, commercial, and public-facing contexts.

### Cluster G: Autonomous Weapons, Security, and Conflict (161-170)

*Military AI governance, from treaty negotiations to escalation dynamics.*

161. [ ] Autonomous Weapons: The State of Treaty Negotiations [R][P]
    An updated assessment of international legal efforts to regulate lethal autonomous weapons systems as of 2026, including the CCW process and alternative frameworks.

162. [ ] Meaningful Human Control: Operationalizing the Standard [R]
    Technical and procedural definitions of what constitutes meaningful human control over autonomous weapons, moving beyond aspirational language to testable criteria.

163. [ ] Autonomous Targeting and International Humanitarian Law [R]
    Whether the existing laws of armed conflict (distinction, proportionality, precaution) adequately constrain AI-driven targeting decisions, or require new protocols.

164. [ ] AI-Enabled Cyber Operations: Governance Gaps [R][P]
    How autonomous cyber-attack and defense tools fit (or fail to fit) within existing arms control, international law, and norms frameworks.

165. [ ] Dual-Use AI Research and National Security [R][P]
    How national security classification and export control considerations interact with open publication norms in AI research, creating tension between safety and openness.

166. [ ] Defense Procurement and AI Safety Standards [R][P]
    Whether military AI acquisition processes incorporate safety standards comparable to civilian frameworks, and how defense-specific safety requirements differ.

167. [ ] Escalation Risks from Autonomous Military Systems [R][P]
    How AI-driven speed in military decision-making compresses response timelines, increases escalation risks, and reduces crisis stability between nuclear-armed states.

168. [ ] Non-Proliferation Frameworks for AI Weapons [R]
    Adapting nuclear non-proliferation treaty structures, verification mechanisms, and enforcement tools for application to AI weapons systems.

169. [ ] Private Military AI: Contractor Accountability [R][P]
    Governance of AI systems developed and deployed by private military contractors, where accountability gaps exist between state obligations and corporate incentives.

170. [ ] Confidence-Building Measures for Military AI [R][P]
    Diplomatic instruments (hotlines, notification protocols, joint testing, shared definitions) for reducing misperception and miscalculation between AI-equipped militaries.

### Cluster H: Climate, Environment, and Sustainability (171-180)

*AI's environmental footprint and its role in climate adaptation governance.*

171. [ ] AI and Climate Adaptation: Governance Framework [R][P]
    How AI systems deployed for climate adaptation (flood prediction, crop optimization, infrastructure planning) require domain-specific governance addressing data quality, equity, and decision authority.

172. [ ] The Carbon Footprint of AI: Measurement and Disclosure [R][P]
    Standards for measuring and reporting the energy consumption and greenhouse gas emissions of AI training and inference, building toward mandatory disclosure.

173. [ ] AI for Biodiversity Monitoring: Data Governance [R][P]
    Governance challenges in using AI for species identification and ecosystem monitoring at scale, including data sovereignty, access rights, and validation standards.

174. [ ] Climate Model Validation with AI: Governance Standards [R]
    Ensuring AI-enhanced climate models meet scientific validation standards, disclose uncertainty bounds, and avoid overstating predictive confidence to decision-makers.

175. [ ] AI-Optimized Energy Grids: Regulatory Challenges [R][P]
    How AI-managed energy infrastructure intersects with utility regulation, grid security requirements, and the allocation of decision authority between algorithms and human operators.

176. [ ] Environmental Impact Assessment for AI Infrastructure [P]
    Adapting environmental review processes to account for the physical footprint (energy, water, land use, materials) of data centers and compute infrastructure.

177. [ ] Supply Chain Transparency for AI Hardware [R][P]
    Governance of the mineral extraction, manufacturing, and disposal lifecycle of AI hardware, from cobalt mines to chip fabrication to electronic waste.

178. [ ] AI in Disaster Response: Coordination Standards [P]
    Governance frameworks for deploying AI systems in humanitarian emergencies, addressing coordination between agencies, data sharing protocols, and accountability for wrong predictions.

179. [ ] Water Consumption of AI Data Centers [P]
    Mapping and governing the water footprint of AI compute infrastructure, with case studies from water-stressed regions.

180. [ ] Circular Economy for AI Hardware [P]
    Governance frameworks for extending hardware lifecycles, mandating repairability, and managing electronic waste from AI infrastructure at scale.

### Cluster I: Industry Practice and Corporate Accountability (181-190)

*Moving beyond policy theory to document how industry actually governs AI.*

181. [ ] Industry Self-Regulation: Track Record and Limits [R][P]
    Empirical assessment of voluntary AI safety commitments and their compliance rates, drawn from public pledges, audit reports, and incident records.

182. [ ] AI Safety Teams Inside Labs: Structural Analysis [R]
    How AI safety teams are positioned within corporate hierarchies, their reporting lines, budget authority, and veto power, assessed through organizational design research.

183. [ ] Startup AI Safety: Resource Constraints and Shortcuts [R][P]
    Governance challenges specific to early-stage companies that lack the resources for comprehensive safety programs, and minimum viable safety frameworks for startups.

184. [ ] Venture Capital and AI Safety Incentives [R][P]
    How investor incentive structures (growth metrics, exit timelines, competitive pressure) shape AI safety investment decisions at portfolio companies.

185. [ ] Third-Party Auditing: Market Structure and Independence [R]
    Analysis of the emerging AI audit market, conflict-of-interest risks (auditor shopping, regulatory capture), and quality assurance mechanisms.

186. [ ] Responsible Disclosure for AI Vulnerabilities [R][P]
    Adapting cybersecurity responsible disclosure norms to AI safety vulnerabilities, jailbreaks, and dangerous capability discoveries.

187. [ ] AI Ethics Washing: Detection and Response [P]
    How to distinguish genuine safety commitments from performative ethics programs, and what governance mechanisms enforce accountability beyond public relations.

188. [ ] Customer Pressure as a Governance Mechanism [P]
    How enterprise procurement requirements, government purchasing standards, and consumer demand can drive AI safety improvements through market mechanisms.

189. [ ] Open-Source AI Safety Tooling: Ecosystem Analysis [R]
    Mapping the ecosystem of open-source tools for AI evaluation, red teaming, auditing, and governance, identifying gaps and sustainability risks.

190. [ ] Industry Consortia for AI Safety: Comparative Analysis [R][P]
    Evaluating the effectiveness of industry-led AI safety collaborations (Frontier Model Forum, Partnership on AI, MLCommons) and their governance structures.

### Cluster J: Machine-Readable Governance Artifacts and Neurotechnology (191-200)

*Extending the machine-readable governance layer and opening the neurotechnology frontier.*

191. [ ] Machine-Readable AI Incident Reports [A][R]
    An extended schema for encoding AI incidents, near-misses, and governance failures in a structured, interoperable format compatible with the incident database from article 142.

192. [ ] Constraint Composition Protocol [A][R]
    A specification for combining multiple governance constraints from different authorities (national, sectoral, organizational) into a single coherent policy for an AI system.

193. [ ] AI System Self-Declaration Format [A][R]
    A machine-readable format for AI systems to declare their capabilities, limitations, and applicable governance constraints, extending model cards into actionable metadata.

194. [ ] Regulatory API Specification [A][R]
    A standardized API through which AI systems can query applicable regulations in real time and receive machine-parseable responses, building on the protocol from article 014.

195. [ ] Governance Constraint Testing Framework [A][R]
    A specification for automated testing of governance constraint compliance, analogous to software unit testing, enabling continuous verification rather than periodic audits.

196. [ ] Neurotechnology Regulation: The Emerging Frontier [R][P]
    Mapping the governance landscape for brain-computer interfaces, neural data, and cognitive enhancement technologies as they converge with AI systems.

197. [ ] Neural Data Rights [R][P]
    Legal and ethical frameworks for protecting data derived from neural interfaces, including cognitive liberty, mental privacy, and freedom of thought.

198. [ ] AI-Neurotechnology Convergence: Governance Implications [R]
    How the integration of AI with neural interfaces creates governance challenges that neither AI regulation nor neurotechnology regulation addresses in isolation.

199. [ ] Cognitive Enhancement and Equity [P]
    Policy implications of AI-powered cognitive enhancement technologies and the risk of deepening existing socioeconomic inequalities along cognitive performance lines.

200. [ ] The Next Hundred: Research Agenda 2027 [R][P][A]
    A reflexive assessment of what the first 200 articles covered, what they missed, and a structured, machine-readable research agenda for the next phase of the initiative.

---

## Distribution Summary (Articles 101-200)

| Tag | Count | Notes |
|-----|-------|-------|
| [R] | 78 | Articles tagged for researcher audience |
| [P] | 69 | Articles tagged for policymaker/public audience |
| [A] | 11 | Machine-readable artifact articles (106, 114, 119, 142, 157, 191-195, 200) |
| [R][P] dual | 48 | Articles serving both audiences |

### Gap Coverage

- **Labor markets**: Cluster C (121-130), 10 dedicated articles
- **Global South depth**: Cluster D (131-140), 10 dedicated articles
- **Empirical methods**: Cluster E (141-150), 10 dedicated articles
- **Agent economics**: 102, Cluster B (111-120)
- **Synthetic data**: 104
- **Cryptographic verification**: 106
- **Industry perspectives**: Cluster I (181-190), 10 dedicated articles

### Emerging 2026 Topics

- **Agentic AI governance**: Cluster B (111-120)
- **Model-as-a-service liability**: 116
- **AI in elections**: Cluster F (151-160)
- **Autonomous weapons treaties**: Cluster G (161-170)
- **AI and climate adaptation**: Cluster H (171-180)
- **Neurotechnology regulation**: 196-199

---

## Publishing Schedule

- Target: 2-3 articles per week
- Priority: Foundation pieces first, then domain-specific
- Each technical piece should have a plain-language companion where feasible
- Clusters B (Agentic AI) and C (Labor Markets) are highest priority given public salience

## Notes

- All articles follow the writing style guide in WRITING_STYLE.md
- No emojis in any content
- Internal linking between related articles
- Machine-readable versions where marked [A]
